{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d1d0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\numpy\\.libs\\libopenblas.4SP5SUA7CBGXUEOC35YP2ASOICYYEQZZ.gfortran-win_amd64.dll\n",
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba846a30",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215f480",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ac6ce",
   "metadata": {},
   "source": [
    "#### (a) After 1080 epoch to reach accurace =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f50b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss  0.7049422860145569\n",
      "Training accuracy is  0.5\n",
      "Epoch  10 Loss  0.7001311779022217\n",
      "Training accuracy is  0.5\n",
      "Epoch  20 Loss  0.6951521635055542\n",
      "Training accuracy is  0.5\n",
      "Epoch  30 Loss  0.6933895945549011\n",
      "Training accuracy is  0.5\n",
      "Epoch  40 Loss  0.6931244134902954\n",
      "Training accuracy is  0.5\n",
      "Epoch  50 Loss  0.6931405067443848\n",
      "Training accuracy is  0.5\n",
      "Epoch  60 Loss  0.6931229829788208\n",
      "Training accuracy is  0.5\n",
      "Epoch  70 Loss  0.6930912137031555\n",
      "Training accuracy is  0.5\n",
      "Epoch  80 Loss  0.6930682063102722\n",
      "Training accuracy is  0.5\n",
      "Epoch  90 Loss  0.6930526494979858\n",
      "Training accuracy is  0.75\n",
      "Epoch  100 Loss  0.6930404901504517\n",
      "Training accuracy is  0.75\n",
      "Epoch  110 Loss  0.6930286884307861\n",
      "Training accuracy is  0.75\n",
      "Epoch  120 Loss  0.693016767501831\n",
      "Training accuracy is  0.75\n",
      "Epoch  130 Loss  0.6930046081542969\n",
      "Training accuracy is  0.5\n",
      "Epoch  140 Loss  0.6929952502250671\n",
      "Training accuracy is  0.5\n",
      "Epoch  150 Loss  0.6929852366447449\n",
      "Training accuracy is  0.5\n",
      "Epoch  160 Loss  0.6929756999015808\n",
      "Training accuracy is  0.5\n",
      "Epoch  170 Loss  0.6929659843444824\n",
      "Training accuracy is  0.5\n",
      "Epoch  180 Loss  0.6929566860198975\n",
      "Training accuracy is  0.5\n",
      "Epoch  190 Loss  0.692947268486023\n",
      "Training accuracy is  0.5\n",
      "Epoch  200 Loss  0.6929376721382141\n",
      "Training accuracy is  0.5\n",
      "Epoch  210 Loss  0.6929283142089844\n",
      "Training accuracy is  0.5\n",
      "Epoch  220 Loss  0.6929186582565308\n",
      "Training accuracy is  0.5\n",
      "Epoch  230 Loss  0.6929088234901428\n",
      "Training accuracy is  0.75\n",
      "Epoch  240 Loss  0.6928987503051758\n",
      "Training accuracy is  0.75\n",
      "Epoch  250 Loss  0.6928884983062744\n",
      "Training accuracy is  0.75\n",
      "Epoch  260 Loss  0.6928780674934387\n",
      "Training accuracy is  0.75\n",
      "Epoch  270 Loss  0.6928673386573792\n",
      "Training accuracy is  0.75\n",
      "Epoch  280 Loss  0.69285649061203\n",
      "Training accuracy is  0.75\n",
      "Epoch  290 Loss  0.6928457021713257\n",
      "Training accuracy is  0.75\n",
      "Epoch  300 Loss  0.6928341388702393\n",
      "Training accuracy is  0.75\n",
      "Epoch  310 Loss  0.6928225755691528\n",
      "Training accuracy is  0.5\n",
      "Epoch  320 Loss  0.6928106546401978\n",
      "Training accuracy is  0.5\n",
      "Epoch  330 Loss  0.6927982568740845\n",
      "Training accuracy is  0.5\n",
      "Epoch  340 Loss  0.6927855014801025\n",
      "Training accuracy is  0.5\n",
      "Epoch  350 Loss  0.692772388458252\n",
      "Training accuracy is  0.5\n",
      "Epoch  360 Loss  0.6927588582038879\n",
      "Training accuracy is  0.5\n",
      "Epoch  370 Loss  0.6927448511123657\n",
      "Training accuracy is  0.5\n",
      "Epoch  380 Loss  0.6927302479743958\n",
      "Training accuracy is  0.5\n",
      "Epoch  390 Loss  0.692715048789978\n",
      "Training accuracy is  0.5\n",
      "Epoch  400 Loss  0.6926994919776917\n",
      "Training accuracy is  0.5\n",
      "Epoch  410 Loss  0.6926833987236023\n",
      "Training accuracy is  0.5\n",
      "Epoch  420 Loss  0.6926665306091309\n",
      "Training accuracy is  0.5\n",
      "Epoch  430 Loss  0.6926493048667908\n",
      "Training accuracy is  0.5\n",
      "Epoch  440 Loss  0.6926312446594238\n",
      "Training accuracy is  0.5\n",
      "Epoch  450 Loss  0.6926127672195435\n",
      "Training accuracy is  0.5\n",
      "Epoch  460 Loss  0.6925933361053467\n",
      "Training accuracy is  0.5\n",
      "Epoch  470 Loss  0.6925731897354126\n",
      "Training accuracy is  0.5\n",
      "Epoch  480 Loss  0.6925521492958069\n",
      "Training accuracy is  0.5\n",
      "Epoch  490 Loss  0.6925302147865295\n",
      "Training accuracy is  0.5\n",
      "Epoch  500 Loss  0.6925073862075806\n",
      "Training accuracy is  0.5\n",
      "Epoch  510 Loss  0.69248366355896\n",
      "Training accuracy is  0.5\n",
      "Epoch  520 Loss  0.692458987236023\n",
      "Training accuracy is  0.5\n",
      "Epoch  530 Loss  0.6924329996109009\n",
      "Training accuracy is  0.5\n",
      "Epoch  540 Loss  0.6924057006835938\n",
      "Training accuracy is  0.5\n",
      "Epoch  550 Loss  0.6923772096633911\n",
      "Training accuracy is  0.5\n",
      "Epoch  560 Loss  0.69234699010849\n",
      "Training accuracy is  0.5\n",
      "Epoch  570 Loss  0.6923154592514038\n",
      "Training accuracy is  0.5\n",
      "Epoch  580 Loss  0.692282497882843\n",
      "Training accuracy is  0.5\n",
      "Epoch  590 Loss  0.6922478675842285\n",
      "Training accuracy is  0.5\n",
      "Epoch  600 Loss  0.6922109723091125\n",
      "Training accuracy is  0.5\n",
      "Epoch  610 Loss  0.6921722292900085\n",
      "Training accuracy is  0.5\n",
      "Epoch  620 Loss  0.6921311616897583\n",
      "Training accuracy is  0.5\n",
      "Epoch  630 Loss  0.6920880079269409\n",
      "Training accuracy is  0.5\n",
      "Epoch  640 Loss  0.6920417547225952\n",
      "Training accuracy is  0.5\n",
      "Epoch  650 Loss  0.691993236541748\n",
      "Training accuracy is  0.5\n",
      "Epoch  660 Loss  0.6919417977333069\n",
      "Training accuracy is  0.5\n",
      "Epoch  670 Loss  0.691886305809021\n",
      "Training accuracy is  0.5\n",
      "Epoch  680 Loss  0.6918274164199829\n",
      "Training accuracy is  0.5\n",
      "Epoch  690 Loss  0.6917645931243896\n",
      "Training accuracy is  0.5\n",
      "Epoch  700 Loss  0.6916976571083069\n",
      "Training accuracy is  0.5\n",
      "Epoch  710 Loss  0.6916258335113525\n",
      "Training accuracy is  0.5\n",
      "Epoch  720 Loss  0.6915507316589355\n",
      "Training accuracy is  0.5\n",
      "Epoch  730 Loss  0.69147127866745\n",
      "Training accuracy is  0.5\n",
      "Epoch  740 Loss  0.6913857460021973\n",
      "Training accuracy is  0.5\n",
      "Epoch  750 Loss  0.6912945508956909\n",
      "Training accuracy is  0.5\n",
      "Epoch  760 Loss  0.6911959648132324\n",
      "Training accuracy is  0.5\n",
      "Epoch  770 Loss  0.6910896897315979\n",
      "Training accuracy is  0.5\n",
      "Epoch  780 Loss  0.6909741163253784\n",
      "Training accuracy is  0.5\n",
      "Epoch  790 Loss  0.6908471584320068\n",
      "Training accuracy is  0.5\n",
      "Epoch  800 Loss  0.6907098889350891\n",
      "Training accuracy is  0.5\n",
      "Epoch  810 Loss  0.6905593872070312\n",
      "Training accuracy is  0.5\n",
      "Epoch  820 Loss  0.6903934478759766\n",
      "Training accuracy is  0.5\n",
      "Epoch  830 Loss  0.6902110576629639\n",
      "Training accuracy is  0.5\n",
      "Epoch  840 Loss  0.690009355545044\n",
      "Training accuracy is  0.5\n",
      "Epoch  850 Loss  0.6897909641265869\n",
      "Training accuracy is  0.5\n",
      "Epoch  860 Loss  0.6895453333854675\n",
      "Training accuracy is  0.5\n",
      "Epoch  870 Loss  0.6892795562744141\n",
      "Training accuracy is  0.5\n",
      "Epoch  880 Loss  0.6889804601669312\n",
      "Training accuracy is  0.5\n",
      "Epoch  890 Loss  0.6886457204818726\n",
      "Training accuracy is  0.5\n",
      "Epoch  900 Loss  0.6882699728012085\n",
      "Training accuracy is  0.5\n",
      "Epoch  910 Loss  0.6878454685211182\n",
      "Training accuracy is  0.5\n",
      "Epoch  920 Loss  0.6873555779457092\n",
      "Training accuracy is  0.5\n",
      "Epoch  930 Loss  0.6867976784706116\n",
      "Training accuracy is  0.5\n",
      "Epoch  940 Loss  0.6861504316329956\n",
      "Training accuracy is  0.5\n",
      "Epoch  950 Loss  0.6853946447372437\n",
      "Training accuracy is  0.5\n",
      "Epoch  960 Loss  0.6845227479934692\n",
      "Training accuracy is  0.5\n",
      "Epoch  970 Loss  0.6834635138511658\n",
      "Training accuracy is  0.5\n",
      "Epoch  980 Loss  0.6821982860565186\n",
      "Training accuracy is  0.5\n",
      "Epoch  990 Loss  0.6806832551956177\n",
      "Training accuracy is  0.5\n",
      "Epoch  1000 Loss  0.6788161993026733\n",
      "Training accuracy is  0.5\n",
      "Epoch  1010 Loss  0.6764807105064392\n",
      "Training accuracy is  0.5\n",
      "Epoch  1020 Loss  0.6735011339187622\n",
      "Training accuracy is  0.5\n",
      "Epoch  1030 Loss  0.6696534156799316\n",
      "Training accuracy is  0.5\n",
      "Epoch  1040 Loss  0.6643049120903015\n",
      "Training accuracy is  0.5\n",
      "Epoch  1050 Loss  0.6566085815429688\n",
      "Training accuracy is  0.5\n",
      "Epoch  1060 Loss  0.6462041139602661\n",
      "Training accuracy is  0.5\n",
      "Epoch  1070 Loss  0.6307687163352966\n",
      "Training accuracy is  0.75\n",
      "Epoch  1080 Loss  0.6097596287727356\n",
      "Training accuracy is  1.0\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 20)\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.fc3 = nn.Linear(20, 20)\n",
    "        self.fc4 = nn.Linear(20, 20)\n",
    "        self.fc5 = nn.Linear(20, 20)\n",
    "        self.fc6 = nn.Linear(20, 20)\n",
    "        self.fc7 = nn.Linear(20, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        return F.log_softmax(x)\n",
    "        #return F.softmax(x)\n",
    "    #%% plot function\n",
    "        \n",
    "def plot_data(X, y, filename):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "        \n",
    "def plot_decision_boundary(clf, X, y, filename):\n",
    "    # Set min and max values and give it some padding\n",
    "    #x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    #y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    x_min, x_max = -0.5, 1.5\n",
    "    y_min, y_max = -0.5, 1.5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    X_out = net(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype = torch.float))\n",
    "    Z = X_out.data.max(1)[1]\n",
    "    # Z.shape\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "#%% read data\n",
    "\n",
    "data=pd.DataFrame(data={\"x1\":[0,0,1,1],\"x2\":[0,1,0,1],\"y\":[0,1,1,0]})\n",
    "X = data.values[:, 0:2]  # Take only the first two features.     \n",
    "X = torch.tensor(X, dtype = torch.float)   \n",
    "y = data.values[:, 2]\n",
    "y = torch.tensor(y, dtype = torch.long)\n",
    "\n",
    "#plot_data(X,y,'data.pdf')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "plt.show()\n",
    "\n",
    "#%% train\n",
    "net = Net()\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = .01\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# create a loss function\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# nepochs = 10000\n",
    "#nepochs = 3000 #10000\n",
    "nepochs = 3000\n",
    "data, target = X, y\n",
    "# run the main training loop\n",
    "for epoch in range(nepochs):\n",
    "#    adjust learning rate if desired\n",
    "#    if epoch % 3000 == 0 and epoch <= 24000:\n",
    "#        for g in optimizer.param_groups:\n",
    "#            g['lr'] = g['lr']/2\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagate\n",
    "    net_out = net(data)\n",
    "    # compute loss\n",
    "    loss = criterion(net_out, target)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # print out report\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correctidx = pred.eq(target.data) \n",
    "        ncorrect = correctidx.sum()\n",
    "        accuracy = ncorrect.item()/len(data)\n",
    "        print('Training accuracy is ', accuracy)\n",
    "# adding stop condition as soon as the accuracy reach 1\n",
    "        if accuracy ==1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c4f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "#%%  plot outputs\n",
    "plot_decision_boundary(net, X, y, 'Results0.0001.pdf')\n",
    "plot_decision_boundary(net, X[correctidx,:], y[correctidx], 'Correct.pdf')\n",
    "plot_decision_boundary(net, X[~correctidx,:], y[~correctidx], 'Inorrect.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ef006",
   "metadata": {},
   "source": [
    "#### (b) After 3100 epoch, the loss fall below 1*10^-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9c70e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss  0.6980985403060913\n",
      "Training accuracy is  0.5\n",
      "Epoch  10 Loss  0.6956726908683777\n",
      "Training accuracy is  0.5\n",
      "Epoch  20 Loss  0.6935121417045593\n",
      "Training accuracy is  0.5\n",
      "Epoch  30 Loss  0.6929730772972107\n",
      "Training accuracy is  0.5\n",
      "Epoch  40 Loss  0.6929244995117188\n",
      "Training accuracy is  0.5\n",
      "Epoch  50 Loss  0.6928489804267883\n",
      "Training accuracy is  0.5\n",
      "Epoch  60 Loss  0.6927491426467896\n",
      "Training accuracy is  0.5\n",
      "Epoch  70 Loss  0.6926646828651428\n",
      "Training accuracy is  0.5\n",
      "Epoch  80 Loss  0.6925920248031616\n",
      "Training accuracy is  0.5\n",
      "Epoch  90 Loss  0.6925411820411682\n",
      "Training accuracy is  0.5\n",
      "Epoch  100 Loss  0.6924867630004883\n",
      "Training accuracy is  0.5\n",
      "Epoch  110 Loss  0.6924335956573486\n",
      "Training accuracy is  0.5\n",
      "Epoch  120 Loss  0.6923801898956299\n",
      "Training accuracy is  0.5\n",
      "Epoch  130 Loss  0.6923214197158813\n",
      "Training accuracy is  0.5\n",
      "Epoch  140 Loss  0.6922513246536255\n",
      "Training accuracy is  0.5\n",
      "Epoch  150 Loss  0.6921745538711548\n",
      "Training accuracy is  0.5\n",
      "Epoch  160 Loss  0.6921002268791199\n",
      "Training accuracy is  0.5\n",
      "Epoch  170 Loss  0.6920382976531982\n",
      "Training accuracy is  0.5\n",
      "Epoch  180 Loss  0.6919770240783691\n",
      "Training accuracy is  0.5\n",
      "Epoch  190 Loss  0.6919178366661072\n",
      "Training accuracy is  0.5\n",
      "Epoch  200 Loss  0.6918400526046753\n",
      "Training accuracy is  0.5\n",
      "Epoch  210 Loss  0.691766619682312\n",
      "Training accuracy is  0.5\n",
      "Epoch  220 Loss  0.6916874647140503\n",
      "Training accuracy is  0.5\n",
      "Epoch  230 Loss  0.6916009187698364\n",
      "Training accuracy is  0.5\n",
      "Epoch  240 Loss  0.6915153861045837\n",
      "Training accuracy is  0.5\n",
      "Epoch  250 Loss  0.6914243698120117\n",
      "Training accuracy is  0.5\n",
      "Epoch  260 Loss  0.6913212537765503\n",
      "Training accuracy is  0.5\n",
      "Epoch  270 Loss  0.6912168860435486\n",
      "Training accuracy is  0.5\n",
      "Epoch  280 Loss  0.6910881400108337\n",
      "Training accuracy is  0.5\n",
      "Epoch  290 Loss  0.6909564733505249\n",
      "Training accuracy is  0.5\n",
      "Epoch  300 Loss  0.690813422203064\n",
      "Training accuracy is  0.5\n",
      "Epoch  310 Loss  0.6906528472900391\n",
      "Training accuracy is  0.5\n",
      "Epoch  320 Loss  0.6904669404029846\n",
      "Training accuracy is  0.5\n",
      "Epoch  330 Loss  0.6902599334716797\n",
      "Training accuracy is  0.5\n",
      "Epoch  340 Loss  0.6900376081466675\n",
      "Training accuracy is  0.5\n",
      "Epoch  350 Loss  0.6897910237312317\n",
      "Training accuracy is  0.5\n",
      "Epoch  360 Loss  0.6895203590393066\n",
      "Training accuracy is  0.5\n",
      "Epoch  370 Loss  0.6891890168190002\n",
      "Training accuracy is  0.75\n",
      "Epoch  380 Loss  0.6888188123703003\n",
      "Training accuracy is  0.75\n",
      "Epoch  390 Loss  0.6883989572525024\n",
      "Training accuracy is  0.75\n",
      "Epoch  400 Loss  0.6879163980484009\n",
      "Training accuracy is  0.75\n",
      "Epoch  410 Loss  0.6873536705970764\n",
      "Training accuracy is  0.75\n",
      "Epoch  420 Loss  0.6867015361785889\n",
      "Training accuracy is  0.75\n",
      "Epoch  430 Loss  0.6858740448951721\n",
      "Training accuracy is  0.75\n",
      "Epoch  440 Loss  0.6848944425582886\n",
      "Training accuracy is  0.75\n",
      "Epoch  450 Loss  0.683662474155426\n",
      "Training accuracy is  1.0\n",
      "Epoch  460 Loss  0.6821313500404358\n",
      "Training accuracy is  1.0\n",
      "Epoch  470 Loss  0.6801905632019043\n",
      "Training accuracy is  1.0\n",
      "Epoch  480 Loss  0.6776757836341858\n",
      "Training accuracy is  1.0\n",
      "Epoch  490 Loss  0.6743284463882446\n",
      "Training accuracy is  1.0\n",
      "Epoch  500 Loss  0.6696659922599792\n",
      "Training accuracy is  1.0\n",
      "Epoch  510 Loss  0.6631253361701965\n",
      "Training accuracy is  1.0\n",
      "Epoch  520 Loss  0.653444766998291\n",
      "Training accuracy is  1.0\n",
      "Epoch  530 Loss  0.6383123993873596\n",
      "Training accuracy is  1.0\n",
      "Epoch  540 Loss  0.6130560040473938\n",
      "Training accuracy is  1.0\n",
      "Epoch  550 Loss  0.5653759241104126\n",
      "Training accuracy is  1.0\n",
      "Epoch  560 Loss  0.4787553548812866\n",
      "Training accuracy is  1.0\n",
      "Epoch  570 Loss  0.35131335258483887\n",
      "Training accuracy is  1.0\n",
      "Epoch  580 Loss  0.2343936264514923\n",
      "Training accuracy is  1.0\n",
      "Epoch  590 Loss  0.16926530003547668\n",
      "Training accuracy is  1.0\n",
      "Epoch  600 Loss  0.1264536827802658\n",
      "Training accuracy is  1.0\n",
      "Epoch  610 Loss  0.09693434834480286\n",
      "Training accuracy is  1.0\n",
      "Epoch  620 Loss  0.07593315094709396\n",
      "Training accuracy is  1.0\n",
      "Epoch  630 Loss  0.060769472271203995\n",
      "Training accuracy is  1.0\n",
      "Epoch  640 Loss  0.049576520919799805\n",
      "Training accuracy is  1.0\n",
      "Epoch  650 Loss  0.041097965091466904\n",
      "Training accuracy is  1.0\n",
      "Epoch  660 Loss  0.03453707695007324\n",
      "Training accuracy is  1.0\n",
      "Epoch  670 Loss  0.02936987206339836\n",
      "Training accuracy is  1.0\n",
      "Epoch  680 Loss  0.025234872475266457\n",
      "Training accuracy is  1.0\n",
      "Epoch  690 Loss  0.021869855001568794\n",
      "Training accuracy is  1.0\n",
      "Epoch  700 Loss  0.019109005108475685\n",
      "Training accuracy is  1.0\n",
      "Epoch  710 Loss  0.016820168122649193\n",
      "Training accuracy is  1.0\n",
      "Epoch  720 Loss  0.014903366565704346\n",
      "Training accuracy is  1.0\n",
      "Epoch  730 Loss  0.013279716484248638\n",
      "Training accuracy is  1.0\n",
      "Epoch  740 Loss  0.011894562281668186\n",
      "Training accuracy is  1.0\n",
      "Epoch  750 Loss  0.010709053836762905\n",
      "Training accuracy is  1.0\n",
      "Epoch  760 Loss  0.009686172939836979\n",
      "Training accuracy is  1.0\n",
      "Epoch  770 Loss  0.008797653019428253\n",
      "Training accuracy is  1.0\n",
      "Epoch  780 Loss  0.008018347434699535\n",
      "Training accuracy is  1.0\n",
      "Epoch  790 Loss  0.007334797643125057\n",
      "Training accuracy is  1.0\n",
      "Epoch  800 Loss  0.006732266861945391\n",
      "Training accuracy is  1.0\n",
      "Epoch  810 Loss  0.006199802737683058\n",
      "Training accuracy is  1.0\n",
      "Epoch  820 Loss  0.005727570969611406\n",
      "Training accuracy is  1.0\n",
      "Epoch  830 Loss  0.005307105835527182\n",
      "Training accuracy is  1.0\n",
      "Epoch  840 Loss  0.004931227769702673\n",
      "Training accuracy is  1.0\n",
      "Epoch  850 Loss  0.004594117868691683\n",
      "Training accuracy is  1.0\n",
      "Epoch  860 Loss  0.0042906091548502445\n",
      "Training accuracy is  1.0\n",
      "Epoch  870 Loss  0.0040165879763662815\n",
      "Training accuracy is  1.0\n",
      "Epoch  880 Loss  0.003768336260691285\n",
      "Training accuracy is  1.0\n",
      "Epoch  890 Loss  0.0035430158022791147\n",
      "Training accuracy is  1.0\n",
      "Epoch  900 Loss  0.0033378638327121735\n",
      "Training accuracy is  1.0\n",
      "Epoch  910 Loss  0.003150573465973139\n",
      "Training accuracy is  1.0\n",
      "Epoch  920 Loss  0.0029790226835757494\n",
      "Training accuracy is  1.0\n",
      "Epoch  930 Loss  0.002821418922394514\n",
      "Training accuracy is  1.0\n",
      "Epoch  940 Loss  0.002676525618880987\n",
      "Training accuracy is  1.0\n",
      "Epoch  950 Loss  0.00254281354136765\n",
      "Training accuracy is  1.0\n",
      "Epoch  960 Loss  0.002419218420982361\n",
      "Training accuracy is  1.0\n",
      "Epoch  970 Loss  0.002304828492924571\n",
      "Training accuracy is  1.0\n",
      "Epoch  980 Loss  0.002198669593781233\n",
      "Training accuracy is  1.0\n",
      "Epoch  990 Loss  0.0021000036504119635\n",
      "Training accuracy is  1.0\n",
      "Epoch  1000 Loss  0.002008121693506837\n",
      "Training accuracy is  1.0\n",
      "Epoch  1010 Loss  0.0019224623683840036\n",
      "Training accuracy is  1.0\n",
      "Epoch  1020 Loss  0.001842405297793448\n",
      "Training accuracy is  1.0\n",
      "Epoch  1030 Loss  0.001767476787790656\n",
      "Training accuracy is  1.0\n",
      "Epoch  1040 Loss  0.0016973231686279178\n",
      "Training accuracy is  1.0\n",
      "Epoch  1050 Loss  0.001631439896300435\n",
      "Training accuracy is  1.0\n",
      "Epoch  1060 Loss  0.0015695912297815084\n",
      "Training accuracy is  1.0\n",
      "Epoch  1070 Loss  0.001511421287432313\n",
      "Training accuracy is  1.0\n",
      "Epoch  1080 Loss  0.0014566052705049515\n",
      "Training accuracy is  1.0\n",
      "Epoch  1090 Loss  0.001404935261234641\n",
      "Training accuracy is  1.0\n",
      "Epoch  1100 Loss  0.0013561747036874294\n",
      "Training accuracy is  1.0\n",
      "Epoch  1110 Loss  0.0013099967036396265\n",
      "Training accuracy is  1.0\n",
      "Epoch  1120 Loss  0.0012664024252444506\n",
      "Training accuracy is  1.0\n",
      "Epoch  1130 Loss  0.0012250947766005993\n",
      "Training accuracy is  1.0\n",
      "Epoch  1140 Loss  0.001185925561003387\n",
      "Training accuracy is  1.0\n",
      "Epoch  1150 Loss  0.0011487466981634498\n",
      "Training accuracy is  1.0\n",
      "Epoch  1160 Loss  0.0011134095257148147\n",
      "Training accuracy is  1.0\n",
      "Epoch  1170 Loss  0.0010798255680128932\n",
      "Training accuracy is  1.0\n",
      "Epoch  1180 Loss  0.0010478460462763906\n",
      "Training accuracy is  1.0\n",
      "Epoch  1190 Loss  0.0010173522168770432\n",
      "Training accuracy is  1.0\n",
      "Epoch  1200 Loss  0.000988314743153751\n",
      "Training accuracy is  1.0\n",
      "Epoch  1210 Loss  0.0009605253580957651\n",
      "Training accuracy is  1.0\n",
      "Epoch  1220 Loss  0.0009340737015008926\n",
      "Training accuracy is  1.0\n",
      "Epoch  1230 Loss  0.000908751564566046\n",
      "Training accuracy is  1.0\n",
      "Epoch  1240 Loss  0.0008845293195918202\n",
      "Training accuracy is  1.0\n",
      "Epoch  1250 Loss  0.0008613477693870664\n",
      "Training accuracy is  1.0\n",
      "Epoch  1260 Loss  0.0008391471928916872\n",
      "Training accuracy is  1.0\n",
      "Epoch  1270 Loss  0.0008178387070074677\n",
      "Training accuracy is  1.0\n",
      "Epoch  1280 Loss  0.0007974222535267472\n",
      "Training accuracy is  1.0\n",
      "Epoch  1290 Loss  0.0007778384606353939\n",
      "Training accuracy is  1.0\n",
      "Epoch  1300 Loss  0.000759027898311615\n",
      "Training accuracy is  1.0\n",
      "Epoch  1310 Loss  0.0007409608806483448\n",
      "Training accuracy is  1.0\n",
      "Epoch  1320 Loss  0.0007235777447931468\n",
      "Training accuracy is  1.0\n",
      "Epoch  1330 Loss  0.0007068789564073086\n",
      "Training accuracy is  1.0\n",
      "Epoch  1340 Loss  0.0006907748756930232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is  1.0\n",
      "Epoch  1350 Loss  0.000675295596010983\n",
      "Training accuracy is  1.0\n",
      "Epoch  1360 Loss  0.0006603218498639762\n",
      "Training accuracy is  1.0\n",
      "Epoch  1370 Loss  0.0006459432188421488\n",
      "Training accuracy is  1.0\n",
      "Epoch  1380 Loss  0.0006320703541859984\n",
      "Training accuracy is  1.0\n",
      "Epoch  1390 Loss  0.0006186733953654766\n",
      "Training accuracy is  1.0\n",
      "Epoch  1400 Loss  0.0006057228310965002\n",
      "Training accuracy is  1.0\n",
      "Epoch  1410 Loss  0.0005932482308708131\n",
      "Training accuracy is  1.0\n",
      "Epoch  1420 Loss  0.0005811604205518961\n",
      "Training accuracy is  1.0\n",
      "Epoch  1430 Loss  0.0005694893188774586\n",
      "Training accuracy is  1.0\n",
      "Epoch  1440 Loss  0.0005582347512245178\n",
      "Training accuracy is  1.0\n",
      "Epoch  1450 Loss  0.0005473074270412326\n",
      "Training accuracy is  1.0\n",
      "Epoch  1460 Loss  0.0005367670091800392\n",
      "Training accuracy is  1.0\n",
      "Epoch  1470 Loss  0.0005264944047667086\n",
      "Training accuracy is  1.0\n",
      "Epoch  1480 Loss  0.0005165789043530822\n",
      "Training accuracy is  1.0\n",
      "Epoch  1490 Loss  0.0005069610197097063\n",
      "Training accuracy is  1.0\n",
      "Epoch  1500 Loss  0.0004977003554813564\n",
      "Training accuracy is  1.0\n",
      "Epoch  1510 Loss  0.0004886479000560939\n",
      "Training accuracy is  1.0\n",
      "Epoch  1520 Loss  0.00047992297913879156\n",
      "Training accuracy is  1.0\n",
      "Epoch  1530 Loss  0.00047143612755462527\n",
      "Training accuracy is  1.0\n",
      "Epoch  1540 Loss  0.00046315754298120737\n",
      "Training accuracy is  1.0\n",
      "Epoch  1550 Loss  0.000455117056844756\n",
      "Training accuracy is  1.0\n",
      "Epoch  1560 Loss  0.00044737436110153794\n",
      "Training accuracy is  1.0\n",
      "Epoch  1570 Loss  0.00043984001968055964\n",
      "Training accuracy is  1.0\n",
      "Epoch  1580 Loss  0.00043248420115560293\n",
      "Training accuracy is  1.0\n",
      "Epoch  1590 Loss  0.00042533676605671644\n",
      "Training accuracy is  1.0\n",
      "Epoch  1600 Loss  0.0004183977725915611\n",
      "Training accuracy is  1.0\n",
      "Epoch  1610 Loss  0.0004116373311262578\n",
      "Training accuracy is  1.0\n",
      "Epoch  1620 Loss  0.0004050555289722979\n",
      "Training accuracy is  1.0\n",
      "Epoch  1630 Loss  0.00039865230792202055\n",
      "Training accuracy is  1.0\n",
      "Epoch  1640 Loss  0.0003924277552869171\n",
      "Training accuracy is  1.0\n",
      "Epoch  1650 Loss  0.0003863222955260426\n",
      "Training accuracy is  1.0\n",
      "Epoch  1660 Loss  0.0003804549924097955\n",
      "Training accuracy is  1.0\n",
      "Epoch  1670 Loss  0.0003746769798453897\n",
      "Training accuracy is  1.0\n",
      "Epoch  1680 Loss  0.0003690776356961578\n",
      "Training accuracy is  1.0\n",
      "Epoch  1690 Loss  0.0003635378088802099\n",
      "Training accuracy is  1.0\n",
      "Epoch  1700 Loss  0.00035820636549033225\n",
      "Training accuracy is  1.0\n",
      "Epoch  1710 Loss  0.0003529941022861749\n",
      "Training accuracy is  1.0\n",
      "Epoch  1720 Loss  0.00034790090285241604\n",
      "Training accuracy is  1.0\n",
      "Epoch  1730 Loss  0.0003429267671890557\n",
      "Training accuracy is  1.0\n",
      "Epoch  1740 Loss  0.000338101526722312\n",
      "Training accuracy is  1.0\n",
      "Epoch  1750 Loss  0.00033336563501507044\n",
      "Training accuracy is  1.0\n",
      "Epoch  1760 Loss  0.00032874883618205786\n",
      "Training accuracy is  1.0\n",
      "Epoch  1770 Loss  0.0003241915546823293\n",
      "Training accuracy is  1.0\n",
      "Epoch  1780 Loss  0.0003198129707016051\n",
      "Training accuracy is  1.0\n",
      "Epoch  1790 Loss  0.00031549393315799534\n",
      "Training accuracy is  1.0\n",
      "Epoch  1800 Loss  0.00031129398848861456\n",
      "Training accuracy is  1.0\n",
      "Epoch  1810 Loss  0.00030715364846400917\n",
      "Training accuracy is  1.0\n",
      "Epoch  1820 Loss  0.00030313237220980227\n",
      "Training accuracy is  1.0\n",
      "Epoch  1830 Loss  0.0002992302179336548\n",
      "Training accuracy is  1.0\n",
      "Epoch  1840 Loss  0.00029538763919845223\n",
      "Training accuracy is  1.0\n",
      "Epoch  1850 Loss  0.00029157480457797647\n",
      "Training accuracy is  1.0\n",
      "Epoch  1860 Loss  0.00028785131871700287\n",
      "Training accuracy is  1.0\n",
      "Epoch  1870 Loss  0.0002842767571564764\n",
      "Training accuracy is  1.0\n",
      "Epoch  1880 Loss  0.00028073193971067667\n",
      "Training accuracy is  1.0\n",
      "Epoch  1890 Loss  0.00027727647102437913\n",
      "Training accuracy is  1.0\n",
      "Epoch  1900 Loss  0.0002738508046604693\n",
      "Training accuracy is  1.0\n",
      "Epoch  1910 Loss  0.0002705740334931761\n",
      "Training accuracy is  1.0\n",
      "Epoch  1920 Loss  0.00026729723322205245\n",
      "Training accuracy is  1.0\n",
      "Epoch  1930 Loss  0.00026413961313664913\n",
      "Training accuracy is  1.0\n",
      "Epoch  1940 Loss  0.00026101170806214213\n",
      "Training accuracy is  1.0\n",
      "Epoch  1950 Loss  0.00025791360531002283\n",
      "Training accuracy is  1.0\n",
      "Epoch  1960 Loss  0.00025493462453596294\n",
      "Training accuracy is  1.0\n",
      "Epoch  1970 Loss  0.0002519854751881212\n",
      "Training accuracy is  1.0\n",
      "Epoch  1980 Loss  0.0002490958431735635\n",
      "Training accuracy is  1.0\n",
      "Epoch  1990 Loss  0.00024626581580378115\n",
      "Training accuracy is  1.0\n",
      "Epoch  2000 Loss  0.00024349532031919807\n",
      "Training accuracy is  1.0\n",
      "Epoch  2010 Loss  0.0002407546271570027\n",
      "Training accuracy is  1.0\n",
      "Epoch  2020 Loss  0.00023810325365047902\n",
      "Training accuracy is  1.0\n",
      "Epoch  2030 Loss  0.00023548169701825827\n",
      "Training accuracy is  1.0\n",
      "Epoch  2040 Loss  0.0002328898845007643\n",
      "Training accuracy is  1.0\n",
      "Epoch  2050 Loss  0.0002303874643985182\n",
      "Training accuracy is  1.0\n",
      "Epoch  2060 Loss  0.00022791483206674457\n",
      "Training accuracy is  1.0\n",
      "Epoch  2070 Loss  0.00022544215607922524\n",
      "Training accuracy is  1.0\n",
      "Epoch  2080 Loss  0.00022308866027742624\n",
      "Training accuracy is  1.0\n",
      "Epoch  2090 Loss  0.00022073514992371202\n",
      "Training accuracy is  1.0\n",
      "Epoch  2100 Loss  0.00021841141278855503\n",
      "Training accuracy is  1.0\n",
      "Epoch  2110 Loss  0.0002161472657462582\n",
      "Training accuracy is  1.0\n",
      "Epoch  2120 Loss  0.0002139128919225186\n",
      "Training accuracy is  1.0\n",
      "Epoch  2130 Loss  0.00021170827676542103\n",
      "Training accuracy is  1.0\n",
      "Epoch  2140 Loss  0.00020962287089787424\n",
      "Training accuracy is  1.0\n",
      "Epoch  2150 Loss  0.0002074778312817216\n",
      "Training accuracy is  1.0\n",
      "Epoch  2160 Loss  0.00020539239631034434\n",
      "Training accuracy is  1.0\n",
      "Epoch  2170 Loss  0.00020339632465038449\n",
      "Training accuracy is  1.0\n",
      "Epoch  2180 Loss  0.00020137045066803694\n",
      "Training accuracy is  1.0\n",
      "Epoch  2190 Loss  0.0001994041376747191\n",
      "Training accuracy is  1.0\n",
      "Epoch  2200 Loss  0.00019743782468140125\n",
      "Training accuracy is  1.0\n",
      "Epoch  2210 Loss  0.0001955609186552465\n",
      "Training accuracy is  1.0\n",
      "Epoch  2220 Loss  0.00019368398352526128\n",
      "Training accuracy is  1.0\n",
      "Epoch  2230 Loss  0.0001918070192914456\n",
      "Training accuracy is  1.0\n",
      "Epoch  2240 Loss  0.0001900194474728778\n",
      "Training accuracy is  1.0\n",
      "Epoch  2250 Loss  0.00018823187565431\n",
      "Training accuracy is  1.0\n",
      "Epoch  2260 Loss  0.00018647409160621464\n",
      "Training accuracy is  1.0\n",
      "Epoch  2270 Loss  0.00018474609532859176\n",
      "Training accuracy is  1.0\n",
      "Epoch  2280 Loss  0.00018304788682144135\n",
      "Training accuracy is  1.0\n",
      "Epoch  2290 Loss  0.0001813794660847634\n",
      "Training accuracy is  1.0\n",
      "Epoch  2300 Loss  0.00017971103079617023\n",
      "Training accuracy is  1.0\n",
      "Epoch  2310 Loss  0.00017810218560043722\n",
      "Training accuracy is  1.0\n",
      "Epoch  2320 Loss  0.00017649332585278898\n",
      "Training accuracy is  1.0\n",
      "Epoch  2330 Loss  0.0001749142538756132\n",
      "Training accuracy is  1.0\n",
      "Epoch  2340 Loss  0.00017336499877274036\n",
      "Training accuracy is  1.0\n",
      "Epoch  2350 Loss  0.0001718157291179523\n",
      "Training accuracy is  1.0\n",
      "Epoch  2360 Loss  0.0001703558227745816\n",
      "Training accuracy is  1.0\n",
      "Epoch  2370 Loss  0.00016883631178643554\n",
      "Training accuracy is  1.0\n",
      "Epoch  2380 Loss  0.00016737640544306487\n",
      "Training accuracy is  1.0\n",
      "Epoch  2390 Loss  0.00016594631597399712\n",
      "Training accuracy is  1.0\n",
      "Epoch  2400 Loss  0.0001645161974010989\n",
      "Training accuracy is  1.0\n",
      "Epoch  2410 Loss  0.00016314566892106086\n",
      "Training accuracy is  1.0\n",
      "Epoch  2420 Loss  0.00016177511133719236\n",
      "Training accuracy is  1.0\n",
      "Epoch  2430 Loss  0.00016037478053476661\n",
      "Training accuracy is  1.0\n",
      "Epoch  2440 Loss  0.0001590638275956735\n",
      "Training accuracy is  1.0\n",
      "Epoch  2450 Loss  0.0001577528746565804\n",
      "Training accuracy is  1.0\n",
      "Epoch  2460 Loss  0.00015644192171748728\n",
      "Training accuracy is  1.0\n",
      "Epoch  2470 Loss  0.0001551607419969514\n",
      "Training accuracy is  1.0\n",
      "Epoch  2480 Loss  0.00015387956227641553\n",
      "Training accuracy is  1.0\n",
      "Epoch  2490 Loss  0.00015259839710779488\n",
      "Training accuracy is  1.0\n",
      "Epoch  2500 Loss  0.00015140659525059164\n",
      "Training accuracy is  1.0\n",
      "Epoch  2510 Loss  0.00015021480794530362\n",
      "Training accuracy is  1.0\n",
      "Epoch  2520 Loss  0.0001490230206400156\n",
      "Training accuracy is  1.0\n",
      "Epoch  2530 Loss  0.00014783121878281236\n",
      "Training accuracy is  1.0\n",
      "Epoch  2540 Loss  0.00014663940237369388\n",
      "Training accuracy is  1.0\n",
      "Epoch  2550 Loss  0.00014547741739079356\n",
      "Training accuracy is  1.0\n",
      "Epoch  2560 Loss  0.0001444047811673954\n",
      "Training accuracy is  1.0\n",
      "Epoch  2570 Loss  0.00014327256940305233\n",
      "Training accuracy is  1.0\n",
      "Epoch  2580 Loss  0.00014217013085726649\n",
      "Training accuracy is  1.0\n",
      "Epoch  2590 Loss  0.00014109749463386834\n",
      "Training accuracy is  1.0\n",
      "Epoch  2600 Loss  0.00013999507063999772\n",
      "Training accuracy is  1.0\n",
      "Epoch  2610 Loss  0.00013892243441659957\n",
      "Training accuracy is  1.0\n",
      "Epoch  2620 Loss  0.0001379094028379768\n",
      "Training accuracy is  1.0\n",
      "Epoch  2630 Loss  0.00013686655438505113\n",
      "Training accuracy is  1.0\n",
      "Epoch  2640 Loss  0.00013582370593212545\n",
      "Training accuracy is  1.0\n",
      "Epoch  2650 Loss  0.00013481065980158746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is  1.0\n",
      "Epoch  2660 Loss  0.00013382740144152194\n",
      "Training accuracy is  1.0\n",
      "Epoch  2670 Loss  0.00013284414308145642\n",
      "Training accuracy is  1.0\n",
      "Epoch  2680 Loss  0.00013186087016947567\n",
      "Training accuracy is  1.0\n",
      "Epoch  2690 Loss  0.00013093720190227032\n",
      "Training accuracy is  1.0\n",
      "Epoch  2700 Loss  0.00012998373131267726\n",
      "Training accuracy is  1.0\n",
      "Epoch  2710 Loss  0.0001290600630454719\n",
      "Training accuracy is  1.0\n",
      "Epoch  2720 Loss  0.00012813639477826655\n",
      "Training accuracy is  1.0\n",
      "Epoch  2730 Loss  0.00012721271195914596\n",
      "Training accuracy is  1.0\n",
      "Epoch  2740 Loss  0.00012631883146241307\n",
      "Training accuracy is  1.0\n",
      "Epoch  2750 Loss  0.00012545473873615265\n",
      "Training accuracy is  1.0\n",
      "Epoch  2760 Loss  0.00012456085823941976\n",
      "Training accuracy is  1.0\n",
      "Epoch  2770 Loss  0.00012366696319077164\n",
      "Training accuracy is  1.0\n",
      "Epoch  2780 Loss  0.00012286248966120183\n",
      "Training accuracy is  1.0\n",
      "Epoch  2790 Loss  0.0001219685873365961\n",
      "Training accuracy is  1.0\n",
      "Epoch  2800 Loss  0.00012116409197915345\n",
      "Training accuracy is  1.0\n",
      "Epoch  2810 Loss  0.00012032979429932311\n",
      "Training accuracy is  1.0\n",
      "Epoch  2820 Loss  0.00011949548934353516\n",
      "Training accuracy is  1.0\n",
      "Epoch  2830 Loss  0.00011872078903252259\n",
      "Training accuracy is  1.0\n",
      "Epoch  2840 Loss  0.00011791627912316471\n",
      "Training accuracy is  1.0\n",
      "Epoch  2850 Loss  0.00011711177648976445\n",
      "Training accuracy is  1.0\n",
      "Epoch  2860 Loss  0.00011633706890279427\n",
      "Training accuracy is  1.0\n",
      "Epoch  2870 Loss  0.0001155325589934364\n",
      "Training accuracy is  1.0\n",
      "Epoch  2880 Loss  0.00011478763917693868\n",
      "Training accuracy is  1.0\n",
      "Epoch  2890 Loss  0.00011407251440687105\n",
      "Training accuracy is  1.0\n",
      "Epoch  2900 Loss  0.00011329780681990087\n",
      "Training accuracy is  1.0\n",
      "Epoch  2910 Loss  0.00011252309195697308\n",
      "Training accuracy is  1.0\n",
      "Epoch  2920 Loss  0.00011186756455572322\n",
      "Training accuracy is  1.0\n",
      "Epoch  2930 Loss  0.00011112264473922551\n",
      "Training accuracy is  1.0\n",
      "Epoch  2940 Loss  0.00011040751996915787\n",
      "Training accuracy is  1.0\n",
      "Epoch  2950 Loss  0.00010969238792313263\n",
      "Training accuracy is  1.0\n",
      "Epoch  2960 Loss  0.000108977263153065\n",
      "Training accuracy is  1.0\n",
      "Epoch  2970 Loss  0.00010832172847585753\n",
      "Training accuracy is  1.0\n",
      "Epoch  2980 Loss  0.00010763639875221997\n",
      "Training accuracy is  1.0\n",
      "Epoch  2990 Loss  0.00010695107630454004\n",
      "Training accuracy is  1.0\n",
      "Epoch  3000 Loss  0.00010626573930494487\n",
      "Training accuracy is  1.0\n",
      "Epoch  3010 Loss  0.00010563999967416748\n",
      "Training accuracy is  1.0\n",
      "Epoch  3020 Loss  0.00010498446499696001\n",
      "Training accuracy is  1.0\n",
      "Epoch  3030 Loss  0.00010432891576783732\n",
      "Training accuracy is  1.0\n",
      "Epoch  3040 Loss  0.00010367338109062985\n",
      "Training accuracy is  1.0\n",
      "Epoch  3050 Loss  0.00010307744378224015\n",
      "Training accuracy is  1.0\n",
      "Epoch  3060 Loss  0.00010245170415146276\n",
      "Training accuracy is  1.0\n",
      "Epoch  3070 Loss  0.00010182595724472776\n",
      "Training accuracy is  1.0\n",
      "Epoch  3080 Loss  0.00010120021761395037\n",
      "Training accuracy is  1.0\n",
      "Epoch  3090 Loss  0.00010060426575364545\n",
      "Training accuracy is  1.0\n",
      "Epoch  3100 Loss  9.997851884691045e-05\n",
      "Training accuracy is  1.0\n"
     ]
    }
   ],
   "source": [
    "#%% train\n",
    "net = Net()\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = .01\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# create a loss function\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# nepochs = 10000\n",
    "#nepochs = 3000 #10000\n",
    "nepochs = 5000\n",
    "data, target = X, y\n",
    "# run the main training loop\n",
    "for epoch in range(nepochs):\n",
    "#    adjust learning rate if desired\n",
    "#    if epoch % 3000 == 0 and epoch <= 24000:\n",
    "#        for g in optimizer.param_groups:\n",
    "#            g['lr'] = g['lr']/2\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagate\n",
    "    net_out = net(data)\n",
    "    # compute loss\n",
    "    loss = criterion(net_out, target)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # print out report\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correctidx = pred.eq(target.data) \n",
    "        ncorrect = correctidx.sum()\n",
    "        accuracy = ncorrect.item()/len(data)\n",
    "        print('Training accuracy is ', accuracy)\n",
    "# adding stop condition as soon as the accuracy reach 1\n",
    "        if loss.item()<0.0001:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20da767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "#%%  plot outputs\n",
    "plot_decision_boundary(net, X, y, 'Results0.0001.pdf')\n",
    "plot_decision_boundary(net, X[correctidx,:], y[correctidx], 'Correct.pdf')\n",
    "plot_decision_boundary(net, X[~correctidx,:], y[~correctidx], 'Inorrect.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdaf1af",
   "metadata": {},
   "source": [
    "#### (c) 1 hidden layer 3 node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1901cd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 3)\n",
    "        self.fc7 = nn.Linear(3, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc7(x)\n",
    "        return F.log_softmax(x)\n",
    "        #return F.softmax(x)\n",
    "    #%% plot function\n",
    "        \n",
    "def plot_data(X, y, filename):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "        \n",
    "def plot_decision_boundary(clf, X, y, filename):\n",
    "    # Set min and max values and give it some padding\n",
    "    #x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    #y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    x_min, x_max = -1, 1\n",
    "    y_min, y_max = -1, 1\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    X_out = net(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype = torch.float))\n",
    "    Z = X_out.data.max(1)[1]\n",
    "    # Z.shape\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "#%% read data\n",
    "\n",
    "data=pd.DataFrame(data={\"x1\":[0,0,1,1],\"x2\":[0,1,0,1],\"y\":[0,1,1,0]})\n",
    "X = data.values[:, 0:2]  # Take only the first two features.     \n",
    "X = torch.tensor(X, dtype = torch.float)   \n",
    "y = data.values[:, 2]\n",
    "y = torch.tensor(y, dtype = torch.long)\n",
    "\n",
    "#plot_data(X,y,'data.pdf')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8e61063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss  0.7479711174964905\n",
      "Training accuracy is  0.5\n",
      "Epoch  10 Loss  0.69833904504776\n",
      "Training accuracy is  0.5\n",
      "Epoch  20 Loss  0.6668489575386047\n",
      "Training accuracy is  0.5\n",
      "Epoch  30 Loss  0.6624796986579895\n",
      "Training accuracy is  0.5\n",
      "Epoch  40 Loss  0.6531241536140442\n",
      "Training accuracy is  0.75\n",
      "Epoch  50 Loss  0.6436635851860046\n",
      "Training accuracy is  0.5\n",
      "Epoch  60 Loss  0.6335506439208984\n",
      "Training accuracy is  0.5\n",
      "Epoch  70 Loss  0.6227771043777466\n",
      "Training accuracy is  0.5\n",
      "Epoch  80 Loss  0.6111659407615662\n",
      "Training accuracy is  0.75\n",
      "Epoch  90 Loss  0.5982900261878967\n",
      "Training accuracy is  0.75\n",
      "Epoch  100 Loss  0.5865616202354431\n",
      "Training accuracy is  0.75\n",
      "Epoch  110 Loss  0.5752888321876526\n",
      "Training accuracy is  0.75\n",
      "Epoch  120 Loss  0.5642483234405518\n",
      "Training accuracy is  0.75\n",
      "Epoch  130 Loss  0.5536409020423889\n",
      "Training accuracy is  0.75\n",
      "Epoch  140 Loss  0.5431841015815735\n",
      "Training accuracy is  0.75\n",
      "Epoch  150 Loss  0.5332648158073425\n",
      "Training accuracy is  0.75\n",
      "Epoch  160 Loss  0.5241427421569824\n",
      "Training accuracy is  0.75\n",
      "Epoch  170 Loss  0.5152794718742371\n",
      "Training accuracy is  0.75\n",
      "Epoch  180 Loss  0.50691819190979\n",
      "Training accuracy is  0.75\n",
      "Epoch  190 Loss  0.49860861897468567\n",
      "Training accuracy is  0.75\n",
      "Epoch  200 Loss  0.4905815124511719\n",
      "Training accuracy is  0.75\n",
      "Epoch  210 Loss  0.48248347640037537\n",
      "Training accuracy is  0.75\n",
      "Epoch  220 Loss  0.4744330048561096\n",
      "Training accuracy is  0.75\n",
      "Epoch  230 Loss  0.46636462211608887\n",
      "Training accuracy is  0.75\n",
      "Epoch  240 Loss  0.457739919424057\n",
      "Training accuracy is  0.75\n",
      "Epoch  250 Loss  0.4491150677204132\n",
      "Training accuracy is  0.75\n",
      "Epoch  260 Loss  0.44001463055610657\n",
      "Training accuracy is  0.75\n",
      "Epoch  270 Loss  0.4302089810371399\n",
      "Training accuracy is  0.75\n",
      "Epoch  280 Loss  0.4201154112815857\n",
      "Training accuracy is  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#%% train\n",
    "net = Net()\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = .01\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# create a loss function\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# nepochs = 10000\n",
    "#nepochs = 3000 #10000\n",
    "nepochs = 10000\n",
    "data, target = X, y\n",
    "# run the main training loop\n",
    "for epoch in range(nepochs):\n",
    "#    adjust learning rate if desired\n",
    "#    if epoch % 3000 == 0 and epoch <= 24000:\n",
    "#        for g in optimizer.param_groups:\n",
    "#            g['lr'] = g['lr']/2\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagate\n",
    "    net_out = net(data)\n",
    "    # compute loss\n",
    "    loss = criterion(net_out, target)\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # print out report\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correctidx = pred.eq(target.data) \n",
    "        ncorrect = correctidx.sum()\n",
    "        accuracy = ncorrect.item()/len(data)\n",
    "        print('Training accuracy is ', accuracy)\n",
    "# adding stop condition as soon as the accuracy reach 1\n",
    "        if accuracy ==1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a92e8",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "#### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e42e3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"Feedforward_Data_ellipse.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a67d99f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=[\"x1\",\"x2\",\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89523393",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.values[:, 0:2]  # Take only the first two features.     \n",
    "X = torch.tensor(X, dtype = torch.float)   \n",
    "y = data.values[:, 2]\n",
    "y = torch.tensor(y, dtype = torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c9e1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_l=[]\n",
    "loss_l=[]\n",
    "par=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ea8e639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't run this block\n",
    "#h_1=range(2,10)\n",
    "#h_2=range(2,10)\n",
    "#h_3=range(2,10)\n",
    "#parameters =list(product(h_1,h_2,h_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "185e4d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=[[80,80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0cc448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss  0.6997531056404114\n",
      "Training accuracy is  0.67578125\n",
      "Epoch  10 Loss  0.49385643005371094\n",
      "Training accuracy is  0.8325570913461539\n",
      "Epoch  20 Loss  0.2842622995376587\n",
      "Training accuracy is  0.8558443509615384\n",
      "Epoch  30 Loss  0.2167314887046814\n",
      "Training accuracy is  0.8916766826923077\n",
      "Epoch  40 Loss  0.20396128296852112\n",
      "Training accuracy is  0.9016676682692307\n",
      "Epoch  50 Loss  0.2005247324705124\n",
      "Training accuracy is  0.8979116586538461\n",
      "Epoch  60 Loss  0.19889654219150543\n",
      "Training accuracy is  0.8991135817307693\n",
      "Epoch  70 Loss  0.19797363877296448\n",
      "Training accuracy is  0.8982872596153846\n",
      "Epoch  80 Loss  0.19709110260009766\n",
      "Training accuracy is  0.8984375\n",
      "Epoch  90 Loss  0.1965232491493225\n",
      "Training accuracy is  0.8985126201923077\n",
      "Epoch  100 Loss  0.1960477977991104\n",
      "Training accuracy is  0.8985877403846154\n",
      "Epoch  110 Loss  0.19567669928073883\n",
      "Training accuracy is  0.8989633413461539\n",
      "Epoch  120 Loss  0.1963711827993393\n",
      "Training accuracy is  0.8991887019230769\n",
      "Epoch  130 Loss  0.19545510411262512\n",
      "Training accuracy is  0.8993389423076923\n",
      "Epoch  140 Loss  0.19483624398708344\n",
      "Training accuracy is  0.8991887019230769\n",
      "Epoch  150 Loss  0.19471052289009094\n",
      "Training accuracy is  0.8985877403846154\n",
      "Epoch  160 Loss  0.19463396072387695\n",
      "Training accuracy is  0.8985877403846154\n",
      "Epoch  170 Loss  0.19474530220031738\n",
      "Training accuracy is  0.8985877403846154\n",
      "Epoch  180 Loss  0.1942468285560608\n",
      "Training accuracy is  0.8994891826923077\n",
      "Epoch  190 Loss  0.1939650923013687\n",
      "Training accuracy is  0.8991135817307693\n",
      "Epoch  200 Loss  0.19393771886825562\n",
      "Training accuracy is  0.8995643028846154\n",
      "Epoch  210 Loss  0.1937682032585144\n",
      "Training accuracy is  0.8990384615384616\n",
      "Epoch  220 Loss  0.19375623762607574\n",
      "Training accuracy is  0.8991135817307693\n",
      "Epoch  230 Loss  0.19359320402145386\n",
      "Training accuracy is  0.8988882211538461\n",
      "Epoch  240 Loss  0.19324442744255066\n",
      "Training accuracy is  0.8997896634615384\n",
      "Epoch  250 Loss  0.19355985522270203\n",
      "Training accuracy is  0.8991135817307693\n",
      "Epoch  260 Loss  0.1931205540895462\n",
      "Training accuracy is  0.8991135817307693\n",
      "Epoch  270 Loss  0.19301623106002808\n",
      "Training accuracy is  0.8997145432692307\n",
      "Epoch  280 Loss  0.19274252653121948\n",
      "Training accuracy is  0.8994891826923077\n",
      "Epoch  290 Loss  0.19526734948158264\n",
      "Training accuracy is  0.8985126201923077\n",
      "Epoch  300 Loss  0.19248653948307037\n",
      "Training accuracy is  0.8991887019230769\n",
      "Epoch  310 Loss  0.19242309033870697\n",
      "Training accuracy is  0.8996394230769231\n",
      "Epoch  320 Loss  0.19245292246341705\n",
      "Training accuracy is  0.8997896634615384\n",
      "Epoch  330 Loss  0.1921599954366684\n",
      "Training accuracy is  0.8996394230769231\n",
      "Epoch  340 Loss  0.19214919209480286\n",
      "Training accuracy is  0.8998647836538461\n",
      "Epoch  350 Loss  0.19345490634441376\n",
      "Training accuracy is  0.9000901442307693\n",
      "Epoch  360 Loss  0.19211214780807495\n",
      "Training accuracy is  0.8996394230769231\n",
      "Epoch  370 Loss  0.19191506505012512\n",
      "Training accuracy is  0.8999399038461539\n",
      "Epoch  380 Loss  0.19185134768486023\n",
      "Training accuracy is  0.8995643028846154\n",
      "Epoch  390 Loss  0.192015141248703\n",
      "Training accuracy is  0.8996394230769231\n",
      "Epoch  400 Loss  0.19142469763755798\n",
      "Training accuracy is  0.8997896634615384\n",
      "Epoch  410 Loss  0.19155147671699524\n",
      "Training accuracy is  0.8995643028846154\n",
      "Epoch  420 Loss  0.19115711748600006\n",
      "Training accuracy is  0.8999399038461539\n",
      "Epoch  430 Loss  0.19509941339492798\n",
      "Training accuracy is  0.9003155048076923\n",
      "Epoch  440 Loss  0.19126476347446442\n",
      "Training accuracy is  0.9001652644230769\n",
      "Epoch  450 Loss  0.19097448885440826\n",
      "Training accuracy is  0.8998647836538461\n",
      "Epoch  460 Loss  0.19083712995052338\n",
      "Training accuracy is  0.8997145432692307\n",
      "Epoch  470 Loss  0.1906871497631073\n",
      "Training accuracy is  0.8999399038461539\n",
      "Epoch  480 Loss  0.19118070602416992\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  490 Loss  0.1910439431667328\n",
      "Training accuracy is  0.9000901442307693\n",
      "Epoch  500 Loss  0.1912868171930313\n",
      "Training accuracy is  0.8995643028846154\n",
      "Epoch  510 Loss  0.19023588299751282\n",
      "Training accuracy is  0.8998647836538461\n",
      "Epoch  520 Loss  0.19381220638751984\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  530 Loss  0.19172334671020508\n",
      "Training accuracy is  0.8997896634615384\n",
      "Epoch  540 Loss  0.19051751494407654\n",
      "Training accuracy is  0.8997145432692307\n",
      "Epoch  550 Loss  0.19013039767742157\n",
      "Training accuracy is  0.9001652644230769\n",
      "Epoch  560 Loss  0.19011107087135315\n",
      "Training accuracy is  0.8997896634615384\n",
      "Epoch  570 Loss  0.19206292927265167\n",
      "Training accuracy is  0.8995643028846154\n",
      "Epoch  580 Loss  0.19050775468349457\n",
      "Training accuracy is  0.9005408653846154\n",
      "Epoch  590 Loss  0.18932367861270905\n",
      "Training accuracy is  0.8998647836538461\n",
      "Epoch  600 Loss  0.18971262872219086\n",
      "Training accuracy is  0.8998647836538461\n",
      "Epoch  610 Loss  0.1892385184764862\n",
      "Training accuracy is  0.9001652644230769\n",
      "Epoch  620 Loss  0.19362856447696686\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  630 Loss  0.18892072141170502\n",
      "Training accuracy is  0.9001652644230769\n",
      "Epoch  640 Loss  0.18930570781230927\n",
      "Training accuracy is  0.8997896634615384\n",
      "Epoch  650 Loss  0.1890493780374527\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  660 Loss  0.18878602981567383\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  670 Loss  0.19127623736858368\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  680 Loss  0.19021232426166534\n",
      "Training accuracy is  0.8997896634615384\n",
      "Epoch  690 Loss  0.1893245279788971\n",
      "Training accuracy is  0.9003155048076923\n",
      "Epoch  700 Loss  0.18848615884780884\n",
      "Training accuracy is  0.9000150240384616\n",
      "Epoch  710 Loss  0.18862198293209076\n",
      "Training accuracy is  0.9004657451923077\n",
      "Epoch  720 Loss  0.1899464875459671\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  730 Loss  0.1879153549671173\n",
      "Training accuracy is  0.9001652644230769\n",
      "Epoch  740 Loss  0.1899167001247406\n",
      "Training accuracy is  0.8997896634615384\n",
      "Epoch  750 Loss  0.18778148293495178\n",
      "Training accuracy is  0.9004657451923077\n",
      "Epoch  760 Loss  0.18760624527931213\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  770 Loss  0.18898527324199677\n",
      "Training accuracy is  0.8998647836538461\n",
      "Epoch  780 Loss  0.1875685602426529\n",
      "Training accuracy is  0.9001652644230769\n",
      "Epoch  790 Loss  0.18857982754707336\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  800 Loss  0.1872621476650238\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  810 Loss  0.18726764619350433\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  820 Loss  0.18811891973018646\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  830 Loss  0.18709567189216614\n",
      "Training accuracy is  0.9005408653846154\n",
      "Epoch  840 Loss  0.19109909236431122\n",
      "Training accuracy is  0.9017427884615384\n",
      "Epoch  850 Loss  0.18860694766044617\n",
      "Training accuracy is  0.8998647836538461\n",
      "Epoch  860 Loss  0.18793900310993195\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  870 Loss  0.1870555579662323\n",
      "Training accuracy is  0.9000150240384616\n",
      "Epoch  880 Loss  0.1868891566991806\n",
      "Training accuracy is  0.9001652644230769\n",
      "Epoch  890 Loss  0.18962931632995605\n",
      "Training accuracy is  0.8998647836538461\n",
      "Epoch  900 Loss  0.18655426800251007\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  910 Loss  0.18629789352416992\n",
      "Training accuracy is  0.9005408653846154\n",
      "Epoch  920 Loss  0.18745176494121552\n",
      "Training accuracy is  0.9000150240384616\n",
      "Epoch  930 Loss  0.18623177707195282\n",
      "Training accuracy is  0.9003155048076923\n",
      "Epoch  940 Loss  0.18734481930732727\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  950 Loss  0.1859697550535202\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  960 Loss  0.18994835019111633\n",
      "Training accuracy is  0.8999399038461539\n",
      "Epoch  970 Loss  0.18773654103279114\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  980 Loss  0.18548470735549927\n",
      "Training accuracy is  0.9003155048076923\n",
      "Epoch  990 Loss  0.18841293454170227\n",
      "Training accuracy is  0.9000150240384616\n",
      "Epoch  1000 Loss  0.18514610826969147\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  1010 Loss  0.18967334926128387\n",
      "Training accuracy is  0.9021183894230769\n",
      "Epoch  1020 Loss  0.18526294827461243\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  1030 Loss  0.18611016869544983\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  1040 Loss  0.1847556233406067\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  1050 Loss  0.19520583748817444\n",
      "Training accuracy is  0.9136117788461539\n",
      "Epoch  1060 Loss  0.18838748335838318\n",
      "Training accuracy is  0.9000150240384616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1070 Loss  0.18575024604797363\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  1080 Loss  0.18532679975032806\n",
      "Training accuracy is  0.900390625\n",
      "Epoch  1090 Loss  0.18423308432102203\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  1100 Loss  0.19052754342556\n",
      "Training accuracy is  0.9084284855769231\n",
      "Epoch  1110 Loss  0.18691636621952057\n",
      "Training accuracy is  0.9000150240384616\n",
      "Epoch  1120 Loss  0.18605579435825348\n",
      "Training accuracy is  0.9009915865384616\n",
      "Epoch  1130 Loss  0.18455770611763\n",
      "Training accuracy is  0.9003155048076923\n",
      "Epoch  1140 Loss  0.18486692011356354\n",
      "Training accuracy is  0.900390625\n",
      "Epoch  1150 Loss  0.1858372539281845\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  1160 Loss  0.18459166586399078\n",
      "Training accuracy is  0.9005408653846154\n",
      "Epoch  1170 Loss  0.18525372445583344\n",
      "Training accuracy is  0.9012169471153846\n",
      "Epoch  1180 Loss  0.18469016253948212\n",
      "Training accuracy is  0.9008413461538461\n",
      "Epoch  1190 Loss  0.18548597395420074\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  1200 Loss  0.18383942544460297\n",
      "Training accuracy is  0.9006159855769231\n",
      "Epoch  1210 Loss  0.1843247264623642\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  1220 Loss  0.18522170186042786\n",
      "Training accuracy is  0.9008413461538461\n",
      "Epoch  1230 Loss  0.18576505780220032\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  1240 Loss  0.18279686570167542\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  1250 Loss  0.19012655317783356\n",
      "Training accuracy is  0.9067007211538461\n",
      "Epoch  1260 Loss  0.18326815962791443\n",
      "Training accuracy is  0.900390625\n",
      "Epoch  1270 Loss  0.18350228667259216\n",
      "Training accuracy is  0.9006159855769231\n",
      "Epoch  1280 Loss  0.18297435343265533\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  1290 Loss  0.1875743567943573\n",
      "Training accuracy is  0.9013671875\n",
      "Epoch  1300 Loss  0.18561317026615143\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  1310 Loss  0.18222568929195404\n",
      "Training accuracy is  0.9008413461538461\n",
      "Epoch  1320 Loss  0.18771450221538544\n",
      "Training accuracy is  0.9048227163461539\n",
      "Epoch  1330 Loss  0.18187019228935242\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  1340 Loss  0.18721753358840942\n",
      "Training accuracy is  0.9002403846153846\n",
      "Epoch  1350 Loss  0.18162639439105988\n",
      "Training accuracy is  0.9008413461538461\n",
      "Epoch  1360 Loss  0.18709376454353333\n",
      "Training accuracy is  0.9046724759615384\n",
      "Epoch  1370 Loss  0.18134988844394684\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  1380 Loss  0.18696686625480652\n",
      "Training accuracy is  0.9001652644230769\n",
      "Epoch  1390 Loss  0.18132638931274414\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  1400 Loss  0.18420197069644928\n",
      "Training accuracy is  0.9013671875\n",
      "Epoch  1410 Loss  0.18101266026496887\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  1420 Loss  0.189886674284935\n",
      "Training accuracy is  0.9000150240384616\n",
      "Epoch  1430 Loss  0.18321368098258972\n",
      "Training accuracy is  0.9037710336538461\n",
      "Epoch  1440 Loss  0.18067510426044464\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  1450 Loss  0.18458649516105652\n",
      "Training accuracy is  0.900390625\n",
      "Epoch  1460 Loss  0.18089351058006287\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  1470 Loss  0.18062306940555573\n",
      "Training accuracy is  0.9009915865384616\n",
      "Epoch  1480 Loss  0.19084757566452026\n",
      "Training accuracy is  0.9088040865384616\n",
      "Epoch  1490 Loss  0.18544088304042816\n",
      "Training accuracy is  0.900390625\n",
      "Epoch  1500 Loss  0.18189303576946259\n",
      "Training accuracy is  0.9025691105769231\n",
      "Epoch  1510 Loss  0.1812264770269394\n",
      "Training accuracy is  0.9010667067307693\n",
      "Epoch  1520 Loss  0.18028734624385834\n",
      "Training accuracy is  0.9009915865384616\n",
      "Epoch  1530 Loss  0.1908016800880432\n",
      "Training accuracy is  0.9124849759615384\n",
      "Epoch  1540 Loss  0.18377672135829926\n",
      "Training accuracy is  0.900390625\n",
      "Epoch  1550 Loss  0.17953014373779297\n",
      "Training accuracy is  0.9008413461538461\n",
      "Epoch  1560 Loss  0.18605446815490723\n",
      "Training accuracy is  0.9115835336538461\n",
      "Epoch  1570 Loss  0.17942048609256744\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  1580 Loss  0.18245524168014526\n",
      "Training accuracy is  0.9004657451923077\n",
      "Epoch  1590 Loss  0.17950084805488586\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  1600 Loss  0.18549790978431702\n",
      "Training accuracy is  0.9096304086538461\n",
      "Epoch  1610 Loss  0.17893502116203308\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  1620 Loss  0.18195751309394836\n",
      "Training accuracy is  0.9004657451923077\n",
      "Epoch  1630 Loss  0.17904745042324066\n",
      "Training accuracy is  0.9008413461538461\n",
      "Epoch  1640 Loss  0.18514445424079895\n",
      "Training accuracy is  0.9078275240384616\n",
      "Epoch  1650 Loss  0.17849312722682953\n",
      "Training accuracy is  0.9008413461538461\n",
      "Epoch  1660 Loss  0.18520832061767578\n",
      "Training accuracy is  0.900390625\n",
      "Epoch  1670 Loss  0.17828525602817535\n",
      "Training accuracy is  0.9009915865384616\n",
      "Epoch  1680 Loss  0.18514877557754517\n",
      "Training accuracy is  0.9086538461538461\n",
      "Epoch  1690 Loss  0.17807579040527344\n",
      "Training accuracy is  0.9008413461538461\n",
      "Epoch  1700 Loss  0.18450047075748444\n",
      "Training accuracy is  0.900390625\n",
      "Epoch  1710 Loss  0.17788466811180115\n",
      "Training accuracy is  0.9009915865384616\n",
      "Epoch  1720 Loss  0.18401457369327545\n",
      "Training accuracy is  0.9075270432692307\n",
      "Epoch  1730 Loss  0.17776301503181458\n",
      "Training accuracy is  0.9008413461538461\n",
      "Epoch  1740 Loss  0.187063530087471\n",
      "Training accuracy is  0.900390625\n",
      "Epoch  1750 Loss  0.17764312028884888\n",
      "Training accuracy is  0.9012920673076923\n",
      "Epoch  1760 Loss  0.18538036942481995\n",
      "Training accuracy is  0.9126352163461539\n",
      "Epoch  1770 Loss  0.1773536205291748\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  1780 Loss  0.1827743947505951\n",
      "Training accuracy is  0.9004657451923077\n",
      "Epoch  1790 Loss  0.17721182107925415\n",
      "Training accuracy is  0.9009915865384616\n",
      "Epoch  1800 Loss  0.18588823080062866\n",
      "Training accuracy is  0.9221754807692307\n",
      "Epoch  1810 Loss  0.17695492506027222\n",
      "Training accuracy is  0.9009915865384616\n",
      "Epoch  1820 Loss  0.17760907113552094\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  1830 Loss  0.17956234514713287\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  1840 Loss  0.18688057363033295\n",
      "Training accuracy is  0.9259314903846154\n",
      "Epoch  1850 Loss  0.17668978869915009\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  1860 Loss  0.18333980441093445\n",
      "Training accuracy is  0.9006159855769231\n",
      "Epoch  1870 Loss  0.1764315962791443\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  1880 Loss  0.17860294878482819\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  1890 Loss  0.17663942277431488\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  1900 Loss  0.18671567738056183\n",
      "Training accuracy is  0.9288611778846154\n",
      "Epoch  1910 Loss  0.1758355349302292\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  1920 Loss  0.1848629266023636\n",
      "Training accuracy is  0.9004657451923077\n",
      "Epoch  1930 Loss  0.17568951845169067\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  1940 Loss  0.18107618391513824\n",
      "Training accuracy is  0.9264573317307693\n",
      "Epoch  1950 Loss  0.17587968707084656\n",
      "Training accuracy is  0.9010667067307693\n",
      "Epoch  1960 Loss  0.18157292902469635\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  1970 Loss  0.17565247416496277\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  1980 Loss  0.17617103457450867\n",
      "Training accuracy is  0.9043719951923077\n",
      "Epoch  1990 Loss  0.18008679151535034\n",
      "Training accuracy is  0.9054236778846154\n",
      "Epoch  2000 Loss  0.17838963866233826\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  2010 Loss  0.1762235462665558\n",
      "Training accuracy is  0.9008413461538461\n",
      "Epoch  2020 Loss  0.17470256984233856\n",
      "Training accuracy is  0.9010667067307693\n",
      "Epoch  2030 Loss  0.18866698443889618\n",
      "Training accuracy is  0.9495943509615384\n",
      "Epoch  2040 Loss  0.17503085732460022\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  2050 Loss  0.17790187895298004\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  2060 Loss  0.1768181025981903\n",
      "Training accuracy is  0.9094801682692307\n",
      "Epoch  2070 Loss  0.1772158294916153\n",
      "Training accuracy is  0.9045973557692307\n",
      "Epoch  2080 Loss  0.1741299331188202\n",
      "Training accuracy is  0.9013671875\n",
      "Epoch  2090 Loss  0.18129943311214447\n",
      "Training accuracy is  0.953125\n",
      "Epoch  2100 Loss  0.17389392852783203\n",
      "Training accuracy is  0.9009915865384616\n",
      "Epoch  2110 Loss  0.18069323897361755\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  2120 Loss  0.17469476163387299\n",
      "Training accuracy is  0.9051231971153846\n",
      "Epoch  2130 Loss  0.18037840723991394\n",
      "Training accuracy is  0.9110576923076923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2140 Loss  0.17379529774188995\n",
      "Training accuracy is  0.9027193509615384\n",
      "Epoch  2150 Loss  0.18987873196601868\n",
      "Training accuracy is  0.9516977163461539\n",
      "Epoch  2160 Loss  0.17339619994163513\n",
      "Training accuracy is  0.9014423076923077\n",
      "Epoch  2170 Loss  0.17593011260032654\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  2180 Loss  0.17401543259620667\n",
      "Training accuracy is  0.9009915865384616\n",
      "Epoch  2190 Loss  0.18079319596290588\n",
      "Training accuracy is  0.9501953125\n",
      "Epoch  2200 Loss  0.17340177297592163\n",
      "Training accuracy is  0.90234375\n",
      "Epoch  2210 Loss  0.1731460839509964\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  2220 Loss  0.18133462965488434\n",
      "Training accuracy is  0.9007662259615384\n",
      "Epoch  2230 Loss  0.1728476583957672\n",
      "Training accuracy is  0.9027193509615384\n",
      "Epoch  2240 Loss  0.18638035655021667\n",
      "Training accuracy is  0.9302133413461539\n",
      "Epoch  2250 Loss  0.1726749837398529\n",
      "Training accuracy is  0.9012169471153846\n",
      "Epoch  2260 Loss  0.18708902597427368\n",
      "Training accuracy is  0.9006911057692307\n",
      "Epoch  2270 Loss  0.1721828579902649\n",
      "Training accuracy is  0.9020432692307693\n",
      "Epoch  2280 Loss  0.19655944406986237\n",
      "Training accuracy is  0.9556790865384616\n",
      "Epoch  2290 Loss  0.17202505469322205\n",
      "Training accuracy is  0.9021183894230769\n",
      "Epoch  2300 Loss  0.1798836588859558\n",
      "Training accuracy is  0.9592848557692307\n",
      "Epoch  2310 Loss  0.17188435792922974\n",
      "Training accuracy is  0.9018179086538461\n",
      "Epoch  2320 Loss  0.18335913121700287\n",
      "Training accuracy is  0.9006159855769231\n",
      "Epoch  2330 Loss  0.17167800664901733\n",
      "Training accuracy is  0.90234375\n",
      "Epoch  2340 Loss  0.18821503221988678\n",
      "Training accuracy is  0.9572566105769231\n",
      "Epoch  2350 Loss  0.17261725664138794\n",
      "Training accuracy is  0.9069260817307693\n",
      "Epoch  2360 Loss  0.1791570782661438\n",
      "Training accuracy is  0.9180438701923077\n",
      "Epoch  2370 Loss  0.1728057861328125\n",
      "Training accuracy is  0.9097806490384616\n",
      "Epoch  2380 Loss  0.17665995657444\n",
      "Training accuracy is  0.9130108173076923\n",
      "Epoch  2390 Loss  0.17461635172367096\n",
      "Training accuracy is  0.9246544471153846\n",
      "Epoch  2400 Loss  0.174056738615036\n",
      "Training accuracy is  0.9091045673076923\n",
      "Epoch  2410 Loss  0.17859217524528503\n",
      "Training accuracy is  0.9493689903846154\n",
      "Epoch  2420 Loss  0.17286428809165955\n",
      "Training accuracy is  0.908203125\n",
      "Epoch  2430 Loss  0.1822357028722763\n",
      "Training accuracy is  0.9546274038461539\n",
      "Epoch  2440 Loss  0.17271463572978973\n",
      "Training accuracy is  0.9097055288461539\n",
      "Epoch  2450 Loss  0.18075944483280182\n",
      "Training accuracy is  0.9437349759615384\n",
      "Epoch  2460 Loss  0.1737145036458969\n",
      "Training accuracy is  0.9164663461538461\n",
      "Epoch  2470 Loss  0.1770554929971695\n",
      "Training accuracy is  0.9255558894230769\n",
      "Epoch  2480 Loss  0.17554116249084473\n",
      "Training accuracy is  0.9322415865384616\n",
      "Epoch  2490 Loss  0.17470945417881012\n",
      "Training accuracy is  0.9169170673076923\n",
      "Epoch  2500 Loss  0.17780305445194244\n",
      "Training accuracy is  0.9419320913461539\n",
      "Epoch  2510 Loss  0.17383810877799988\n",
      "Training accuracy is  0.9174429086538461\n",
      "Epoch  2520 Loss  0.17860165238380432\n",
      "Training accuracy is  0.9437349759615384\n",
      "Epoch  2530 Loss  0.17395499348640442\n",
      "Training accuracy is  0.9223257211538461\n",
      "Epoch  2540 Loss  0.17734120786190033\n",
      "Training accuracy is  0.9341195913461539\n",
      "Epoch  2550 Loss  0.17487746477127075\n",
      "Training accuracy is  0.9308894230769231\n",
      "Epoch  2560 Loss  0.17496497929096222\n",
      "Training accuracy is  0.9242788461538461\n",
      "Epoch  2570 Loss  0.17647995054721832\n",
      "Training accuracy is  0.9418569711538461\n",
      "Epoch  2580 Loss  0.17352770268917084\n",
      "Training accuracy is  0.9196965144230769\n",
      "Epoch  2590 Loss  0.17765332758426666\n",
      "Training accuracy is  0.9443359375\n",
      "Epoch  2600 Loss  0.17386220395565033\n",
      "Training accuracy is  0.9264573317307693\n",
      "Epoch  2610 Loss  0.17655692994594574\n",
      "Training accuracy is  0.9375\n",
      "Epoch  2620 Loss  0.173992320895195\n",
      "Training accuracy is  0.9307391826923077\n",
      "Epoch  2630 Loss  0.17497605085372925\n",
      "Training accuracy is  0.9304387019230769\n",
      "Epoch  2640 Loss  0.17527982592582703\n",
      "Training accuracy is  0.9398287259615384\n",
      "Epoch  2650 Loss  0.17371247708797455\n",
      "Training accuracy is  0.9260817307692307\n",
      "Epoch  2660 Loss  0.1759309619665146\n",
      "Training accuracy is  0.9429837740384616\n",
      "Epoch  2670 Loss  0.17387573421001434\n",
      "Training accuracy is  0.9326171875\n",
      "Epoch  2680 Loss  0.17518183588981628\n",
      "Training accuracy is  0.9378004807692307\n",
      "Epoch  2690 Loss  0.17453894019126892\n",
      "Training accuracy is  0.9373497596153846\n",
      "Epoch  2700 Loss  0.17444632947444916\n",
      "Training accuracy is  0.9367487980769231\n",
      "Epoch  2710 Loss  0.1748296320438385\n",
      "Training accuracy is  0.9382512019230769\n",
      "Epoch  2720 Loss  0.17447713017463684\n",
      "Training accuracy is  0.9399038461538461\n",
      "Epoch  2730 Loss  0.17421802878379822\n",
      "Training accuracy is  0.9359224759615384\n",
      "Epoch  2740 Loss  0.17499282956123352\n",
      "Training accuracy is  0.9434344951923077\n",
      "Epoch  2750 Loss  0.17371346056461334\n",
      "Training accuracy is  0.9354717548076923\n",
      "Epoch  2760 Loss  0.17509055137634277\n",
      "Training accuracy is  0.9446364182692307\n",
      "Epoch  2770 Loss  0.17349942028522491\n",
      "Training accuracy is  0.9362980769230769\n",
      "Epoch  2780 Loss  0.17484606802463531\n",
      "Training accuracy is  0.9440354567307693\n",
      "Epoch  2790 Loss  0.17376708984375\n",
      "Training accuracy is  0.9396784855769231\n",
      "Epoch  2800 Loss  0.17451056838035583\n",
      "Training accuracy is  0.9429837740384616\n",
      "Epoch  2810 Loss  0.17385408282279968\n",
      "Training accuracy is  0.9403545673076923\n",
      "Epoch  2820 Loss  0.17447367310523987\n",
      "Training accuracy is  0.9447115384615384\n",
      "Epoch  2830 Loss  0.17348453402519226\n",
      "Training accuracy is  0.9399789663461539\n",
      "Epoch  2840 Loss  0.17461195588111877\n",
      "Training accuracy is  0.9469651442307693\n",
      "Epoch  2850 Loss  0.17321020364761353\n",
      "Training accuracy is  0.9404296875\n",
      "Epoch  2860 Loss  0.17436382174491882\n",
      "Training accuracy is  0.9460637019230769\n",
      "Epoch  2870 Loss  0.17327505350112915\n",
      "Training accuracy is  0.9423076923076923\n",
      "Epoch  2880 Loss  0.17398713529109955\n",
      "Training accuracy is  0.9459134615384616\n",
      "Epoch  2890 Loss  0.1731589436531067\n",
      "Training accuracy is  0.943359375\n",
      "Epoch  2900 Loss  0.17353346943855286\n",
      "Training accuracy is  0.9460637019230769\n",
      "Epoch  2910 Loss  0.1730249524116516\n",
      "Training accuracy is  0.9463641826923077\n",
      "Epoch  2920 Loss  0.17321999371051788\n",
      "Training accuracy is  0.9445612980769231\n",
      "Epoch  2930 Loss  0.17323435842990875\n",
      "Training accuracy is  0.9481670673076923\n",
      "Epoch  2940 Loss  0.17272496223449707\n",
      "Training accuracy is  0.9438852163461539\n",
      "Epoch  2950 Loss  0.17336639761924744\n",
      "Training accuracy is  0.9485426682692307\n",
      "Epoch  2960 Loss  0.17280545830726624\n",
      "Training accuracy is  0.9453876201923077\n",
      "Epoch  2970 Loss  0.1734326034784317\n",
      "Training accuracy is  0.9497445913461539\n",
      "Epoch  2980 Loss  0.17272475361824036\n",
      "Training accuracy is  0.9463641826923077\n",
      "Epoch  2990 Loss  0.1734210103750229\n",
      "Training accuracy is  0.9507211538461539\n",
      "Epoch  3000 Loss  0.1726069301366806\n",
      "Training accuracy is  0.9034705528846154\n",
      "Epoch  3010 Loss  0.16795095801353455\n",
      "Training accuracy is  0.9030949519230769\n",
      "Epoch  3020 Loss  0.1658727526664734\n",
      "Training accuracy is  0.9056490384615384\n",
      "Epoch  3030 Loss  0.16513265669345856\n",
      "Training accuracy is  0.9027944711538461\n",
      "Epoch  3040 Loss  0.16490820050239563\n",
      "Training accuracy is  0.9054987980769231\n",
      "Epoch  3050 Loss  0.16482946276664734\n",
      "Training accuracy is  0.9039963942307693\n",
      "Epoch  3060 Loss  0.16473720967769623\n",
      "Training accuracy is  0.9046724759615384\n",
      "Epoch  3070 Loss  0.16462799906730652\n",
      "Training accuracy is  0.9048227163461539\n",
      "Epoch  3080 Loss  0.1645241379737854\n",
      "Training accuracy is  0.9046724759615384\n",
      "Epoch  3090 Loss  0.16442367434501648\n",
      "Training accuracy is  0.9046724759615384\n",
      "Epoch  3100 Loss  0.16432741284370422\n",
      "Training accuracy is  0.9047475961538461\n",
      "Epoch  3110 Loss  0.1642313003540039\n",
      "Training accuracy is  0.9047475961538461\n",
      "Epoch  3120 Loss  0.16413475573062897\n",
      "Training accuracy is  0.9047475961538461\n",
      "Epoch  3130 Loss  0.16403859853744507\n",
      "Training accuracy is  0.9048978365384616\n",
      "Epoch  3140 Loss  0.16394248604774475\n",
      "Training accuracy is  0.9048978365384616\n",
      "Epoch  3150 Loss  0.16384628415107727\n",
      "Training accuracy is  0.9048978365384616\n",
      "Epoch  3160 Loss  0.16374953091144562\n",
      "Training accuracy is  0.9049729567307693\n",
      "Epoch  3170 Loss  0.16365203261375427\n",
      "Training accuracy is  0.9049729567307693\n",
      "Epoch  3180 Loss  0.16355349123477936\n",
      "Training accuracy is  0.9050480769230769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3190 Loss  0.16345348954200745\n",
      "Training accuracy is  0.9050480769230769\n",
      "Epoch  3200 Loss  0.16335047781467438\n",
      "Training accuracy is  0.9051231971153846\n",
      "Epoch  3210 Loss  0.16324934363365173\n",
      "Training accuracy is  0.9051983173076923\n",
      "Epoch  3220 Loss  0.16314846277236938\n",
      "Training accuracy is  0.9052734375\n",
      "Epoch  3230 Loss  0.16304650902748108\n",
      "Training accuracy is  0.9052734375\n",
      "Epoch  3240 Loss  0.16294516623020172\n",
      "Training accuracy is  0.9052734375\n",
      "Epoch  3250 Loss  0.16284415125846863\n",
      "Training accuracy is  0.9053485576923077\n",
      "Epoch  3260 Loss  0.16274197399616241\n",
      "Training accuracy is  0.9054987980769231\n",
      "Epoch  3270 Loss  0.16263970732688904\n",
      "Training accuracy is  0.9054987980769231\n",
      "Epoch  3280 Loss  0.16253754496574402\n",
      "Training accuracy is  0.9055739182692307\n",
      "Epoch  3290 Loss  0.1624351143836975\n",
      "Training accuracy is  0.9055739182692307\n",
      "Epoch  3300 Loss  0.16233213245868683\n",
      "Training accuracy is  0.9055739182692307\n",
      "Epoch  3310 Loss  0.16222865879535675\n",
      "Training accuracy is  0.9055739182692307\n",
      "Epoch  3320 Loss  0.16212481260299683\n",
      "Training accuracy is  0.9057241586538461\n",
      "Epoch  3330 Loss  0.16202053427696228\n",
      "Training accuracy is  0.9057241586538461\n",
      "Epoch  3340 Loss  0.1619158536195755\n",
      "Training accuracy is  0.9057992788461539\n",
      "Epoch  3350 Loss  0.1618107259273529\n",
      "Training accuracy is  0.9057992788461539\n",
      "Epoch  3360 Loss  0.16170556843280792\n",
      "Training accuracy is  0.9057992788461539\n",
      "Epoch  3370 Loss  0.16159923374652863\n",
      "Training accuracy is  0.9057992788461539\n",
      "Epoch  3380 Loss  0.16149264574050903\n",
      "Training accuracy is  0.9059495192307693\n",
      "Epoch  3390 Loss  0.1613852083683014\n",
      "Training accuracy is  0.9059495192307693\n",
      "Epoch  3400 Loss  0.16127687692642212\n",
      "Training accuracy is  0.9060246394230769\n",
      "Epoch  3410 Loss  0.16116705536842346\n",
      "Training accuracy is  0.9060997596153846\n",
      "Epoch  3420 Loss  0.16105613112449646\n",
      "Training accuracy is  0.9060997596153846\n",
      "Epoch  3430 Loss  0.16094398498535156\n",
      "Training accuracy is  0.9060246394230769\n",
      "Epoch  3440 Loss  0.16083112359046936\n",
      "Training accuracy is  0.9060997596153846\n",
      "Epoch  3450 Loss  0.160719633102417\n",
      "Training accuracy is  0.90625\n",
      "Epoch  3460 Loss  0.16060352325439453\n",
      "Training accuracy is  0.9064002403846154\n",
      "Epoch  3470 Loss  0.16048966348171234\n",
      "Training accuracy is  0.9064753605769231\n",
      "Epoch  3480 Loss  0.16037820279598236\n",
      "Training accuracy is  0.9064753605769231\n",
      "Epoch  3490 Loss  0.16026368737220764\n",
      "Training accuracy is  0.9064002403846154\n",
      "Epoch  3500 Loss  0.16015681624412537\n",
      "Training accuracy is  0.9067758413461539\n",
      "Epoch  3510 Loss  0.16004036366939545\n",
      "Training accuracy is  0.9073016826923077\n",
      "Epoch  3520 Loss  0.15997323393821716\n",
      "Training accuracy is  0.9075270432692307\n",
      "Epoch  3530 Loss  0.15979918837547302\n",
      "Training accuracy is  0.9068509615384616\n",
      "Epoch  3540 Loss  0.15982668101787567\n",
      "Training accuracy is  0.9060246394230769\n",
      "Epoch  3550 Loss  0.15956434607505798\n",
      "Training accuracy is  0.9079026442307693\n",
      "Epoch  3560 Loss  0.15945564210414886\n",
      "Training accuracy is  0.9071514423076923\n",
      "Epoch  3570 Loss  0.1593347191810608\n",
      "Training accuracy is  0.9068509615384616\n",
      "Epoch  3580 Loss  0.15990249812602997\n",
      "Training accuracy is  0.9031700721153846\n",
      "Epoch  3590 Loss  0.16396571695804596\n",
      "Training accuracy is  0.9019681490384616\n",
      "Epoch  3600 Loss  0.16275998950004578\n",
      "Training accuracy is  0.9474158653846154\n",
      "Epoch  3610 Loss  0.15946060419082642\n",
      "Training accuracy is  0.9114332932692307\n",
      "Epoch  3620 Loss  0.15921160578727722\n",
      "Training accuracy is  0.904296875\n",
      "Epoch  3630 Loss  0.1664232313632965\n",
      "Training accuracy is  0.9011418269230769\n",
      "Epoch  3640 Loss  0.15865442156791687\n",
      "Training accuracy is  0.9113581730769231\n",
      "Epoch  3650 Loss  0.16538630425930023\n",
      "Training accuracy is  0.9589092548076923\n",
      "Epoch  3660 Loss  0.15871866047382355\n",
      "Training accuracy is  0.9112079326923077\n",
      "Epoch  3670 Loss  0.15919335186481476\n",
      "Training accuracy is  0.9045222355769231\n",
      "Epoch  3680 Loss  0.1652471423149109\n",
      "Training accuracy is  0.9013671875\n",
      "Epoch  3690 Loss  0.15815486013889313\n",
      "Training accuracy is  0.9109074519230769\n",
      "Epoch  3700 Loss  0.16471344232559204\n",
      "Training accuracy is  0.9606370192307693\n",
      "Epoch  3710 Loss  0.158386692404747\n",
      "Training accuracy is  0.9126352163461539\n",
      "Epoch  3720 Loss  0.15911632776260376\n",
      "Training accuracy is  0.9027193509615384\n",
      "Epoch  3730 Loss  0.16221970319747925\n",
      "Training accuracy is  0.9021935096153846\n",
      "Epoch  3740 Loss  0.15792328119277954\n",
      "Training accuracy is  0.9175931490384616\n",
      "Epoch  3750 Loss  0.1658526062965393\n",
      "Training accuracy is  0.9616887019230769\n",
      "Epoch  3760 Loss  0.15750378370285034\n",
      "Training accuracy is  0.91015625\n",
      "Epoch  3770 Loss  0.1581602841615677\n",
      "Training accuracy is  0.9036959134615384\n",
      "Epoch  3780 Loss  0.16298255324363708\n",
      "Training accuracy is  0.9018930288461539\n",
      "Epoch  3790 Loss  0.15829230844974518\n",
      "Training accuracy is  0.9327674278846154\n",
      "Epoch  3800 Loss  0.16171853244304657\n",
      "Training accuracy is  0.9459885817307693\n",
      "Epoch  3810 Loss  0.15690793097019196\n",
      "Training accuracy is  0.9102313701923077\n",
      "Epoch  3820 Loss  0.15704043209552765\n",
      "Training accuracy is  0.9084284855769231\n",
      "Epoch  3830 Loss  0.15854154527187347\n",
      "Training accuracy is  0.9021183894230769\n",
      "Epoch  3840 Loss  0.15776656568050385\n",
      "Training accuracy is  0.9079777644230769\n",
      "Epoch  3850 Loss  0.16577696800231934\n",
      "Training accuracy is  0.9642427884615384\n",
      "Epoch  3860 Loss  0.1564197838306427\n",
      "Training accuracy is  0.9072265625\n",
      "Epoch  3870 Loss  0.16152551770210266\n",
      "Training accuracy is  0.9013671875\n",
      "Epoch  3880 Loss  0.156948983669281\n",
      "Training accuracy is  0.90625\n",
      "Epoch  3890 Loss  0.1560521274805069\n",
      "Training accuracy is  0.9093299278846154\n",
      "Epoch  3900 Loss  0.15598240494728088\n",
      "Training accuracy is  0.9079026442307693\n",
      "Epoch  3910 Loss  0.17087452113628387\n",
      "Training accuracy is  0.9009164663461539\n",
      "Epoch  3920 Loss  0.15914584696292877\n",
      "Training accuracy is  0.9581580528846154\n",
      "Epoch  3930 Loss  0.15614654123783112\n",
      "Training accuracy is  0.9134615384615384\n",
      "Epoch  3940 Loss  0.16000677645206451\n",
      "Training accuracy is  0.9016676682692307\n",
      "Epoch  3950 Loss  0.15659116208553314\n",
      "Training accuracy is  0.9056490384615384\n",
      "Epoch  3960 Loss  0.15608333051204681\n",
      "Training accuracy is  0.9054236778846154\n",
      "Epoch  3970 Loss  0.16311289370059967\n",
      "Training accuracy is  0.9013671875\n",
      "Epoch  3980 Loss  0.15514184534549713\n",
      "Training accuracy is  0.9118840144230769\n",
      "Epoch  3990 Loss  0.1590738445520401\n",
      "Training accuracy is  0.9592097355769231\n",
      "Epoch  4000 Loss  0.156606063246727\n",
      "Training accuracy is  0.9265324519230769\n",
      "Epoch  4010 Loss  0.15532079339027405\n",
      "Training accuracy is  0.9059495192307693\n",
      "Epoch  4020 Loss  0.1639184057712555\n",
      "Training accuracy is  0.9012920673076923\n",
      "Epoch  4030 Loss  0.15463247895240784\n",
      "Training accuracy is  0.9120342548076923\n",
      "Epoch  4040 Loss  0.15832877159118652\n",
      "Training accuracy is  0.9591346153846154\n",
      "Epoch  4050 Loss  0.15630000829696655\n",
      "Training accuracy is  0.9293870192307693\n",
      "Epoch  4060 Loss  0.1545964926481247\n",
      "Training accuracy is  0.9085036057692307\n",
      "Epoch  4070 Loss  0.16085408627986908\n",
      "Training accuracy is  0.9012920673076923\n",
      "Epoch  4080 Loss  0.15450304746627808\n",
      "Training accuracy is  0.9114332932692307\n",
      "Epoch  4090 Loss  0.15833571553230286\n",
      "Training accuracy is  0.9610877403846154\n",
      "Epoch  4100 Loss  0.15590201318264008\n",
      "Training accuracy is  0.9323918269230769\n",
      "Epoch  4110 Loss  0.1538059115409851\n",
      "Training accuracy is  0.9127854567307693\n",
      "Epoch  4120 Loss  0.15366962552070618\n",
      "Training accuracy is  0.9125600961538461\n",
      "Epoch  4130 Loss  0.15421254932880402\n",
      "Training accuracy is  0.935546875\n",
      "Epoch  4140 Loss  0.1570839136838913\n",
      "Training accuracy is  0.9341947115384616\n",
      "Epoch  4150 Loss  0.16385620832443237\n",
      "Training accuracy is  0.9012169471153846\n",
      "Epoch  4160 Loss  0.15331970155239105\n",
      "Training accuracy is  0.9220252403846154\n",
      "Epoch  4170 Loss  0.16325093805789948\n",
      "Training accuracy is  0.9679236778846154\n",
      "Epoch  4180 Loss  0.15330909192562103\n",
      "Training accuracy is  0.9186448317307693\n",
      "Epoch  4190 Loss  0.15398284792900085\n",
      "Training accuracy is  0.939453125\n",
      "Epoch  4200 Loss  0.16075246036052704\n",
      "Training accuracy is  0.9592097355769231\n",
      "Epoch  4210 Loss  0.15285907685756683\n",
      "Training accuracy is  0.9092548076923077\n",
      "Epoch  4220 Loss  0.16175341606140137\n",
      "Training accuracy is  0.9012920673076923\n",
      "Epoch  4230 Loss  0.15279223024845123\n",
      "Training accuracy is  0.9108323317307693\n",
      "Epoch  4240 Loss  0.15277937054634094\n",
      "Training accuracy is  0.9208984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4250 Loss  0.16146515309810638\n",
      "Training accuracy is  0.9680739182692307\n",
      "Epoch  4260 Loss  0.15255852043628693\n",
      "Training accuracy is  0.9154897836538461\n",
      "Epoch  4270 Loss  0.15931569039821625\n",
      "Training accuracy is  0.9013671875\n",
      "Epoch  4280 Loss  0.15269966423511505\n",
      "Training accuracy is  0.9100060096153846\n",
      "Epoch  4290 Loss  0.1519550383090973\n",
      "Training accuracy is  0.9124849759615384\n",
      "Epoch  4300 Loss  0.15469162166118622\n",
      "Training accuracy is  0.9027944711538461\n",
      "Epoch  4310 Loss  0.1526883989572525\n",
      "Training accuracy is  0.9106069711538461\n",
      "Epoch  4320 Loss  0.15921901166439056\n",
      "Training accuracy is  0.9701772836538461\n",
      "Epoch  4330 Loss  0.15222761034965515\n",
      "Training accuracy is  0.9266826923076923\n",
      "Epoch  4340 Loss  0.15139266848564148\n",
      "Training accuracy is  0.9124849759615384\n",
      "Epoch  4350 Loss  0.15793929994106293\n",
      "Training accuracy is  0.9013671875\n",
      "Epoch  4360 Loss  0.15154635906219482\n",
      "Training accuracy is  0.9131610576923077\n",
      "Epoch  4370 Loss  0.15654468536376953\n",
      "Training accuracy is  0.9685246394230769\n",
      "Epoch  4380 Loss  0.15229026973247528\n",
      "Training accuracy is  0.9333683894230769\n",
      "Epoch  4390 Loss  0.1509651392698288\n",
      "Training accuracy is  0.9212740384615384\n",
      "Epoch  4400 Loss  0.16090510785579681\n",
      "Training accuracy is  0.9684495192307693\n",
      "Epoch  4410 Loss  0.15091504156589508\n",
      "Training accuracy is  0.9201472355769231\n",
      "Epoch  4420 Loss  0.15438136458396912\n",
      "Training accuracy is  0.9027193509615384\n",
      "Epoch  4430 Loss  0.15209807455539703\n",
      "Training accuracy is  0.9079777644230769\n",
      "Epoch  4440 Loss  0.15082219243049622\n",
      "Training accuracy is  0.9115835336538461\n",
      "Epoch  4450 Loss  0.16235797107219696\n",
      "Training accuracy is  0.9012920673076923\n",
      "Epoch  4460 Loss  0.15015196800231934\n",
      "Training accuracy is  0.9175180288461539\n",
      "Epoch  4470 Loss  0.15561887621879578\n",
      "Training accuracy is  0.9696514423076923\n",
      "Epoch  4480 Loss  0.15120133757591248\n",
      "Training accuracy is  0.9344951923076923\n",
      "Epoch  4490 Loss  0.14982661604881287\n",
      "Training accuracy is  0.9180438701923077\n",
      "Epoch  4500 Loss  0.1498730629682541\n",
      "Training accuracy is  0.9189453125\n",
      "Epoch  4510 Loss  0.1505761593580246\n",
      "Training accuracy is  0.9440354567307693\n",
      "Epoch  4520 Loss  0.1531020849943161\n",
      "Training accuracy is  0.9435096153846154\n",
      "Epoch  4530 Loss  0.15690848231315613\n",
      "Training accuracy is  0.9014423076923077\n",
      "Epoch  4540 Loss  0.1494760662317276\n",
      "Training accuracy is  0.9157151442307693\n",
      "Epoch  4550 Loss  0.15712425112724304\n",
      "Training accuracy is  0.9701772836538461\n",
      "Epoch  4560 Loss  0.150035560131073\n",
      "Training accuracy is  0.9341947115384616\n",
      "Epoch  4570 Loss  0.1496780961751938\n",
      "Training accuracy is  0.9418569711538461\n",
      "Epoch  4580 Loss  0.16023889183998108\n",
      "Training accuracy is  0.9689002403846154\n",
      "Epoch  4590 Loss  0.1490182876586914\n",
      "Training accuracy is  0.9302133413461539\n",
      "Epoch  4600 Loss  0.16083924472332\n",
      "Training accuracy is  0.96875\n",
      "Epoch  4610 Loss  0.14920157194137573\n",
      "Training accuracy is  0.9331430288461539\n",
      "Epoch  4620 Loss  0.15098562836647034\n",
      "Training accuracy is  0.9607872596153846\n",
      "Epoch  4630 Loss  0.15213309228420258\n",
      "Training accuracy is  0.9518479567307693\n",
      "Epoch  4640 Loss  0.14863929152488708\n",
      "Training accuracy is  0.9364483173076923\n",
      "Epoch  4650 Loss  0.16473887860774994\n",
      "Training accuracy is  0.9695763221153846\n",
      "Epoch  4660 Loss  0.14830933511257172\n",
      "Training accuracy is  0.9295372596153846\n",
      "Epoch  4670 Loss  0.15272928774356842\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  4680 Loss  0.14964237809181213\n",
      "Training accuracy is  0.9422325721153846\n",
      "Epoch  4690 Loss  0.1483592689037323\n",
      "Training accuracy is  0.9406550480769231\n",
      "Epoch  4700 Loss  0.1625182032585144\n",
      "Training accuracy is  0.9716045673076923\n",
      "Epoch  4710 Loss  0.14769980311393738\n",
      "Training accuracy is  0.9286358173076923\n",
      "Epoch  4720 Loss  0.1516713947057724\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  4730 Loss  0.1490347534418106\n",
      "Training accuracy is  0.9437349759615384\n",
      "Epoch  4740 Loss  0.14748628437519073\n",
      "Training accuracy is  0.9323167067307693\n",
      "Epoch  4750 Loss  0.16206780076026917\n",
      "Training accuracy is  0.9625150240384616\n",
      "Epoch  4760 Loss  0.1472448706626892\n",
      "Training accuracy is  0.9291616586538461\n",
      "Epoch  4770 Loss  0.14707046747207642\n",
      "Training accuracy is  0.9259314903846154\n",
      "Epoch  4780 Loss  0.15135352313518524\n",
      "Training accuracy is  0.9711538461538461\n",
      "Epoch  4790 Loss  0.1471889317035675\n",
      "Training accuracy is  0.9311147836538461\n",
      "Epoch  4800 Loss  0.1518869400024414\n",
      "Training accuracy is  0.9025691105769231\n",
      "Epoch  4810 Loss  0.14718158543109894\n",
      "Training accuracy is  0.9139873798076923\n",
      "Epoch  4820 Loss  0.14666567742824554\n",
      "Training accuracy is  0.9395282451923077\n",
      "Epoch  4830 Loss  0.16283774375915527\n",
      "Training accuracy is  0.9718299278846154\n",
      "Epoch  4840 Loss  0.14628195762634277\n",
      "Training accuracy is  0.9305138221153846\n",
      "Epoch  4850 Loss  0.15516304969787598\n",
      "Training accuracy is  0.9699519230769231\n",
      "Epoch  4860 Loss  0.14658033847808838\n",
      "Training accuracy is  0.9368990384615384\n",
      "Epoch  4870 Loss  0.1469191014766693\n",
      "Training accuracy is  0.9418569711538461\n",
      "Epoch  4880 Loss  0.1658354103565216\n",
      "Training accuracy is  0.9690504807692307\n",
      "Epoch  4890 Loss  0.14648661017417908\n",
      "Training accuracy is  0.9412560096153846\n",
      "Epoch  4900 Loss  0.1638585478067398\n",
      "Training accuracy is  0.9670222355769231\n",
      "Epoch  4910 Loss  0.1460370123386383\n",
      "Training accuracy is  0.9417067307692307\n",
      "Epoch  4920 Loss  0.15893079340457916\n",
      "Training accuracy is  0.9690504807692307\n",
      "Epoch  4930 Loss  0.146248921751976\n",
      "Training accuracy is  0.9451622596153846\n",
      "Epoch  4940 Loss  0.15579064190387726\n",
      "Training accuracy is  0.9710787259615384\n",
      "Epoch  4950 Loss  0.14658251404762268\n",
      "Training accuracy is  0.9491436298076923\n",
      "Epoch  4960 Loss  0.15404850244522095\n",
      "Training accuracy is  0.9719050480769231\n",
      "Epoch  4970 Loss  0.14691756665706635\n",
      "Training accuracy is  0.9538010817307693\n",
      "Epoch  4980 Loss  0.15277037024497986\n",
      "Training accuracy is  0.9721304086538461\n",
      "Epoch  4990 Loss  0.14719034731388092\n",
      "Training accuracy is  0.9559795673076923\n",
      "Epoch  5000 Loss  0.15131165087223053\n",
      "Training accuracy is  0.9713040865384616\n",
      "Epoch  5010 Loss  0.14773191511631012\n",
      "Training accuracy is  0.9590594951923077\n",
      "Epoch  5020 Loss  0.14996904134750366\n",
      "Training accuracy is  0.9704026442307693\n",
      "Epoch  5030 Loss  0.14827442169189453\n",
      "Training accuracy is  0.9617638221153846\n",
      "Epoch  5040 Loss  0.14883235096931458\n",
      "Training accuracy is  0.9681490384615384\n",
      "Epoch  5050 Loss  0.14931675791740417\n",
      "Training accuracy is  0.9655949519230769\n",
      "Epoch  5060 Loss  0.14788982272148132\n",
      "Training accuracy is  0.9652944711538461\n",
      "Epoch  5070 Loss  0.15044593811035156\n",
      "Training accuracy is  0.9676983173076923\n",
      "Epoch  5080 Loss  0.14730487763881683\n",
      "Training accuracy is  0.9646935096153846\n",
      "Epoch  5090 Loss  0.15086165070533752\n",
      "Training accuracy is  0.9694260817307693\n",
      "Epoch  5100 Loss  0.14666056632995605\n",
      "Training accuracy is  0.9631159855769231\n",
      "Epoch  5110 Loss  0.1513393074274063\n",
      "Training accuracy is  0.9710036057692307\n",
      "Epoch  5120 Loss  0.14666542410850525\n",
      "Training accuracy is  0.9635667067307693\n",
      "Epoch  5130 Loss  0.15151037275791168\n",
      "Training accuracy is  0.9713792067307693\n",
      "Epoch  5140 Loss  0.1462785303592682\n",
      "Training accuracy is  0.9632662259615384\n",
      "Epoch  5150 Loss  0.15139442682266235\n",
      "Training accuracy is  0.9716045673076923\n",
      "Epoch  5160 Loss  0.14621120691299438\n",
      "Training accuracy is  0.9635667067307693\n",
      "Epoch  5170 Loss  0.15041540563106537\n",
      "Training accuracy is  0.9714543269230769\n",
      "Epoch  5180 Loss  0.14731420576572418\n",
      "Training accuracy is  0.9621394230769231\n",
      "Epoch  5190 Loss  0.14467206597328186\n",
      "Training accuracy is  0.9601111778846154\n",
      "Epoch  5200 Loss  0.15247029066085815\n",
      "Training accuracy is  0.9705528846153846\n",
      "Epoch  5210 Loss  0.14574752748012543\n",
      "Training accuracy is  0.9643930288461539\n",
      "Epoch  5220 Loss  0.15133707225322723\n",
      "Training accuracy is  0.9721304086538461\n",
      "Epoch  5230 Loss  0.14574910700321198\n",
      "Training accuracy is  0.9652944711538461\n",
      "Epoch  5240 Loss  0.15039542317390442\n",
      "Training accuracy is  0.9719801682692307\n",
      "Epoch  5250 Loss  0.14561285078525543\n",
      "Training accuracy is  0.9651442307692307\n",
      "Epoch  5260 Loss  0.15022774040699005\n",
      "Training accuracy is  0.9719801682692307\n",
      "Epoch  5270 Loss  0.1453210413455963\n",
      "Training accuracy is  0.9651442307692307\n",
      "Epoch  5280 Loss  0.1499149203300476\n",
      "Training accuracy is  0.9722806490384616\n",
      "Epoch  5290 Loss  0.14522697031497955\n",
      "Training accuracy is  0.9647686298076923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5300 Loss  0.14903105795383453\n",
      "Training accuracy is  0.9723557692307693\n",
      "Epoch  5310 Loss  0.14547017216682434\n",
      "Training accuracy is  0.9658954326923077\n",
      "Epoch  5320 Loss  0.1479460448026657\n",
      "Training accuracy is  0.9725060096153846\n",
      "Epoch  5330 Loss  0.14606308937072754\n",
      "Training accuracy is  0.9679987980769231\n",
      "Epoch  5340 Loss  0.14714881777763367\n",
      "Training accuracy is  0.9717548076923077\n",
      "Epoch  5350 Loss  0.14628730714321136\n",
      "Training accuracy is  0.9682241586538461\n",
      "Epoch  5360 Loss  0.14649496972560883\n",
      "Training accuracy is  0.9710036057692307\n",
      "Epoch  5370 Loss  0.14660970866680145\n",
      "Training accuracy is  0.9674729567307693\n",
      "Epoch  5380 Loss  0.14492812752723694\n",
      "Training accuracy is  0.9649188701923077\n",
      "Epoch  5390 Loss  0.14982818067073822\n",
      "Training accuracy is  0.9701021634615384\n",
      "Epoch  5400 Loss  0.1450268179178238\n",
      "Training accuracy is  0.9665715144230769\n",
      "Epoch  5410 Loss  0.14835377037525177\n",
      "Training accuracy is  0.9722055288461539\n",
      "Epoch  5420 Loss  0.1449197679758072\n",
      "Training accuracy is  0.9685246394230769\n",
      "Epoch  5430 Loss  0.14782559871673584\n",
      "Training accuracy is  0.9727313701923077\n",
      "Epoch  5440 Loss  0.14463357627391815\n",
      "Training accuracy is  0.9685246394230769\n",
      "Epoch  5450 Loss  0.1474519670009613\n",
      "Training accuracy is  0.9728064903846154\n",
      "Epoch  5460 Loss  0.14445076882839203\n",
      "Training accuracy is  0.9685246394230769\n",
      "Epoch  5470 Loss  0.14743034541606903\n",
      "Training accuracy is  0.9727313701923077\n",
      "Epoch  5480 Loss  0.14432695508003235\n",
      "Training accuracy is  0.9679987980769231\n",
      "Epoch  5490 Loss  0.14681853353977203\n",
      "Training accuracy is  0.9728816105769231\n",
      "Epoch  5500 Loss  0.14431539177894592\n",
      "Training accuracy is  0.9685246394230769\n",
      "Epoch  5510 Loss  0.1458066999912262\n",
      "Training accuracy is  0.9712289663461539\n",
      "Epoch  5520 Loss  0.14594349265098572\n",
      "Training accuracy is  0.9696514423076923\n",
      "Epoch  5530 Loss  0.14566034078598022\n",
      "Training accuracy is  0.9707782451923077\n",
      "Epoch  5540 Loss  0.14564624428749084\n",
      "Training accuracy is  0.9712289663461539\n",
      "Epoch  5550 Loss  0.14509938657283783\n",
      "Training accuracy is  0.9716045673076923\n",
      "Epoch  5560 Loss  0.14559903740882874\n",
      "Training accuracy is  0.9718299278846154\n",
      "Epoch  5570 Loss  0.14459265768527985\n",
      "Training accuracy is  0.9710787259615384\n",
      "Epoch  5580 Loss  0.14565104246139526\n",
      "Training accuracy is  0.9721304086538461\n",
      "Epoch  5590 Loss  0.1443084180355072\n",
      "Training accuracy is  0.970703125\n",
      "Epoch  5600 Loss  0.14574164152145386\n",
      "Training accuracy is  0.9719801682692307\n",
      "Epoch  5610 Loss  0.144194558262825\n",
      "Training accuracy is  0.9708533653846154\n",
      "Epoch  5620 Loss  0.1450628936290741\n",
      "Training accuracy is  0.9719801682692307\n",
      "Epoch  5630 Loss  0.14396978914737701\n",
      "Training accuracy is  0.9709284855769231\n",
      "Epoch  5640 Loss  0.14406155049800873\n",
      "Training accuracy is  0.9716796875\n",
      "Epoch  5650 Loss  0.14467139542102814\n",
      "Training accuracy is  0.9723557692307693\n",
      "Epoch  5660 Loss  0.14356938004493713\n",
      "Training accuracy is  0.9708533653846154\n",
      "Epoch  5670 Loss  0.14551813900470734\n",
      "Training accuracy is  0.9728816105769231\n",
      "Epoch  5680 Loss  0.14342249929904938\n",
      "Training accuracy is  0.9710787259615384\n",
      "Epoch  5690 Loss  0.1451970785856247\n",
      "Training accuracy is  0.9730318509615384\n",
      "Epoch  5700 Loss  0.14339934289455414\n",
      "Training accuracy is  0.9713792067307693\n",
      "Epoch  5710 Loss  0.1440236121416092\n",
      "Training accuracy is  0.9722806490384616\n",
      "Epoch  5720 Loss  0.1434842050075531\n",
      "Training accuracy is  0.9720552884615384\n",
      "Epoch  5730 Loss  0.14353621006011963\n",
      "Training accuracy is  0.9724308894230769\n",
      "Epoch  5740 Loss  0.14408129453659058\n",
      "Training accuracy is  0.9725060096153846\n",
      "Epoch  5750 Loss  0.14331474900245667\n",
      "Training accuracy is  0.9717548076923077\n",
      "Epoch  5760 Loss  0.14444173872470856\n",
      "Training accuracy is  0.9728064903846154\n",
      "Epoch  5770 Loss  0.14300626516342163\n",
      "Training accuracy is  0.9715294471153846\n",
      "Epoch  5780 Loss  0.14367224276065826\n",
      "Training accuracy is  0.9728816105769231\n",
      "Epoch  5790 Loss  0.14282695949077606\n",
      "Training accuracy is  0.9725060096153846\n",
      "Epoch  5800 Loss  0.1427966058254242\n",
      "Training accuracy is  0.9727313701923077\n",
      "Epoch  5810 Loss  0.14334478974342346\n",
      "Training accuracy is  0.97265625\n",
      "Epoch  5820 Loss  0.14248353242874146\n",
      "Training accuracy is  0.9723557692307693\n",
      "Epoch  5830 Loss  0.14379912614822388\n",
      "Training accuracy is  0.9732572115384616\n",
      "Epoch  5840 Loss  0.14252711832523346\n",
      "Training accuracy is  0.9720552884615384\n",
      "Epoch  5850 Loss  0.14371894299983978\n",
      "Training accuracy is  0.9728816105769231\n",
      "Epoch  5860 Loss  0.14236384630203247\n",
      "Training accuracy is  0.9720552884615384\n",
      "Epoch  5870 Loss  0.14294378459453583\n",
      "Training accuracy is  0.9732572115384616\n",
      "Epoch  5880 Loss  0.1421893984079361\n",
      "Training accuracy is  0.9731069711538461\n",
      "Epoch  5890 Loss  0.14215971529483795\n",
      "Training accuracy is  0.9730318509615384\n",
      "Epoch  5900 Loss  0.14287494122982025\n",
      "Training accuracy is  0.9733323317307693\n",
      "Epoch  5910 Loss  0.1418086588382721\n",
      "Training accuracy is  0.9718299278846154\n",
      "Epoch  5920 Loss  0.14356139302253723\n",
      "Training accuracy is  0.9728816105769231\n",
      "Epoch  5930 Loss  0.14162948727607727\n",
      "Training accuracy is  0.9716796875\n",
      "Epoch  5940 Loss  0.14226993918418884\n",
      "Training accuracy is  0.9737079326923077\n",
      "Epoch  5950 Loss  0.14163383841514587\n",
      "Training accuracy is  0.9731069711538461\n",
      "Epoch  5960 Loss  0.14157189428806305\n",
      "Training accuracy is  0.9731820913461539\n",
      "Epoch  5970 Loss  0.14234481751918793\n",
      "Training accuracy is  0.9735576923076923\n",
      "Epoch  5980 Loss  0.1414506584405899\n",
      "Training accuracy is  0.9723557692307693\n",
      "Epoch  5990 Loss  0.14310148358345032\n",
      "Training accuracy is  0.9731069711538461\n",
      "Epoch  6000 Loss  0.14097250998020172\n",
      "Training accuracy is  0.9409555288461539\n",
      "Epoch  6010 Loss  0.1371283084154129\n",
      "Training accuracy is  0.9396784855769231\n",
      "Epoch  6020 Loss  0.1354963332414627\n",
      "Training accuracy is  0.9486929086538461\n",
      "Epoch  6030 Loss  0.13491493463516235\n",
      "Training accuracy is  0.9384765625\n",
      "Epoch  6040 Loss  0.13470256328582764\n",
      "Training accuracy is  0.9490685096153846\n",
      "Epoch  6050 Loss  0.13461577892303467\n",
      "Training accuracy is  0.9411057692307693\n",
      "Epoch  6060 Loss  0.13455714285373688\n",
      "Training accuracy is  0.9452373798076923\n",
      "Epoch  6070 Loss  0.13449372351169586\n",
      "Training accuracy is  0.9440354567307693\n",
      "Epoch  6080 Loss  0.1344268023967743\n",
      "Training accuracy is  0.9435847355769231\n",
      "Epoch  6090 Loss  0.1343631148338318\n",
      "Training accuracy is  0.9446364182692307\n",
      "Epoch  6100 Loss  0.13429947197437286\n",
      "Training accuracy is  0.9446364182692307\n",
      "Epoch  6110 Loss  0.13423548638820648\n",
      "Training accuracy is  0.9444110576923077\n",
      "Epoch  6120 Loss  0.13417194783687592\n",
      "Training accuracy is  0.9445612980769231\n",
      "Epoch  6130 Loss  0.13410833477973938\n",
      "Training accuracy is  0.9446364182692307\n",
      "Epoch  6140 Loss  0.13404478132724762\n",
      "Training accuracy is  0.9448617788461539\n",
      "Epoch  6150 Loss  0.13398107886314392\n",
      "Training accuracy is  0.9447866586538461\n",
      "Epoch  6160 Loss  0.13391710817813873\n",
      "Training accuracy is  0.9450871394230769\n",
      "Epoch  6170 Loss  0.13385286927223206\n",
      "Training accuracy is  0.9449368990384616\n",
      "Epoch  6180 Loss  0.133788600564003\n",
      "Training accuracy is  0.9450120192307693\n",
      "Epoch  6190 Loss  0.133724182844162\n",
      "Training accuracy is  0.9450120192307693\n",
      "Epoch  6200 Loss  0.1336592584848404\n",
      "Training accuracy is  0.9453125\n",
      "Epoch  6210 Loss  0.13359437882900238\n",
      "Training accuracy is  0.9453876201923077\n",
      "Epoch  6220 Loss  0.133529394865036\n",
      "Training accuracy is  0.9453125\n",
      "Epoch  6230 Loss  0.13346420228481293\n",
      "Training accuracy is  0.9454627403846154\n",
      "Epoch  6240 Loss  0.1333988606929779\n",
      "Training accuracy is  0.9454627403846154\n",
      "Epoch  6250 Loss  0.13333329558372498\n",
      "Training accuracy is  0.9458383413461539\n",
      "Epoch  6260 Loss  0.13326750695705414\n",
      "Training accuracy is  0.9458383413461539\n",
      "Epoch  6270 Loss  0.1332014948129654\n",
      "Training accuracy is  0.9462139423076923\n",
      "Epoch  6280 Loss  0.13313527405261993\n",
      "Training accuracy is  0.9463641826923077\n",
      "Epoch  6290 Loss  0.13306891918182373\n",
      "Training accuracy is  0.9462890625\n",
      "Epoch  6300 Loss  0.13300226628780365\n",
      "Training accuracy is  0.9464393028846154\n",
      "Epoch  6310 Loss  0.13293546438217163\n",
      "Training accuracy is  0.9467397836538461\n",
      "Epoch  6320 Loss  0.13286840915679932\n",
      "Training accuracy is  0.9467397836538461\n",
      "Epoch  6330 Loss  0.13280120491981506\n",
      "Training accuracy is  0.9468149038461539\n",
      "Epoch  6340 Loss  0.1327337771654129\n",
      "Training accuracy is  0.9468900240384616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6350 Loss  0.13266628980636597\n",
      "Training accuracy is  0.9468900240384616\n",
      "Epoch  6360 Loss  0.13259828090667725\n",
      "Training accuracy is  0.9468900240384616\n",
      "Epoch  6370 Loss  0.13253025710582733\n",
      "Training accuracy is  0.9468900240384616\n",
      "Epoch  6380 Loss  0.13246110081672668\n",
      "Training accuracy is  0.9470402644230769\n",
      "Epoch  6390 Loss  0.13239175081253052\n",
      "Training accuracy is  0.9473407451923077\n",
      "Epoch  6400 Loss  0.1323191225528717\n",
      "Training accuracy is  0.947265625\n",
      "Epoch  6410 Loss  0.13224568963050842\n",
      "Training accuracy is  0.947265625\n",
      "Epoch  6420 Loss  0.13216683268547058\n",
      "Training accuracy is  0.9475661057692307\n",
      "Epoch  6430 Loss  0.1320737898349762\n",
      "Training accuracy is  0.9477914663461539\n",
      "Epoch  6440 Loss  0.1320020705461502\n",
      "Training accuracy is  0.9477914663461539\n",
      "Epoch  6450 Loss  0.13193045556545258\n",
      "Training accuracy is  0.9480919471153846\n",
      "Epoch  6460 Loss  0.13185879588127136\n",
      "Training accuracy is  0.9482421875\n",
      "Epoch  6470 Loss  0.13178755342960358\n",
      "Training accuracy is  0.9482421875\n",
      "Epoch  6480 Loss  0.13171638548374176\n",
      "Training accuracy is  0.9483173076923077\n",
      "Epoch  6490 Loss  0.13164480030536652\n",
      "Training accuracy is  0.9483924278846154\n",
      "Epoch  6500 Loss  0.1315733790397644\n",
      "Training accuracy is  0.9485426682692307\n",
      "Epoch  6510 Loss  0.13150134682655334\n",
      "Training accuracy is  0.9486177884615384\n",
      "Epoch  6520 Loss  0.1314292997121811\n",
      "Training accuracy is  0.9484675480769231\n",
      "Epoch  6530 Loss  0.13135689496994019\n",
      "Training accuracy is  0.9488431490384616\n",
      "Epoch  6540 Loss  0.13128428161144257\n",
      "Training accuracy is  0.9486177884615384\n",
      "Epoch  6550 Loss  0.131211519241333\n",
      "Training accuracy is  0.9487680288461539\n",
      "Epoch  6560 Loss  0.13113848865032196\n",
      "Training accuracy is  0.9488431490384616\n",
      "Epoch  6570 Loss  0.13106542825698853\n",
      "Training accuracy is  0.9488431490384616\n",
      "Epoch  6580 Loss  0.1309921145439148\n",
      "Training accuracy is  0.9489182692307693\n",
      "Epoch  6590 Loss  0.13091832399368286\n",
      "Training accuracy is  0.94921875\n",
      "Epoch  6600 Loss  0.13084417581558228\n",
      "Training accuracy is  0.9493689903846154\n",
      "Epoch  6610 Loss  0.13076983392238617\n",
      "Training accuracy is  0.9492938701923077\n",
      "Epoch  6620 Loss  0.13069477677345276\n",
      "Training accuracy is  0.9494441105769231\n",
      "Epoch  6630 Loss  0.1306198239326477\n",
      "Training accuracy is  0.9492938701923077\n",
      "Epoch  6640 Loss  0.1305459439754486\n",
      "Training accuracy is  0.9496694711538461\n",
      "Epoch  6650 Loss  0.1304692029953003\n",
      "Training accuracy is  0.9496694711538461\n",
      "Epoch  6660 Loss  0.1303929090499878\n",
      "Training accuracy is  0.9499699519230769\n",
      "Epoch  6670 Loss  0.13031649589538574\n",
      "Training accuracy is  0.9498948317307693\n",
      "Epoch  6680 Loss  0.13023993372917175\n",
      "Training accuracy is  0.9497445913461539\n",
      "Epoch  6690 Loss  0.13016480207443237\n",
      "Training accuracy is  0.9497445913461539\n",
      "Epoch  6700 Loss  0.13008877635002136\n",
      "Training accuracy is  0.9498948317307693\n",
      "Epoch  6710 Loss  0.13001415133476257\n",
      "Training accuracy is  0.9492938701923077\n",
      "Epoch  6720 Loss  0.12993785738945007\n",
      "Training accuracy is  0.9504206730769231\n",
      "Epoch  6730 Loss  0.1298597902059555\n",
      "Training accuracy is  0.9498197115384616\n",
      "Epoch  6740 Loss  0.12977854907512665\n",
      "Training accuracy is  0.9506460336538461\n",
      "Epoch  6750 Loss  0.12970015406608582\n",
      "Training accuracy is  0.9499699519230769\n",
      "Epoch  6760 Loss  0.1296353042125702\n",
      "Training accuracy is  0.9500450721153846\n",
      "Epoch  6770 Loss  0.1295519769191742\n",
      "Training accuracy is  0.9507962740384616\n",
      "Epoch  6780 Loss  0.1294640153646469\n",
      "Training accuracy is  0.9499699519230769\n",
      "Epoch  6790 Loss  0.12941378355026245\n",
      "Training accuracy is  0.9508713942307693\n",
      "Epoch  6800 Loss  0.1293146163225174\n",
      "Training accuracy is  0.9507962740384616\n",
      "Epoch  6810 Loss  0.1292414367198944\n",
      "Training accuracy is  0.9510967548076923\n",
      "Epoch  6820 Loss  0.1291663944721222\n",
      "Training accuracy is  0.9508713942307693\n",
      "Epoch  6830 Loss  0.12910126149654388\n",
      "Training accuracy is  0.9507962740384616\n",
      "Epoch  6840 Loss  0.1290184110403061\n",
      "Training accuracy is  0.9504957932692307\n",
      "Epoch  6850 Loss  0.12892256677150726\n",
      "Training accuracy is  0.9516225961538461\n",
      "Epoch  6860 Loss  0.12885251641273499\n",
      "Training accuracy is  0.9513972355769231\n",
      "Epoch  6870 Loss  0.1287892758846283\n",
      "Training accuracy is  0.9505709134615384\n",
      "Epoch  6880 Loss  0.12869147956371307\n",
      "Training accuracy is  0.9495192307692307\n",
      "Epoch  6890 Loss  0.1287776678800583\n",
      "Training accuracy is  0.9432091346153846\n",
      "Epoch  6900 Loss  0.1335791051387787\n",
      "Training accuracy is  0.9139122596153846\n",
      "Epoch  6910 Loss  0.12840256094932556\n",
      "Training accuracy is  0.9571814903846154\n",
      "Epoch  6920 Loss  0.13068300485610962\n",
      "Training accuracy is  0.9703275240384616\n",
      "Epoch  6930 Loss  0.1285303831100464\n",
      "Training accuracy is  0.9586087740384616\n",
      "Epoch  6940 Loss  0.1281738132238388\n",
      "Training accuracy is  0.9553786057692307\n",
      "Epoch  6950 Loss  0.13117998838424683\n",
      "Training accuracy is  0.9754356971153846\n",
      "Epoch  6960 Loss  0.128623366355896\n",
      "Training accuracy is  0.9554537259615384\n",
      "Epoch  6970 Loss  0.13077588379383087\n",
      "Training accuracy is  0.9280348557692307\n",
      "Epoch  6980 Loss  0.12804311513900757\n",
      "Training accuracy is  0.9613882211538461\n",
      "Epoch  6990 Loss  0.1305263489484787\n",
      "Training accuracy is  0.9723557692307693\n",
      "Epoch  7000 Loss  0.12858590483665466\n",
      "Training accuracy is  0.9638671875\n",
      "Epoch  7010 Loss  0.12769553065299988\n",
      "Training accuracy is  0.9510216346153846\n",
      "Epoch  7020 Loss  0.1287015825510025\n",
      "Training accuracy is  0.9335186298076923\n",
      "Epoch  7030 Loss  0.13206753134727478\n",
      "Training accuracy is  0.9250300480769231\n",
      "Epoch  7040 Loss  0.13008049130439758\n",
      "Training accuracy is  0.9729567307692307\n",
      "Epoch  7050 Loss  0.12772320210933685\n",
      "Training accuracy is  0.9601862980769231\n",
      "Epoch  7060 Loss  0.12758412957191467\n",
      "Training accuracy is  0.9415564903846154\n",
      "Epoch  7070 Loss  0.1321728378534317\n",
      "Training accuracy is  0.9164663461538461\n",
      "Epoch  7080 Loss  0.12703002989292145\n",
      "Training accuracy is  0.9554537259615384\n",
      "Epoch  7090 Loss  0.1294197142124176\n",
      "Training accuracy is  0.9725811298076923\n",
      "Epoch  7100 Loss  0.12856929004192352\n",
      "Training accuracy is  0.9681490384615384\n",
      "Epoch  7110 Loss  0.12687751650810242\n",
      "Training accuracy is  0.95703125\n",
      "Epoch  7120 Loss  0.12683475017547607\n",
      "Training accuracy is  0.9594350961538461\n",
      "Epoch  7130 Loss  0.13595344126224518\n",
      "Training accuracy is  0.9744591346153846\n",
      "Epoch  7140 Loss  0.1270805150270462\n",
      "Training accuracy is  0.9381760817307693\n",
      "Epoch  7150 Loss  0.12792202830314636\n",
      "Training accuracy is  0.9402794471153846\n",
      "Epoch  7160 Loss  0.12704356014728546\n",
      "Training accuracy is  0.9669471153846154\n",
      "Epoch  7170 Loss  0.1300225704908371\n",
      "Training accuracy is  0.9743840144230769\n",
      "Epoch  7180 Loss  0.12664122879505157\n",
      "Training accuracy is  0.9603365384615384\n",
      "Epoch  7190 Loss  0.12624403834342957\n",
      "Training accuracy is  0.9465144230769231\n",
      "Epoch  7200 Loss  0.13180115818977356\n",
      "Training accuracy is  0.9130108173076923\n",
      "Epoch  7210 Loss  0.12589479982852936\n",
      "Training accuracy is  0.9592848557692307\n",
      "Epoch  7220 Loss  0.12892664968967438\n",
      "Training accuracy is  0.9733323317307693\n",
      "Epoch  7230 Loss  0.12574602663516998\n",
      "Training accuracy is  0.9568058894230769\n",
      "Epoch  7240 Loss  0.12598074972629547\n",
      "Training accuracy is  0.9444861778846154\n",
      "Epoch  7250 Loss  0.13281771540641785\n",
      "Training accuracy is  0.9128605769230769\n",
      "Epoch  7260 Loss  0.1257457584142685\n",
      "Training accuracy is  0.9679987980769231\n",
      "Epoch  7270 Loss  0.1280793398618698\n",
      "Training accuracy is  0.9731069711538461\n",
      "Epoch  7280 Loss  0.1252661496400833\n",
      "Training accuracy is  0.9566556490384616\n",
      "Epoch  7290 Loss  0.12572279572486877\n",
      "Training accuracy is  0.9416316105769231\n",
      "Epoch  7300 Loss  0.13170669972896576\n",
      "Training accuracy is  0.9178185096153846\n",
      "Epoch  7310 Loss  0.12531469762325287\n",
      "Training accuracy is  0.9674729567307693\n",
      "Epoch  7320 Loss  0.12818898260593414\n",
      "Training accuracy is  0.9758864182692307\n",
      "Epoch  7330 Loss  0.12500204145908356\n",
      "Training accuracy is  0.9628155048076923\n",
      "Epoch  7340 Loss  0.12465452402830124\n",
      "Training accuracy is  0.9535757211538461\n",
      "Epoch  7350 Loss  0.1275661736726761\n",
      "Training accuracy is  0.9224008413461539\n",
      "Epoch  7360 Loss  0.12511612474918365\n",
      "Training accuracy is  0.9525240384615384\n",
      "Epoch  7370 Loss  0.12853969633579254\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  7380 Loss  0.12434045970439911\n",
      "Training accuracy is  0.9506460336538461\n",
      "Epoch  7390 Loss  0.126929372549057\n",
      "Training accuracy is  0.9287860576923077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7400 Loss  0.12544550001621246\n",
      "Training accuracy is  0.9414813701923077\n",
      "Epoch  7410 Loss  0.12408927828073502\n",
      "Training accuracy is  0.9625901442307693\n",
      "Epoch  7420 Loss  0.128147155046463\n",
      "Training accuracy is  0.9779146634615384\n",
      "Epoch  7430 Loss  0.12548524141311646\n",
      "Training accuracy is  0.9664963942307693\n",
      "Epoch  7440 Loss  0.1258872151374817\n",
      "Training accuracy is  0.9332181490384616\n",
      "Epoch  7450 Loss  0.12557870149612427\n",
      "Training accuracy is  0.9379507211538461\n",
      "Epoch  7460 Loss  0.12371312081813812\n",
      "Training accuracy is  0.9527493990384616\n",
      "Epoch  7470 Loss  0.12353284657001495\n",
      "Training accuracy is  0.9542518028846154\n",
      "Epoch  7480 Loss  0.12817834317684174\n",
      "Training accuracy is  0.9157151442307693\n",
      "Epoch  7490 Loss  0.12340085953474045\n",
      "Training accuracy is  0.9654447115384616\n",
      "Epoch  7500 Loss  0.12637749314308167\n",
      "Training accuracy is  0.9744591346153846\n",
      "Epoch  7510 Loss  0.12401736527681351\n",
      "Training accuracy is  0.9422325721153846\n",
      "Epoch  7520 Loss  0.1259302943944931\n",
      "Training accuracy is  0.9326923076923077\n",
      "Epoch  7530 Loss  0.1232379823923111\n",
      "Training accuracy is  0.9522235576923077\n",
      "Epoch  7540 Loss  0.12295952439308167\n",
      "Training accuracy is  0.9606370192307693\n",
      "Epoch  7550 Loss  0.1246209442615509\n",
      "Training accuracy is  0.9739332932692307\n",
      "Epoch  7560 Loss  0.1284256875514984\n",
      "Training accuracy is  0.9773137019230769\n",
      "Epoch  7570 Loss  0.12582872807979584\n",
      "Training accuracy is  0.9284104567307693\n",
      "Epoch  7580 Loss  0.12317808717489243\n",
      "Training accuracy is  0.9516225961538461\n",
      "Epoch  7590 Loss  0.12308178842067719\n",
      "Training accuracy is  0.970703125\n",
      "Epoch  7600 Loss  0.1287555992603302\n",
      "Training accuracy is  0.978515625\n",
      "Epoch  7610 Loss  0.12251743674278259\n",
      "Training accuracy is  0.9612379807692307\n",
      "Epoch  7620 Loss  0.12386088818311691\n",
      "Training accuracy is  0.9360727163461539\n",
      "Epoch  7630 Loss  0.12620629370212555\n",
      "Training accuracy is  0.9304387019230769\n",
      "Epoch  7640 Loss  0.12214197218418121\n",
      "Training accuracy is  0.9631911057692307\n",
      "Epoch  7650 Loss  0.1246124655008316\n",
      "Training accuracy is  0.9777644230769231\n",
      "Epoch  7660 Loss  0.12524166703224182\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  7670 Loss  0.12219557166099548\n",
      "Training accuracy is  0.9491436298076923\n",
      "Epoch  7680 Loss  0.1258912980556488\n",
      "Training accuracy is  0.9255558894230769\n",
      "Epoch  7690 Loss  0.12255607545375824\n",
      "Training accuracy is  0.9495943509615384\n",
      "Epoch  7700 Loss  0.12205706536769867\n",
      "Training accuracy is  0.9701772836538461\n",
      "Epoch  7710 Loss  0.12772169709205627\n",
      "Training accuracy is  0.9792668269230769\n",
      "Epoch  7720 Loss  0.1218867376446724\n",
      "Training accuracy is  0.9637169471153846\n",
      "Epoch  7730 Loss  0.12340020388364792\n",
      "Training accuracy is  0.9354717548076923\n",
      "Epoch  7740 Loss  0.12456062436103821\n",
      "Training accuracy is  0.9347956730769231\n",
      "Epoch  7750 Loss  0.12129069864749908\n",
      "Training accuracy is  0.9613131009615384\n",
      "Epoch  7760 Loss  0.12285925447940826\n",
      "Training accuracy is  0.9763371394230769\n",
      "Epoch  7770 Loss  0.12656523287296295\n",
      "Training accuracy is  0.9780649038461539\n",
      "Epoch  7780 Loss  0.12176870554685593\n",
      "Training accuracy is  0.9435847355769231\n",
      "Epoch  7790 Loss  0.12454108148813248\n",
      "Training accuracy is  0.9320162259615384\n",
      "Epoch  7800 Loss  0.12121760100126266\n",
      "Training accuracy is  0.9542518028846154\n",
      "Epoch  7810 Loss  0.12098919600248337\n",
      "Training accuracy is  0.9615384615384616\n",
      "Epoch  7820 Loss  0.12108421325683594\n",
      "Training accuracy is  0.9679236778846154\n",
      "Epoch  7830 Loss  0.1334344446659088\n",
      "Training accuracy is  0.9735576923076923\n",
      "Epoch  7840 Loss  0.12111396342515945\n",
      "Training accuracy is  0.9438852163461539\n",
      "Epoch  7850 Loss  0.12304632365703583\n",
      "Training accuracy is  0.9396033653846154\n",
      "Epoch  7860 Loss  0.12063658982515335\n",
      "Training accuracy is  0.9695012019230769\n",
      "Epoch  7870 Loss  0.1250266283750534\n",
      "Training accuracy is  0.9792668269230769\n",
      "Epoch  7880 Loss  0.12118781358003616\n",
      "Training accuracy is  0.9701772836538461\n",
      "Epoch  7890 Loss  0.12042408436536789\n",
      "Training accuracy is  0.9522235576923077\n",
      "Epoch  7900 Loss  0.125983327627182\n",
      "Training accuracy is  0.9205979567307693\n",
      "Epoch  7910 Loss  0.12012744694948196\n",
      "Training accuracy is  0.9610877403846154\n",
      "Epoch  7920 Loss  0.12321116030216217\n",
      "Training accuracy is  0.9780649038461539\n",
      "Epoch  7930 Loss  0.12172220647335052\n",
      "Training accuracy is  0.9747596153846154\n",
      "Epoch  7940 Loss  0.11989697068929672\n",
      "Training accuracy is  0.9667217548076923\n",
      "Epoch  7950 Loss  0.12019093334674835\n",
      "Training accuracy is  0.9722055288461539\n",
      "Epoch  7960 Loss  0.13167190551757812\n",
      "Training accuracy is  0.9776893028846154\n",
      "Epoch  7970 Loss  0.12055293470621109\n",
      "Training accuracy is  0.9418569711538461\n",
      "Epoch  7980 Loss  0.1219053789973259\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  7990 Loss  0.11938447505235672\n",
      "Training accuracy is  0.9634164663461539\n",
      "Epoch  8000 Loss  0.12045127898454666\n",
      "Training accuracy is  0.9750600961538461\n",
      "Epoch  8010 Loss  0.12738104164600372\n",
      "Training accuracy is  0.9792668269230769\n",
      "Epoch  8020 Loss  0.11972007155418396\n",
      "Training accuracy is  0.9507211538461539\n",
      "Epoch  8030 Loss  0.12288008630275726\n",
      "Training accuracy is  0.9323918269230769\n",
      "Epoch  8040 Loss  0.1199854239821434\n",
      "Training accuracy is  0.9504206730769231\n",
      "Epoch  8050 Loss  0.11921067535877228\n",
      "Training accuracy is  0.9544771634615384\n",
      "Epoch  8060 Loss  0.12295500934123993\n",
      "Training accuracy is  0.9260817307692307\n",
      "Epoch  8070 Loss  0.11966868489980698\n",
      "Training accuracy is  0.9543269230769231\n",
      "Epoch  8080 Loss  0.12209861725568771\n",
      "Training accuracy is  0.9788912259615384\n",
      "Epoch  8090 Loss  0.12018154561519623\n",
      "Training accuracy is  0.9745342548076923\n",
      "Epoch  8100 Loss  0.1186896562576294\n",
      "Training accuracy is  0.9674729567307693\n",
      "Epoch  8110 Loss  0.11947809159755707\n",
      "Training accuracy is  0.9745342548076923\n",
      "Epoch  8120 Loss  0.12820817530155182\n",
      "Training accuracy is  0.9782151442307693\n",
      "Epoch  8130 Loss  0.11929387599229813\n",
      "Training accuracy is  0.9442608173076923\n",
      "Epoch  8140 Loss  0.12156900763511658\n",
      "Training accuracy is  0.9372746394230769\n",
      "Epoch  8150 Loss  0.11837577074766159\n",
      "Training accuracy is  0.9576322115384616\n",
      "Epoch  8160 Loss  0.1181919127702713\n",
      "Training accuracy is  0.9617638221153846\n",
      "Epoch  8170 Loss  0.11864732205867767\n",
      "Training accuracy is  0.9550030048076923\n",
      "Epoch  8180 Loss  0.12947730720043182\n",
      "Training accuracy is  0.9106820913461539\n",
      "Epoch  8190 Loss  0.11887549608945847\n",
      "Training accuracy is  0.9770132211538461\n",
      "Epoch  8200 Loss  0.12050206959247589\n",
      "Training accuracy is  0.9767878605769231\n",
      "Epoch  8210 Loss  0.11807496845722198\n",
      "Training accuracy is  0.9530498798076923\n",
      "Epoch  8220 Loss  0.12241632491350174\n",
      "Training accuracy is  0.9293870192307693\n",
      "Epoch  8230 Loss  0.11810740828514099\n",
      "Training accuracy is  0.9557542067307693\n",
      "Epoch  8240 Loss  0.11782221496105194\n",
      "Training accuracy is  0.9717548076923077\n",
      "Epoch  8250 Loss  0.12632836401462555\n",
      "Training accuracy is  0.9774639423076923\n",
      "Epoch  8260 Loss  0.1173403188586235\n",
      "Training accuracy is  0.9611628605769231\n",
      "Epoch  8270 Loss  0.12083905190229416\n",
      "Training accuracy is  0.9338942307692307\n",
      "Epoch  8280 Loss  0.11859403550624847\n",
      "Training accuracy is  0.9493689903846154\n",
      "Epoch  8290 Loss  0.11721054464578629\n",
      "Training accuracy is  0.9598858173076923\n",
      "Epoch  8300 Loss  0.11793200671672821\n",
      "Training accuracy is  0.9477163461538461\n",
      "Epoch  8310 Loss  0.12448322772979736\n",
      "Training accuracy is  0.9286358173076923\n",
      "Epoch  8320 Loss  0.1186470314860344\n",
      "Training accuracy is  0.9777644230769231\n",
      "Epoch  8330 Loss  0.11972474306821823\n",
      "Training accuracy is  0.9773888221153846\n",
      "Epoch  8340 Loss  0.11675585061311722\n",
      "Training accuracy is  0.9656700721153846\n",
      "Epoch  8350 Loss  0.11778093129396439\n",
      "Training accuracy is  0.9557542067307693\n",
      "Epoch  8360 Loss  0.12149389833211899\n",
      "Training accuracy is  0.9305889423076923\n",
      "Epoch  8370 Loss  0.11825951933860779\n",
      "Training accuracy is  0.9507211538461539\n",
      "Epoch  8380 Loss  0.11709548532962799\n",
      "Training accuracy is  0.9740084134615384\n",
      "Epoch  8390 Loss  0.12502336502075195\n",
      "Training accuracy is  0.9787409855769231\n",
      "Epoch  8400 Loss  0.11630213260650635\n",
      "Training accuracy is  0.9626652644230769\n",
      "Epoch  8410 Loss  0.11939297616481781\n",
      "Training accuracy is  0.935546875\n",
      "Epoch  8420 Loss  0.1185474544763565\n",
      "Training accuracy is  0.9461388221153846\n",
      "Epoch  8430 Loss  0.1160682961344719\n",
      "Training accuracy is  0.9676983173076923\n",
      "Epoch  8440 Loss  0.1182255819439888\n",
      "Training accuracy is  0.9786658653846154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8450 Loss  0.12032942473888397\n",
      "Training accuracy is  0.9779897836538461\n",
      "Epoch  8460 Loss  0.11739163845777512\n",
      "Training accuracy is  0.9437349759615384\n",
      "Epoch  8470 Loss  0.1192476749420166\n",
      "Training accuracy is  0.9401292067307693\n",
      "Epoch  8480 Loss  0.11589838564395905\n",
      "Training accuracy is  0.9602614182692307\n",
      "Epoch  8490 Loss  0.11568310856819153\n",
      "Training accuracy is  0.9617638221153846\n",
      "Epoch  8500 Loss  0.12005852162837982\n",
      "Training accuracy is  0.927734375\n",
      "Epoch  8510 Loss  0.11599746346473694\n",
      "Training accuracy is  0.9628155048076923\n",
      "Epoch  8520 Loss  0.12107685208320618\n",
      "Training accuracy is  0.9795673076923077\n",
      "Epoch  8530 Loss  0.11572591960430145\n",
      "Training accuracy is  0.970703125\n",
      "Epoch  8540 Loss  0.1153932735323906\n",
      "Training accuracy is  0.9597355769230769\n",
      "Epoch  8550 Loss  0.12123281508684158\n",
      "Training accuracy is  0.9250300480769231\n",
      "Epoch  8560 Loss  0.11539141833782196\n",
      "Training accuracy is  0.9643179086538461\n",
      "Epoch  8570 Loss  0.11931682378053665\n",
      "Training accuracy is  0.9797926682692307\n",
      "Epoch  8580 Loss  0.11678195744752884\n",
      "Training accuracy is  0.9757361778846154\n",
      "Epoch  8590 Loss  0.11491838097572327\n",
      "Training accuracy is  0.9682241586538461\n",
      "Epoch  8600 Loss  0.11499722301959991\n",
      "Training accuracy is  0.9685997596153846\n",
      "Epoch  8610 Loss  0.11749117076396942\n",
      "Training accuracy is  0.9794921875\n",
      "Epoch  8620 Loss  0.11825695633888245\n",
      "Training accuracy is  0.9772385817307693\n",
      "Epoch  8630 Loss  0.11775864660739899\n",
      "Training accuracy is  0.9371995192307693\n",
      "Epoch  8640 Loss  0.11665312945842743\n",
      "Training accuracy is  0.9495192307692307\n",
      "Epoch  8650 Loss  0.11449845135211945\n",
      "Training accuracy is  0.9693509615384616\n",
      "Epoch  8660 Loss  0.1180446594953537\n",
      "Training accuracy is  0.9800180288461539\n",
      "Epoch  8670 Loss  0.11651331931352615\n",
      "Training accuracy is  0.9755859375\n",
      "Epoch  8680 Loss  0.11615817248821259\n",
      "Training accuracy is  0.9442608173076923\n",
      "Epoch  8690 Loss  0.1178344115614891\n",
      "Training accuracy is  0.94140625\n",
      "Epoch  8700 Loss  0.11423410475254059\n",
      "Training accuracy is  0.9630408653846154\n",
      "Epoch  8710 Loss  0.11409636586904526\n",
      "Training accuracy is  0.9620643028846154\n",
      "Epoch  8720 Loss  0.12064631283283234\n",
      "Training accuracy is  0.9225510817307693\n",
      "Epoch  8730 Loss  0.1139170229434967\n",
      "Training accuracy is  0.9690504807692307\n",
      "Epoch  8740 Loss  0.11985801160335541\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  8750 Loss  0.11393916606903076\n",
      "Training accuracy is  0.9704777644230769\n",
      "Epoch  8760 Loss  0.11384181678295135\n",
      "Training accuracy is  0.9601862980769231\n",
      "Epoch  8770 Loss  0.12119987607002258\n",
      "Training accuracy is  0.9228515625\n",
      "Epoch  8780 Loss  0.11354731023311615\n",
      "Training accuracy is  0.9685997596153846\n",
      "Epoch  8790 Loss  0.11864567548036575\n",
      "Training accuracy is  0.9797926682692307\n",
      "Epoch  8800 Loss  0.11457698047161102\n",
      "Training accuracy is  0.9750600961538461\n",
      "Epoch  8810 Loss  0.11327993869781494\n",
      "Training accuracy is  0.9677734375\n",
      "Epoch  8820 Loss  0.11335237324237823\n",
      "Training accuracy is  0.9649939903846154\n",
      "Epoch  8830 Loss  0.1152653619647026\n",
      "Training accuracy is  0.9445612980769231\n",
      "Epoch  8840 Loss  0.11815505474805832\n",
      "Training accuracy is  0.9436598557692307\n",
      "Epoch  8850 Loss  0.11511431634426117\n",
      "Training accuracy is  0.9788161057692307\n",
      "Epoch  8860 Loss  0.11798246949911118\n",
      "Training accuracy is  0.9794921875\n",
      "Epoch  8870 Loss  0.11287052929401398\n",
      "Training accuracy is  0.9640925480769231\n",
      "Epoch  8880 Loss  0.11618208140134811\n",
      "Training accuracy is  0.9370492788461539\n",
      "Epoch  8890 Loss  0.1149853840470314\n",
      "Training accuracy is  0.9528996394230769\n",
      "Epoch  8900 Loss  0.1137361228466034\n",
      "Training accuracy is  0.9773888221153846\n",
      "Epoch  8910 Loss  0.1193832978606224\n",
      "Training accuracy is  0.9797926682692307\n",
      "Epoch  8920 Loss  0.11263064295053482\n",
      "Training accuracy is  0.9702524038461539\n",
      "Epoch  8930 Loss  0.11297523975372314\n",
      "Training accuracy is  0.9562800480769231\n",
      "Epoch  8940 Loss  0.12100625783205032\n",
      "Training accuracy is  0.9265324519230769\n",
      "Epoch  8950 Loss  0.11231093853712082\n",
      "Training accuracy is  0.9714543269230769\n",
      "Epoch  8960 Loss  0.11756381392478943\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  8970 Loss  0.11368240416049957\n",
      "Training accuracy is  0.9757361778846154\n",
      "Epoch  8980 Loss  0.11207345128059387\n",
      "Training accuracy is  0.9679987980769231\n",
      "Epoch  8990 Loss  0.11249545961618423\n",
      "Training accuracy is  0.9569561298076923\n",
      "Epoch  9000 Loss  0.12246568500995636\n",
      "Training accuracy is  0.9674729567307693\n",
      "Epoch  9010 Loss  0.1153152659535408\n",
      "Training accuracy is  0.9665715144230769\n",
      "Epoch  9020 Loss  0.11312471330165863\n",
      "Training accuracy is  0.9683743990384616\n",
      "Epoch  9030 Loss  0.1122424304485321\n",
      "Training accuracy is  0.9696514423076923\n",
      "Epoch  9040 Loss  0.11191666126251221\n",
      "Training accuracy is  0.9671724759615384\n",
      "Epoch  9050 Loss  0.1117754802107811\n",
      "Training accuracy is  0.9700270432692307\n",
      "Epoch  9060 Loss  0.1117052212357521\n",
      "Training accuracy is  0.9675480769230769\n",
      "Epoch  9070 Loss  0.11165967583656311\n",
      "Training accuracy is  0.9696514423076923\n",
      "Epoch  9080 Loss  0.11162073910236359\n",
      "Training accuracy is  0.9685997596153846\n",
      "Epoch  9090 Loss  0.11158037185668945\n",
      "Training accuracy is  0.9688251201923077\n",
      "Epoch  9100 Loss  0.11153947561979294\n",
      "Training accuracy is  0.9689753605769231\n",
      "Epoch  9110 Loss  0.11149918287992477\n",
      "Training accuracy is  0.9689002403846154\n",
      "Epoch  9120 Loss  0.11145884543657303\n",
      "Training accuracy is  0.9689753605769231\n",
      "Epoch  9130 Loss  0.11141855269670486\n",
      "Training accuracy is  0.9688251201923077\n",
      "Epoch  9140 Loss  0.11137831956148148\n",
      "Training accuracy is  0.9688251201923077\n",
      "Epoch  9150 Loss  0.11133795231580734\n",
      "Training accuracy is  0.9688251201923077\n",
      "Epoch  9160 Loss  0.1112976223230362\n",
      "Training accuracy is  0.9688251201923077\n",
      "Epoch  9170 Loss  0.11125718802213669\n",
      "Training accuracy is  0.9688251201923077\n",
      "Epoch  9180 Loss  0.11121632158756256\n",
      "Training accuracy is  0.9688251201923077\n",
      "Epoch  9190 Loss  0.11117541044950485\n",
      "Training accuracy is  0.9688251201923077\n",
      "Epoch  9200 Loss  0.11113454401493073\n",
      "Training accuracy is  0.9688251201923077\n",
      "Epoch  9210 Loss  0.11109384894371033\n",
      "Training accuracy is  0.9689002403846154\n",
      "Epoch  9220 Loss  0.11105290055274963\n",
      "Training accuracy is  0.9689753605769231\n",
      "Epoch  9230 Loss  0.11101162433624268\n",
      "Training accuracy is  0.9689002403846154\n",
      "Epoch  9240 Loss  0.11097021400928497\n",
      "Training accuracy is  0.9689753605769231\n",
      "Epoch  9250 Loss  0.11092875897884369\n",
      "Training accuracy is  0.9689753605769231\n",
      "Epoch  9260 Loss  0.11088721454143524\n",
      "Training accuracy is  0.9690504807692307\n",
      "Epoch  9270 Loss  0.11084555834531784\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9280 Loss  0.11080383509397507\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9290 Loss  0.11076200008392334\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9300 Loss  0.11072010546922684\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9310 Loss  0.11067795008420944\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9320 Loss  0.1106356680393219\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9330 Loss  0.11059333384037018\n",
      "Training accuracy is  0.9690504807692307\n",
      "Epoch  9340 Loss  0.11055084317922592\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9350 Loss  0.11050833761692047\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9360 Loss  0.11046575009822845\n",
      "Training accuracy is  0.9690504807692307\n",
      "Epoch  9370 Loss  0.11042309552431107\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9380 Loss  0.11038041114807129\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9390 Loss  0.11033765226602554\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9400 Loss  0.1102951392531395\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9410 Loss  0.11025265604257584\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9420 Loss  0.1102101132273674\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9430 Loss  0.1101674735546112\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9440 Loss  0.11012471467256546\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9450 Loss  0.11008188128471375\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9460 Loss  0.11003874242305756\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9470 Loss  0.10999539494514465\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9480 Loss  0.10995184630155563\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9490 Loss  0.10990819334983826\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9500 Loss  0.10986431688070297\n",
      "Training accuracy is  0.9692007211538461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9510 Loss  0.10982035845518112\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  9520 Loss  0.10977636277675629\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  9530 Loss  0.10973214358091354\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  9540 Loss  0.1096877008676529\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  9550 Loss  0.10964316874742508\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  9560 Loss  0.10959725081920624\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  9570 Loss  0.10955169796943665\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  9580 Loss  0.10950624197721481\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  9590 Loss  0.10945975035429001\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  9600 Loss  0.10941056162118912\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9610 Loss  0.10935436189174652\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  9620 Loss  0.10930125415325165\n",
      "Training accuracy is  0.9690504807692307\n",
      "Epoch  9630 Loss  0.10925500094890594\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9640 Loss  0.10920875519514084\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9650 Loss  0.10916256159543991\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  9660 Loss  0.10911652445793152\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9670 Loss  0.10907074064016342\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9680 Loss  0.10902488231658936\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9690 Loss  0.10897902399301529\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  9700 Loss  0.1089329719543457\n",
      "Training accuracy is  0.9693509615384616\n",
      "Epoch  9710 Loss  0.1088869571685791\n",
      "Training accuracy is  0.9693509615384616\n",
      "Epoch  9720 Loss  0.10884062200784683\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9730 Loss  0.1087942123413086\n",
      "Training accuracy is  0.9692007211538461\n",
      "Epoch  9740 Loss  0.10874791443347931\n",
      "Training accuracy is  0.9694260817307693\n",
      "Epoch  9750 Loss  0.10870151966810226\n",
      "Training accuracy is  0.9695012019230769\n",
      "Epoch  9760 Loss  0.10865478962659836\n",
      "Training accuracy is  0.9695012019230769\n",
      "Epoch  9770 Loss  0.1086082011461258\n",
      "Training accuracy is  0.9697265625\n",
      "Epoch  9780 Loss  0.10856166481971741\n",
      "Training accuracy is  0.9693509615384616\n",
      "Epoch  9790 Loss  0.10851474851369858\n",
      "Training accuracy is  0.9698016826923077\n",
      "Epoch  9800 Loss  0.10846738517284393\n",
      "Training accuracy is  0.9698016826923077\n",
      "Epoch  9810 Loss  0.10842012614011765\n",
      "Training accuracy is  0.9698016826923077\n",
      "Epoch  9820 Loss  0.10837295651435852\n",
      "Training accuracy is  0.9696514423076923\n",
      "Epoch  9830 Loss  0.10832551121711731\n",
      "Training accuracy is  0.9698016826923077\n",
      "Epoch  9840 Loss  0.10827822238206863\n",
      "Training accuracy is  0.9696514423076923\n",
      "Epoch  9850 Loss  0.10822954773902893\n",
      "Training accuracy is  0.9699519230769231\n",
      "Epoch  9860 Loss  0.10818181931972504\n",
      "Training accuracy is  0.9697265625\n",
      "Epoch  9870 Loss  0.10813342779874802\n",
      "Training accuracy is  0.9699519230769231\n",
      "Epoch  9880 Loss  0.10808445513248444\n",
      "Training accuracy is  0.9699519230769231\n",
      "Epoch  9890 Loss  0.10803619772195816\n",
      "Training accuracy is  0.9699519230769231\n",
      "Epoch  9900 Loss  0.10798728466033936\n",
      "Training accuracy is  0.9699519230769231\n",
      "Epoch  9910 Loss  0.10793796181678772\n",
      "Training accuracy is  0.9698768028846154\n",
      "Epoch  9920 Loss  0.10789132118225098\n",
      "Training accuracy is  0.9700270432692307\n",
      "Epoch  9930 Loss  0.10784045606851578\n",
      "Training accuracy is  0.9699519230769231\n",
      "Epoch  9940 Loss  0.1077912300825119\n",
      "Training accuracy is  0.9703275240384616\n",
      "Epoch  9950 Loss  0.10774203389883041\n",
      "Training accuracy is  0.9698768028846154\n",
      "Epoch  9960 Loss  0.10769258439540863\n",
      "Training accuracy is  0.9702524038461539\n",
      "Epoch  9970 Loss  0.10764412581920624\n",
      "Training accuracy is  0.9702524038461539\n",
      "Epoch  9980 Loss  0.10760065913200378\n",
      "Training accuracy is  0.9701021634615384\n",
      "Epoch  9990 Loss  0.10754856467247009\n",
      "Training accuracy is  0.9702524038461539\n",
      "Epoch  10000 Loss  0.10749673843383789\n",
      "Training accuracy is  0.9702524038461539\n",
      "Epoch  10010 Loss  0.10744690895080566\n",
      "Training accuracy is  0.9701021634615384\n",
      "Epoch  10020 Loss  0.10740096867084503\n",
      "Training accuracy is  0.9706280048076923\n",
      "Epoch  10030 Loss  0.10734906792640686\n",
      "Training accuracy is  0.9704777644230769\n",
      "Epoch  10040 Loss  0.1073148250579834\n",
      "Training accuracy is  0.9695763221153846\n",
      "Epoch  10050 Loss  0.10725399106740952\n",
      "Training accuracy is  0.9702524038461539\n",
      "Epoch  10060 Loss  0.10723653435707092\n",
      "Training accuracy is  0.9723557692307693\n",
      "Epoch  10070 Loss  0.10715771466493607\n",
      "Training accuracy is  0.9712289663461539\n",
      "Epoch  10080 Loss  0.10710124671459198\n",
      "Training accuracy is  0.9697265625\n",
      "Epoch  10090 Loss  0.10734670609235764\n",
      "Training accuracy is  0.9652944711538461\n",
      "Epoch  10100 Loss  0.10746002197265625\n",
      "Training accuracy is  0.9647686298076923\n",
      "Epoch  10110 Loss  0.10700241476297379\n",
      "Training accuracy is  0.9694260817307693\n",
      "Epoch  10120 Loss  0.10693103820085526\n",
      "Training accuracy is  0.9721304086538461\n",
      "Epoch  10130 Loss  0.10701604187488556\n",
      "Training accuracy is  0.9750600961538461\n",
      "Epoch  10140 Loss  0.11227459460496902\n",
      "Training accuracy is  0.9803936298076923\n",
      "Epoch  10150 Loss  0.10777035355567932\n",
      "Training accuracy is  0.9580078125\n",
      "Epoch  10160 Loss  0.10683579742908478\n",
      "Training accuracy is  0.9753605769230769\n",
      "Epoch  10170 Loss  0.106840118765831\n",
      "Training accuracy is  0.9735576923076923\n",
      "Epoch  10180 Loss  0.10675811022520065\n",
      "Training accuracy is  0.9673978365384616\n",
      "Epoch  10190 Loss  0.10719971358776093\n",
      "Training accuracy is  0.9622896634615384\n",
      "Epoch  10200 Loss  0.10737284272909164\n",
      "Training accuracy is  0.9625901442307693\n",
      "Epoch  10210 Loss  0.1064649447798729\n",
      "Training accuracy is  0.9703275240384616\n",
      "Epoch  10220 Loss  0.10658717155456543\n",
      "Training accuracy is  0.9754356971153846\n",
      "Epoch  10230 Loss  0.10980001837015152\n",
      "Training accuracy is  0.9805438701923077\n",
      "Epoch  10240 Loss  0.10638762265443802\n",
      "Training accuracy is  0.9668719951923077\n",
      "Epoch  10250 Loss  0.10672903060913086\n",
      "Training accuracy is  0.9667217548076923\n",
      "Epoch  10260 Loss  0.10637577623128891\n",
      "Training accuracy is  0.9752103365384616\n",
      "Epoch  10270 Loss  0.10705255717039108\n",
      "Training accuracy is  0.9777644230769231\n",
      "Epoch  10280 Loss  0.10689990967512131\n",
      "Training accuracy is  0.9765625\n",
      "Epoch  10290 Loss  0.1060485988855362\n",
      "Training accuracy is  0.9707782451923077\n",
      "Epoch  10300 Loss  0.10660072416067123\n",
      "Training accuracy is  0.9620643028846154\n",
      "Epoch  10310 Loss  0.10846024006605148\n",
      "Training accuracy is  0.9561298076923077\n",
      "Epoch  10320 Loss  0.1065494567155838\n",
      "Training accuracy is  0.9776141826923077\n",
      "Epoch  10330 Loss  0.10601627826690674\n",
      "Training accuracy is  0.9737830528846154\n",
      "Epoch  10340 Loss  0.10596080869436264\n",
      "Training accuracy is  0.9679987980769231\n",
      "Epoch  10350 Loss  0.10702323913574219\n",
      "Training accuracy is  0.9586087740384616\n",
      "Epoch  10360 Loss  0.10654997825622559\n",
      "Training accuracy is  0.9656700721153846\n",
      "Epoch  10370 Loss  0.10602443665266037\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  10380 Loss  0.10684474557638168\n",
      "Training accuracy is  0.9786658653846154\n",
      "Epoch  10390 Loss  0.105844646692276\n",
      "Training accuracy is  0.9749849759615384\n",
      "Epoch  10400 Loss  0.10557324439287186\n",
      "Training accuracy is  0.9692758413461539\n",
      "Epoch  10410 Loss  0.10688173025846481\n",
      "Training accuracy is  0.9571063701923077\n",
      "Epoch  10420 Loss  0.10631206631660461\n",
      "Training accuracy is  0.9659705528846154\n",
      "Epoch  10430 Loss  0.10648205876350403\n",
      "Training accuracy is  0.9783653846153846\n",
      "Epoch  10440 Loss  0.10532376170158386\n",
      "Training accuracy is  0.9698768028846154\n",
      "Epoch  10450 Loss  0.10573013871908188\n",
      "Training accuracy is  0.9652193509615384\n",
      "Epoch  10460 Loss  0.10615435242652893\n",
      "Training accuracy is  0.9617638221153846\n",
      "Epoch  10470 Loss  0.10580436140298843\n",
      "Training accuracy is  0.9654447115384616\n",
      "Epoch  10480 Loss  0.1050950214266777\n",
      "Training accuracy is  0.9725811298076923\n",
      "Epoch  10490 Loss  0.10532841086387634\n",
      "Training accuracy is  0.9771634615384616\n",
      "Epoch  10500 Loss  0.10950473695993423\n",
      "Training accuracy is  0.9806189903846154\n",
      "Epoch  10510 Loss  0.10543861985206604\n",
      "Training accuracy is  0.9633413461538461\n",
      "Epoch  10520 Loss  0.10500901192426682\n",
      "Training accuracy is  0.9706280048076923\n",
      "Epoch  10530 Loss  0.1052713543176651\n",
      "Training accuracy is  0.9773137019230769\n",
      "Epoch  10540 Loss  0.10511799156665802\n",
      "Training accuracy is  0.9767127403846154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10550 Loss  0.1048569604754448\n",
      "Training accuracy is  0.9753605769230769\n",
      "Epoch  10560 Loss  0.1054643914103508\n",
      "Training accuracy is  0.9790414663461539\n",
      "Epoch  10570 Loss  0.107790507376194\n",
      "Training accuracy is  0.9806941105769231\n",
      "Epoch  10580 Loss  0.10523198544979095\n",
      "Training accuracy is  0.9633413461538461\n",
      "Epoch  10590 Loss  0.10468325018882751\n",
      "Training accuracy is  0.9700270432692307\n",
      "Epoch  10600 Loss  0.10469897091388702\n",
      "Training accuracy is  0.9770132211538461\n",
      "Epoch  10610 Loss  0.10569688677787781\n",
      "Training accuracy is  0.9800180288461539\n",
      "Epoch  10620 Loss  0.10513830929994583\n",
      "Training accuracy is  0.9775390625\n",
      "Epoch  10630 Loss  0.10437305271625519\n",
      "Training accuracy is  0.9699519230769231\n",
      "Epoch  10640 Loss  0.10531996190547943\n",
      "Training accuracy is  0.9603365384615384\n",
      "Epoch  10650 Loss  0.10546059906482697\n",
      "Training accuracy is  0.9629657451923077\n",
      "Epoch  10660 Loss  0.10431548207998276\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  10670 Loss  0.10528551042079926\n",
      "Training accuracy is  0.9791917067307693\n",
      "Epoch  10680 Loss  0.10451681166887283\n",
      "Training accuracy is  0.9767878605769231\n",
      "Epoch  10690 Loss  0.10399983823299408\n",
      "Training accuracy is  0.9713792067307693\n",
      "Epoch  10700 Loss  0.10481321811676025\n",
      "Training accuracy is  0.9615384615384616\n",
      "Epoch  10710 Loss  0.10621210187673569\n",
      "Training accuracy is  0.9599609375\n",
      "Epoch  10720 Loss  0.10479456931352615\n",
      "Training accuracy is  0.9794170673076923\n",
      "Epoch  10730 Loss  0.10383424162864685\n",
      "Training accuracy is  0.9741586538461539\n",
      "Epoch  10740 Loss  0.10406852513551712\n",
      "Training accuracy is  0.9674729567307693\n",
      "Epoch  10750 Loss  0.10483752936124802\n",
      "Training accuracy is  0.9612379807692307\n",
      "Epoch  10760 Loss  0.10433412343263626\n",
      "Training accuracy is  0.9663461538461539\n",
      "Epoch  10770 Loss  0.10361993312835693\n",
      "Training accuracy is  0.9729567307692307\n",
      "Epoch  10780 Loss  0.10352212935686111\n",
      "Training accuracy is  0.9738581730769231\n",
      "Epoch  10790 Loss  0.1037646159529686\n",
      "Training accuracy is  0.9778395432692307\n",
      "Epoch  10800 Loss  0.11077013611793518\n",
      "Training accuracy is  0.9815955528846154\n",
      "Epoch  10810 Loss  0.10559218376874924\n",
      "Training accuracy is  0.9568058894230769\n",
      "Epoch  10820 Loss  0.10406278818845749\n",
      "Training accuracy is  0.9787409855769231\n",
      "Epoch  10830 Loss  0.10331135243177414\n",
      "Training accuracy is  0.9706280048076923\n",
      "Epoch  10840 Loss  0.10339871793985367\n",
      "Training accuracy is  0.9700270432692307\n",
      "Epoch  10850 Loss  0.10316464304924011\n",
      "Training accuracy is  0.9741586538461539\n",
      "Epoch  10860 Loss  0.10346141457557678\n",
      "Training accuracy is  0.9780649038461539\n",
      "Epoch  10870 Loss  0.10610436648130417\n",
      "Training accuracy is  0.9812199519230769\n",
      "Epoch  10880 Loss  0.10305618494749069\n",
      "Training accuracy is  0.9704777644230769\n",
      "Epoch  10890 Loss  0.10371653735637665\n",
      "Training accuracy is  0.9658954326923077\n",
      "Epoch  10900 Loss  0.10297444462776184\n",
      "Training accuracy is  0.9719801682692307\n",
      "Epoch  10910 Loss  0.10292073339223862\n",
      "Training accuracy is  0.9747596153846154\n",
      "Epoch  10920 Loss  0.10409927368164062\n",
      "Training accuracy is  0.9803185096153846\n",
      "Epoch  10930 Loss  0.10454865545034409\n",
      "Training accuracy is  0.9788161057692307\n",
      "Epoch  10940 Loss  0.10404860973358154\n",
      "Training accuracy is  0.9627403846153846\n",
      "Epoch  10950 Loss  0.10286355018615723\n",
      "Training accuracy is  0.9773137019230769\n",
      "Epoch  10960 Loss  0.10300493985414505\n",
      "Training accuracy is  0.9779146634615384\n",
      "Epoch  10970 Loss  0.10261452198028564\n",
      "Training accuracy is  0.9753605769230769\n",
      "Epoch  10980 Loss  0.10254870355129242\n",
      "Training accuracy is  0.9753605769230769\n",
      "Epoch  10990 Loss  0.10400866717100143\n",
      "Training accuracy is  0.9806189903846154\n",
      "Epoch  11000 Loss  0.1037239134311676\n",
      "Training accuracy is  0.9778395432692307\n",
      "Epoch  11010 Loss  0.1036631315946579\n",
      "Training accuracy is  0.9637920673076923\n",
      "Epoch  11020 Loss  0.1027601882815361\n",
      "Training accuracy is  0.9782151442307693\n",
      "Epoch  11030 Loss  0.10240315645933151\n",
      "Training accuracy is  0.9756610576923077\n",
      "Epoch  11040 Loss  0.10227881371974945\n",
      "Training accuracy is  0.9716796875\n",
      "Epoch  11050 Loss  0.1031876653432846\n",
      "Training accuracy is  0.9622896634615384\n",
      "Epoch  11060 Loss  0.10394886881113052\n",
      "Training accuracy is  0.9631159855769231\n",
      "Epoch  11070 Loss  0.10249949991703033\n",
      "Training accuracy is  0.9782151442307693\n",
      "Epoch  11080 Loss  0.10281892120838165\n",
      "Training accuracy is  0.978515625\n",
      "Epoch  11090 Loss  0.10201393812894821\n",
      "Training accuracy is  0.9750600961538461\n",
      "Epoch  11100 Loss  0.10194266587495804\n",
      "Training accuracy is  0.9720552884615384\n",
      "Epoch  11110 Loss  0.10338931530714035\n",
      "Training accuracy is  0.9585336538461539\n",
      "Epoch  11120 Loss  0.10297214239835739\n",
      "Training accuracy is  0.9688251201923077\n",
      "Epoch  11130 Loss  0.10320209711790085\n",
      "Training accuracy is  0.9796424278846154\n",
      "Epoch  11140 Loss  0.10205499827861786\n",
      "Training accuracy is  0.9685997596153846\n",
      "Epoch  11150 Loss  0.10187435150146484\n",
      "Training accuracy is  0.9710787259615384\n",
      "Epoch  11160 Loss  0.1016087457537651\n",
      "Training accuracy is  0.974609375\n",
      "Epoch  11170 Loss  0.10183850675821304\n",
      "Training accuracy is  0.9782151442307693\n",
      "Epoch  11180 Loss  0.10570176690816879\n",
      "Training accuracy is  0.9819711538461539\n",
      "Epoch  11190 Loss  0.10160369426012039\n",
      "Training accuracy is  0.9695012019230769\n",
      "Epoch  11200 Loss  0.10194966197013855\n",
      "Training accuracy is  0.9689753605769231\n",
      "Epoch  11210 Loss  0.1015722006559372\n",
      "Training accuracy is  0.9774639423076923\n",
      "Epoch  11220 Loss  0.10215398669242859\n",
      "Training accuracy is  0.9794170673076923\n",
      "Epoch  11230 Loss  0.10227297991514206\n",
      "Training accuracy is  0.9794170673076923\n",
      "Epoch  11240 Loss  0.10129257291555405\n",
      "Training accuracy is  0.9758112980769231\n",
      "Epoch  11250 Loss  0.10118357837200165\n",
      "Training accuracy is  0.9728064903846154\n",
      "Epoch  11260 Loss  0.10156069695949554\n",
      "Training accuracy is  0.9683743990384616\n",
      "Epoch  11270 Loss  0.10645569115877151\n",
      "Training accuracy is  0.9473407451923077\n",
      "Epoch  11280 Loss  0.10217063874006271\n",
      "Training accuracy is  0.98046875\n",
      "Epoch  11290 Loss  0.10100393742322922\n",
      "Training accuracy is  0.9717548076923077\n",
      "Epoch  11300 Loss  0.10125665366649628\n",
      "Training accuracy is  0.9706280048076923\n",
      "Epoch  11310 Loss  0.10090503096580505\n",
      "Training accuracy is  0.9765625\n",
      "Epoch  11320 Loss  0.1015731617808342\n",
      "Training accuracy is  0.9792668269230769\n",
      "Epoch  11330 Loss  0.10269294679164886\n",
      "Training accuracy is  0.9805438701923077\n",
      "Epoch  11340 Loss  0.10073062032461166\n",
      "Training accuracy is  0.97265625\n",
      "Epoch  11350 Loss  0.10159067809581757\n",
      "Training accuracy is  0.9655949519230769\n",
      "Epoch  11360 Loss  0.10166500508785248\n",
      "Training accuracy is  0.9660456730769231\n",
      "Epoch  11370 Loss  0.10057103633880615\n",
      "Training accuracy is  0.9749849759615384\n",
      "Epoch  11380 Loss  0.1008564680814743\n",
      "Training accuracy is  0.9783653846153846\n",
      "Epoch  11390 Loss  0.10438398271799088\n",
      "Training accuracy is  0.9818960336538461\n",
      "Epoch  11400 Loss  0.10054183006286621\n",
      "Training accuracy is  0.9707782451923077\n",
      "Epoch  11410 Loss  0.1011136919260025\n",
      "Training accuracy is  0.9685246394230769\n",
      "Epoch  11420 Loss  0.10036781430244446\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  11430 Loss  0.10114213824272156\n",
      "Training accuracy is  0.9797175480769231\n",
      "Epoch  11440 Loss  0.10211266577243805\n",
      "Training accuracy is  0.9801682692307693\n",
      "Epoch  11450 Loss  0.10019324719905853\n",
      "Training accuracy is  0.9732572115384616\n",
      "Epoch  11460 Loss  0.10112471878528595\n",
      "Training accuracy is  0.9651442307692307\n",
      "Epoch  11470 Loss  0.10118526965379715\n",
      "Training accuracy is  0.9670222355769231\n",
      "Epoch  11480 Loss  0.10006192326545715\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  11490 Loss  0.1011124774813652\n",
      "Training accuracy is  0.9803185096153846\n",
      "Epoch  11500 Loss  0.10184475779533386\n",
      "Training accuracy is  0.9802433894230769\n",
      "Epoch  11510 Loss  0.10011695325374603\n",
      "Training accuracy is  0.9706280048076923\n",
      "Epoch  11520 Loss  0.1009935662150383\n",
      "Training accuracy is  0.9656700721153846\n",
      "Epoch  11530 Loss  0.10003948211669922\n",
      "Training accuracy is  0.9719801682692307\n",
      "Epoch  11540 Loss  0.0998062714934349\n",
      "Training accuracy is  0.9772385817307693\n",
      "Epoch  11550 Loss  0.10140185058116913\n",
      "Training accuracy is  0.9812950721153846\n",
      "Epoch  11560 Loss  0.10090499371290207\n",
      "Training accuracy is  0.9790414663461539\n",
      "Epoch  11570 Loss  0.10083901137113571\n",
      "Training accuracy is  0.96484375\n",
      "Epoch  11580 Loss  0.09956672787666321\n",
      "Training accuracy is  0.9756610576923077\n",
      "Epoch  11590 Loss  0.10001368075609207\n",
      "Training accuracy is  0.9791917067307693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  11600 Loss  0.10084231197834015\n",
      "Training accuracy is  0.9800180288461539\n",
      "Epoch  11610 Loss  0.09996572136878967\n",
      "Training accuracy is  0.9778395432692307\n",
      "Epoch  11620 Loss  0.09940969944000244\n",
      "Training accuracy is  0.9736328125\n",
      "Epoch  11630 Loss  0.10013513267040253\n",
      "Training accuracy is  0.9660456730769231\n",
      "Epoch  11640 Loss  0.10211639106273651\n",
      "Training accuracy is  0.9612379807692307\n",
      "Epoch  11650 Loss  0.10002139955759048\n",
      "Training accuracy is  0.9799429086538461\n",
      "Epoch  11660 Loss  0.09946271777153015\n",
      "Training accuracy is  0.9774639423076923\n",
      "Epoch  11670 Loss  0.09930532425642014\n",
      "Training accuracy is  0.9716045673076923\n",
      "Epoch  11680 Loss  0.10048273205757141\n",
      "Training accuracy is  0.9640174278846154\n",
      "Epoch  11690 Loss  0.10001159459352493\n",
      "Training accuracy is  0.9685246394230769\n",
      "Epoch  11700 Loss  0.0991966649889946\n",
      "Training accuracy is  0.9780649038461539\n",
      "Epoch  11710 Loss  0.10046584159135818\n",
      "Training accuracy is  0.9805438701923077\n",
      "Epoch  11720 Loss  0.09952804446220398\n",
      "Training accuracy is  0.9791165865384616\n",
      "Epoch  11730 Loss  0.09900720417499542\n",
      "Training accuracy is  0.9723557692307693\n",
      "Epoch  11740 Loss  0.10047625750303268\n",
      "Training accuracy is  0.9628155048076923\n",
      "Epoch  11750 Loss  0.09949539601802826\n",
      "Training accuracy is  0.9705528846153846\n",
      "Epoch  11760 Loss  0.09920643270015717\n",
      "Training accuracy is  0.9797175480769231\n",
      "Epoch  11770 Loss  0.10005700588226318\n",
      "Training accuracy is  0.9801682692307693\n",
      "Epoch  11780 Loss  0.09882252663373947\n",
      "Training accuracy is  0.9764873798076923\n",
      "Epoch  11790 Loss  0.09880116581916809\n",
      "Training accuracy is  0.9719050480769231\n",
      "Epoch  11800 Loss  0.10102768242359161\n",
      "Training accuracy is  0.9593599759615384\n",
      "Epoch  11810 Loss  0.09871118515729904\n",
      "Training accuracy is  0.9748347355769231\n",
      "Epoch  11820 Loss  0.09958478808403015\n",
      "Training accuracy is  0.9801682692307693\n",
      "Epoch  11830 Loss  0.0984921082854271\n",
      "Training accuracy is  0.9767878605769231\n",
      "Epoch  11840 Loss  0.09850739687681198\n",
      "Training accuracy is  0.9728064903846154\n",
      "Epoch  11850 Loss  0.10045497119426727\n",
      "Training accuracy is  0.9604867788461539\n",
      "Epoch  11860 Loss  0.09871045500040054\n",
      "Training accuracy is  0.9728064903846154\n",
      "Epoch  11870 Loss  0.09919790178537369\n",
      "Training accuracy is  0.9802433894230769\n",
      "Epoch  11880 Loss  0.09849615395069122\n",
      "Training accuracy is  0.9782151442307693\n",
      "Epoch  11890 Loss  0.09814054518938065\n",
      "Training accuracy is  0.9745342548076923\n",
      "Epoch  11900 Loss  0.09885997325181961\n",
      "Training accuracy is  0.966796875\n",
      "Epoch  11910 Loss  0.10099388659000397\n",
      "Training accuracy is  0.9625150240384616\n",
      "Epoch  11920 Loss  0.09891755878925323\n",
      "Training accuracy is  0.9801682692307693\n",
      "Epoch  11930 Loss  0.09808114916086197\n",
      "Training accuracy is  0.9764873798076923\n",
      "Epoch  11940 Loss  0.09821458160877228\n",
      "Training accuracy is  0.9710036057692307\n",
      "Epoch  11950 Loss  0.09928043931722641\n",
      "Training accuracy is  0.9652944711538461\n",
      "Epoch  11960 Loss  0.09842686355113983\n",
      "Training accuracy is  0.9707782451923077\n",
      "Epoch  11970 Loss  0.09775520861148834\n",
      "Training accuracy is  0.9764122596153846\n",
      "Epoch  11980 Loss  0.0982019230723381\n",
      "Training accuracy is  0.9800931490384616\n",
      "Epoch  11990 Loss  0.10194031894207001\n",
      "Training accuracy is  0.9823467548076923\n",
      "Epoch  12000 Loss  0.09796115010976791\n",
      "Training accuracy is  0.9749849759615384\n",
      "Epoch  12010 Loss  0.09770425409078598\n",
      "Training accuracy is  0.9759615384615384\n",
      "Epoch  12020 Loss  0.09759669005870819\n",
      "Training accuracy is  0.9752854567307693\n",
      "Epoch  12030 Loss  0.09754211455583572\n",
      "Training accuracy is  0.9759615384615384\n",
      "Epoch  12040 Loss  0.09750782698392868\n",
      "Training accuracy is  0.9754356971153846\n",
      "Epoch  12050 Loss  0.09748025983572006\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12060 Loss  0.09745541214942932\n",
      "Training accuracy is  0.9756610576923077\n",
      "Epoch  12070 Loss  0.09743142127990723\n",
      "Training accuracy is  0.9758112980769231\n",
      "Epoch  12080 Loss  0.09740723669528961\n",
      "Training accuracy is  0.9758112980769231\n",
      "Epoch  12090 Loss  0.09738319367170334\n",
      "Training accuracy is  0.9758112980769231\n",
      "Epoch  12100 Loss  0.09735911339521408\n",
      "Training accuracy is  0.9758112980769231\n",
      "Epoch  12110 Loss  0.09733498841524124\n",
      "Training accuracy is  0.9758112980769231\n",
      "Epoch  12120 Loss  0.09731095284223557\n",
      "Training accuracy is  0.9758864182692307\n",
      "Epoch  12130 Loss  0.09728681296110153\n",
      "Training accuracy is  0.9759615384615384\n",
      "Epoch  12140 Loss  0.09726259112358093\n",
      "Training accuracy is  0.9758864182692307\n",
      "Epoch  12150 Loss  0.09723836928606033\n",
      "Training accuracy is  0.9759615384615384\n",
      "Epoch  12160 Loss  0.09721409529447556\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  12170 Loss  0.09718974679708481\n",
      "Training accuracy is  0.9759615384615384\n",
      "Epoch  12180 Loss  0.09716536104679108\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  12190 Loss  0.09714090824127197\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  12200 Loss  0.09711607545614243\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  12210 Loss  0.09709114581346512\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12220 Loss  0.09706617891788483\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12230 Loss  0.09704123437404633\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12240 Loss  0.09701623022556305\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12250 Loss  0.09699123352766037\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12260 Loss  0.09696618467569351\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12270 Loss  0.09694107621908188\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12280 Loss  0.09691595286130905\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12290 Loss  0.09689077734947205\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  12300 Loss  0.09686554968357086\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  12310 Loss  0.0968402624130249\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12320 Loss  0.09681496024131775\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12330 Loss  0.09678955376148224\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12340 Loss  0.09676416218280792\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12350 Loss  0.09673868864774704\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12360 Loss  0.0967131033539772\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12370 Loss  0.09668754041194916\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12380 Loss  0.09666185826063156\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12390 Loss  0.09663620591163635\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12400 Loss  0.09661053121089935\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12410 Loss  0.09658463299274445\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12420 Loss  0.09655880182981491\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  12430 Loss  0.09653287380933762\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12440 Loss  0.09650696069002151\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12450 Loss  0.09648089855909348\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12460 Loss  0.09645484387874603\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12470 Loss  0.09642861783504486\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12480 Loss  0.09640242159366608\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12490 Loss  0.09637614339590073\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12500 Loss  0.0963497906923294\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12510 Loss  0.0963234007358551\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12520 Loss  0.09629689157009125\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12530 Loss  0.09627044945955276\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12540 Loss  0.09624389559030533\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12550 Loss  0.09621735662221909\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12560 Loss  0.09619064629077911\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12570 Loss  0.09616398066282272\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12580 Loss  0.09613712131977081\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12590 Loss  0.09611018747091293\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12600 Loss  0.09608325362205505\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12610 Loss  0.0960562601685524\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  12620 Loss  0.09602927416563034\n",
      "Training accuracy is  0.9762620192307693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  12630 Loss  0.09600213170051575\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12640 Loss  0.09597491472959518\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12650 Loss  0.09594763815402985\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12660 Loss  0.09592049568891525\n",
      "Training accuracy is  0.9763371394230769\n",
      "Epoch  12670 Loss  0.09589305520057678\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12680 Loss  0.09586568921804428\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12690 Loss  0.09583832323551178\n",
      "Training accuracy is  0.9763371394230769\n",
      "Epoch  12700 Loss  0.09581077098846436\n",
      "Training accuracy is  0.9763371394230769\n",
      "Epoch  12710 Loss  0.09578314423561096\n",
      "Training accuracy is  0.9763371394230769\n",
      "Epoch  12720 Loss  0.09575565159320831\n",
      "Training accuracy is  0.9763371394230769\n",
      "Epoch  12730 Loss  0.0957278162240982\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12740 Loss  0.09570018202066422\n",
      "Training accuracy is  0.9763371394230769\n",
      "Epoch  12750 Loss  0.09567231684923172\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  12760 Loss  0.09564458578824997\n",
      "Training accuracy is  0.9764122596153846\n",
      "Epoch  12770 Loss  0.09561670571565628\n",
      "Training accuracy is  0.9764122596153846\n",
      "Epoch  12780 Loss  0.09558868408203125\n",
      "Training accuracy is  0.9764122596153846\n",
      "Epoch  12790 Loss  0.0955609381198883\n",
      "Training accuracy is  0.9764873798076923\n",
      "Epoch  12800 Loss  0.09553270041942596\n",
      "Training accuracy is  0.9763371394230769\n",
      "Epoch  12810 Loss  0.09550457447767258\n",
      "Training accuracy is  0.9764122596153846\n",
      "Epoch  12820 Loss  0.09547678381204605\n",
      "Training accuracy is  0.9764873798076923\n",
      "Epoch  12830 Loss  0.09544812142848969\n",
      "Training accuracy is  0.9765625\n",
      "Epoch  12840 Loss  0.09542028605937958\n",
      "Training accuracy is  0.9764873798076923\n",
      "Epoch  12850 Loss  0.09539156407117844\n",
      "Training accuracy is  0.9764873798076923\n",
      "Epoch  12860 Loss  0.09536317735910416\n",
      "Training accuracy is  0.9766376201923077\n",
      "Epoch  12870 Loss  0.0953347384929657\n",
      "Training accuracy is  0.9765625\n",
      "Epoch  12880 Loss  0.09530610591173172\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  12890 Loss  0.09527783840894699\n",
      "Training accuracy is  0.9766376201923077\n",
      "Epoch  12900 Loss  0.09524905681610107\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  12910 Loss  0.09522023797035217\n",
      "Training accuracy is  0.9766376201923077\n",
      "Epoch  12920 Loss  0.09519218653440475\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  12930 Loss  0.09516283869743347\n",
      "Training accuracy is  0.9767878605769231\n",
      "Epoch  12940 Loss  0.09513461589813232\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  12950 Loss  0.0951048880815506\n",
      "Training accuracy is  0.9768629807692307\n",
      "Epoch  12960 Loss  0.09507588297128677\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  12970 Loss  0.09504825621843338\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  12980 Loss  0.09501819312572479\n",
      "Training accuracy is  0.9768629807692307\n",
      "Epoch  12990 Loss  0.09498859196901321\n",
      "Training accuracy is  0.9769381009615384\n",
      "Epoch  13000 Loss  0.0949605256319046\n",
      "Training accuracy is  0.9767878605769231\n",
      "Epoch  13010 Loss  0.09493035823106766\n",
      "Training accuracy is  0.9771634615384616\n",
      "Epoch  13020 Loss  0.09490171819925308\n",
      "Training accuracy is  0.9767878605769231\n",
      "Epoch  13030 Loss  0.09487337619066238\n",
      "Training accuracy is  0.9768629807692307\n",
      "Epoch  13040 Loss  0.09484204649925232\n",
      "Training accuracy is  0.9769381009615384\n",
      "Epoch  13050 Loss  0.09481268376111984\n",
      "Training accuracy is  0.9770132211538461\n",
      "Epoch  13060 Loss  0.09478268027305603\n",
      "Training accuracy is  0.9771634615384616\n",
      "Epoch  13070 Loss  0.09475399553775787\n",
      "Training accuracy is  0.9768629807692307\n",
      "Epoch  13080 Loss  0.09472323209047318\n",
      "Training accuracy is  0.9775390625\n",
      "Epoch  13090 Loss  0.09469366818666458\n",
      "Training accuracy is  0.9766376201923077\n",
      "Epoch  13100 Loss  0.09466331452131271\n",
      "Training accuracy is  0.9772385817307693\n",
      "Epoch  13110 Loss  0.09463365375995636\n",
      "Training accuracy is  0.9773888221153846\n",
      "Epoch  13120 Loss  0.09460677206516266\n",
      "Training accuracy is  0.9764873798076923\n",
      "Epoch  13130 Loss  0.09457206726074219\n",
      "Training accuracy is  0.9773137019230769\n",
      "Epoch  13140 Loss  0.09453727304935455\n",
      "Training accuracy is  0.9772385817307693\n",
      "Epoch  13150 Loss  0.09451916813850403\n",
      "Training accuracy is  0.9764873798076923\n",
      "Epoch  13160 Loss  0.09447633475065231\n",
      "Training accuracy is  0.9774639423076923\n",
      "Epoch  13170 Loss  0.09446115046739578\n",
      "Training accuracy is  0.9773888221153846\n",
      "Epoch  13180 Loss  0.0944209098815918\n",
      "Training accuracy is  0.9773137019230769\n",
      "Epoch  13190 Loss  0.09438745677471161\n",
      "Training accuracy is  0.9766376201923077\n",
      "Epoch  13200 Loss  0.09441667050123215\n",
      "Training accuracy is  0.9755859375\n",
      "Epoch  13210 Loss  0.09433376789093018\n",
      "Training accuracy is  0.9765625\n",
      "Epoch  13220 Loss  0.09428758919239044\n",
      "Training accuracy is  0.9771634615384616\n",
      "Epoch  13230 Loss  0.09443871676921844\n",
      "Training accuracy is  0.9792668269230769\n",
      "Epoch  13240 Loss  0.09480448067188263\n",
      "Training accuracy is  0.9802433894230769\n",
      "Epoch  13250 Loss  0.0942460373044014\n",
      "Training accuracy is  0.9755108173076923\n",
      "Epoch  13260 Loss  0.09439143538475037\n",
      "Training accuracy is  0.9748347355769231\n",
      "Epoch  13270 Loss  0.09415455907583237\n",
      "Training accuracy is  0.9765625\n",
      "Epoch  13280 Loss  0.09411417692899704\n",
      "Training accuracy is  0.9778395432692307\n",
      "Epoch  13290 Loss  0.0945780947804451\n",
      "Training accuracy is  0.9806189903846154\n",
      "Epoch  13300 Loss  0.09447698295116425\n",
      "Training accuracy is  0.9788912259615384\n",
      "Epoch  13310 Loss  0.09434343874454498\n",
      "Training accuracy is  0.974609375\n",
      "Epoch  13320 Loss  0.0940944105386734\n",
      "Training accuracy is  0.9787409855769231\n",
      "Epoch  13330 Loss  0.09395114332437515\n",
      "Training accuracy is  0.9774639423076923\n",
      "Epoch  13340 Loss  0.09398046135902405\n",
      "Training accuracy is  0.9756610576923077\n",
      "Epoch  13350 Loss  0.09434331953525543\n",
      "Training accuracy is  0.9734825721153846\n",
      "Epoch  13360 Loss  0.09389348328113556\n",
      "Training accuracy is  0.9767878605769231\n",
      "Epoch  13370 Loss  0.09395448118448257\n",
      "Training accuracy is  0.9789663461538461\n",
      "Epoch  13380 Loss  0.09422431886196136\n",
      "Training accuracy is  0.9802433894230769\n",
      "Epoch  13390 Loss  0.09380452334880829\n",
      "Training accuracy is  0.9779146634615384\n",
      "Epoch  13400 Loss  0.09380248934030533\n",
      "Training accuracy is  0.9756610576923077\n",
      "Epoch  13410 Loss  0.0943692997097969\n",
      "Training accuracy is  0.9719801682692307\n",
      "Epoch  13420 Loss  0.09370686113834381\n",
      "Training accuracy is  0.9771634615384616\n",
      "Epoch  13430 Loss  0.09390652924776077\n",
      "Training accuracy is  0.9796424278846154\n",
      "Epoch  13440 Loss  0.09362010657787323\n",
      "Training accuracy is  0.9772385817307693\n",
      "Epoch  13450 Loss  0.0936422199010849\n",
      "Training accuracy is  0.9755859375\n",
      "Epoch  13460 Loss  0.09423057734966278\n",
      "Training accuracy is  0.9719050480769231\n",
      "Epoch  13470 Loss  0.09352898597717285\n",
      "Training accuracy is  0.9773888221153846\n",
      "Epoch  13480 Loss  0.09374494850635529\n",
      "Training accuracy is  0.9796424278846154\n",
      "Epoch  13490 Loss  0.09346568584442139\n",
      "Training accuracy is  0.9773888221153846\n",
      "Epoch  13500 Loss  0.09347657114267349\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  13510 Loss  0.09412447363138199\n",
      "Training accuracy is  0.9714543269230769\n",
      "Epoch  13520 Loss  0.09339911490678787\n",
      "Training accuracy is  0.9776893028846154\n",
      "Epoch  13530 Loss  0.09356515854597092\n",
      "Training accuracy is  0.9792668269230769\n",
      "Epoch  13540 Loss  0.09329896420240402\n",
      "Training accuracy is  0.9770883413461539\n",
      "Epoch  13550 Loss  0.09339212626218796\n",
      "Training accuracy is  0.9752103365384616\n",
      "Epoch  13560 Loss  0.09387156367301941\n",
      "Training accuracy is  0.9729567307692307\n",
      "Epoch  13570 Loss  0.09319888800382614\n",
      "Training accuracy is  0.9776893028846154\n",
      "Epoch  13580 Loss  0.09343265742063522\n",
      "Training accuracy is  0.9799429086538461\n",
      "Epoch  13590 Loss  0.09322631359100342\n",
      "Training accuracy is  0.9786658653846154\n",
      "Epoch  13600 Loss  0.09310568869113922\n",
      "Training accuracy is  0.9773888221153846\n",
      "Epoch  13610 Loss  0.09326125681400299\n",
      "Training accuracy is  0.9748347355769231\n",
      "Epoch  13620 Loss  0.09438128024339676\n",
      "Training accuracy is  0.970703125\n",
      "Epoch  13630 Loss  0.09342590719461441\n",
      "Training accuracy is  0.98046875\n",
      "Epoch  13640 Loss  0.09302163124084473\n",
      "Training accuracy is  0.9764122596153846\n",
      "Epoch  13650 Loss  0.09299760311841965\n",
      "Training accuracy is  0.9766376201923077\n",
      "Epoch  13660 Loss  0.0929439440369606\n",
      "Training accuracy is  0.9782151442307693\n",
      "Epoch  13670 Loss  0.09312637150287628\n",
      "Training accuracy is  0.9801682692307693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  13680 Loss  0.0933842733502388\n",
      "Training accuracy is  0.9807692307692307\n",
      "Epoch  13690 Loss  0.09285710752010345\n",
      "Training accuracy is  0.9763371394230769\n",
      "Epoch  13700 Loss  0.09311450272798538\n",
      "Training accuracy is  0.9747596153846154\n",
      "Epoch  13710 Loss  0.09283939749002457\n",
      "Training accuracy is  0.9764122596153846\n",
      "Epoch  13720 Loss  0.09276214241981506\n",
      "Training accuracy is  0.978515625\n",
      "Epoch  13730 Loss  0.09327168762683868\n",
      "Training accuracy is  0.9808443509615384\n",
      "Epoch  13740 Loss  0.09303589910268784\n",
      "Training accuracy is  0.9797175480769231\n",
      "Epoch  13750 Loss  0.09294497966766357\n",
      "Training accuracy is  0.9749098557692307\n",
      "Epoch  13760 Loss  0.09262848645448685\n",
      "Training accuracy is  0.9776893028846154\n",
      "Epoch  13770 Loss  0.09271685779094696\n",
      "Training accuracy is  0.9793419471153846\n",
      "Epoch  13780 Loss  0.09285442531108856\n",
      "Training accuracy is  0.9802433894230769\n",
      "Epoch  13790 Loss  0.09264950454235077\n",
      "Training accuracy is  0.9788912259615384\n",
      "Epoch  13800 Loss  0.09248673170804977\n",
      "Training accuracy is  0.9779146634615384\n",
      "Epoch  13810 Loss  0.09248627722263336\n",
      "Training accuracy is  0.9770883413461539\n",
      "Epoch  13820 Loss  0.0928039401769638\n",
      "Training accuracy is  0.9738581730769231\n",
      "Epoch  13830 Loss  0.09343604743480682\n",
      "Training accuracy is  0.9739332932692307\n",
      "Epoch  13840 Loss  0.09272297471761703\n",
      "Training accuracy is  0.9794921875\n",
      "Epoch  13850 Loss  0.09247175604104996\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  13860 Loss  0.09238589555025101\n",
      "Training accuracy is  0.9789663461538461\n",
      "Epoch  13870 Loss  0.09229998290538788\n",
      "Training accuracy is  0.9765625\n",
      "Epoch  13880 Loss  0.09227459132671356\n",
      "Training accuracy is  0.9768629807692307\n",
      "Epoch  13890 Loss  0.09220290929079056\n",
      "Training accuracy is  0.9776893028846154\n",
      "Epoch  13900 Loss  0.09221692383289337\n",
      "Training accuracy is  0.9770883413461539\n",
      "Epoch  13910 Loss  0.092417873442173\n",
      "Training accuracy is  0.9742337740384616\n",
      "Epoch  13920 Loss  0.09309583157300949\n",
      "Training accuracy is  0.9728064903846154\n",
      "Epoch  13930 Loss  0.09236820787191391\n",
      "Training accuracy is  0.9805438701923077\n",
      "Epoch  13940 Loss  0.0920475423336029\n",
      "Training accuracy is  0.9776141826923077\n",
      "Epoch  13950 Loss  0.09213577955961227\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  13960 Loss  0.09206032007932663\n",
      "Training accuracy is  0.9765625\n",
      "Epoch  13970 Loss  0.09206061065196991\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  13980 Loss  0.0926712229847908\n",
      "Training accuracy is  0.9725811298076923\n",
      "Epoch  13990 Loss  0.0919482633471489\n",
      "Training accuracy is  0.9776141826923077\n",
      "Epoch  14000 Loss  0.09214573353528976\n",
      "Training accuracy is  0.98046875\n",
      "Epoch  14010 Loss  0.09183430671691895\n",
      "Training accuracy is  0.9776141826923077\n",
      "Epoch  14020 Loss  0.09197575598955154\n",
      "Training accuracy is  0.9755108173076923\n",
      "Epoch  14030 Loss  0.09237173199653625\n",
      "Training accuracy is  0.9737079326923077\n",
      "Epoch  14040 Loss  0.09174419939517975\n",
      "Training accuracy is  0.9787409855769231\n",
      "Epoch  14050 Loss  0.09197909384965897\n",
      "Training accuracy is  0.9806189903846154\n",
      "Epoch  14060 Loss  0.09188738465309143\n",
      "Training accuracy is  0.9800180288461539\n",
      "Epoch  14070 Loss  0.09165454655885696\n",
      "Training accuracy is  0.9782151442307693\n",
      "Epoch  14080 Loss  0.09166498482227325\n",
      "Training accuracy is  0.9768629807692307\n",
      "Epoch  14090 Loss  0.0927363932132721\n",
      "Training accuracy is  0.9704777644230769\n",
      "Epoch  14100 Loss  0.0915631353855133\n",
      "Training accuracy is  0.9789663461538461\n",
      "Epoch  14110 Loss  0.09158977121114731\n",
      "Training accuracy is  0.9788161057692307\n",
      "Epoch  14120 Loss  0.09162592887878418\n",
      "Training accuracy is  0.9766376201923077\n",
      "Epoch  14130 Loss  0.09151221066713333\n",
      "Training accuracy is  0.9788912259615384\n",
      "Epoch  14140 Loss  0.09159128367900848\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  14150 Loss  0.09156061708927155\n",
      "Training accuracy is  0.9797926682692307\n",
      "Epoch  14160 Loss  0.09147528558969498\n",
      "Training accuracy is  0.9794170673076923\n",
      "Epoch  14170 Loss  0.09164237231016159\n",
      "Training accuracy is  0.98046875\n",
      "Epoch  14180 Loss  0.09203846752643585\n",
      "Training accuracy is  0.9807692307692307\n",
      "Epoch  14190 Loss  0.09130149334669113\n",
      "Training accuracy is  0.9775390625\n",
      "Epoch  14200 Loss  0.09151005744934082\n",
      "Training accuracy is  0.9754356971153846\n",
      "Epoch  14210 Loss  0.09143086522817612\n",
      "Training accuracy is  0.9758864182692307\n",
      "Epoch  14220 Loss  0.09123796969652176\n",
      "Training accuracy is  0.9772385817307693\n",
      "Epoch  14230 Loss  0.09123378247022629\n",
      "Training accuracy is  0.9768629807692307\n",
      "Epoch  14240 Loss  0.09220273792743683\n",
      "Training accuracy is  0.9709284855769231\n",
      "Epoch  14250 Loss  0.09111868590116501\n",
      "Training accuracy is  0.9788161057692307\n",
      "Epoch  14260 Loss  0.09119685739278793\n",
      "Training accuracy is  0.9789663461538461\n",
      "Epoch  14270 Loss  0.09120357781648636\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  14280 Loss  0.09103532880544662\n",
      "Training accuracy is  0.9787409855769231\n",
      "Epoch  14290 Loss  0.09118486940860748\n",
      "Training accuracy is  0.98046875\n",
      "Epoch  14300 Loss  0.09127865731716156\n",
      "Training accuracy is  0.9808443509615384\n",
      "Epoch  14310 Loss  0.09094026684761047\n",
      "Training accuracy is  0.9784405048076923\n",
      "Epoch  14320 Loss  0.09101764857769012\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  14330 Loss  0.09190717339515686\n",
      "Training accuracy is  0.9725060096153846\n",
      "Epoch  14340 Loss  0.09087392687797546\n",
      "Training accuracy is  0.9795673076923077\n",
      "Epoch  14350 Loss  0.09097316861152649\n",
      "Training accuracy is  0.9797926682692307\n",
      "Epoch  14360 Loss  0.09085170179605484\n",
      "Training accuracy is  0.9768629807692307\n",
      "Epoch  14370 Loss  0.09100069105625153\n",
      "Training accuracy is  0.9755108173076923\n",
      "Epoch  14380 Loss  0.09096618741750717\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  14390 Loss  0.09073799103498459\n",
      "Training accuracy is  0.9779146634615384\n",
      "Epoch  14400 Loss  0.09069853276014328\n",
      "Training accuracy is  0.9779146634615384\n",
      "Epoch  14410 Loss  0.09090068936347961\n",
      "Training accuracy is  0.9751352163461539\n",
      "Epoch  14420 Loss  0.09210176765918732\n",
      "Training accuracy is  0.9718299278846154\n",
      "Epoch  14430 Loss  0.0911584347486496\n",
      "Training accuracy is  0.9812199519230769\n",
      "Epoch  14440 Loss  0.0906902402639389\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  14450 Loss  0.09051743149757385\n",
      "Training accuracy is  0.978515625\n",
      "Epoch  14460 Loss  0.0905933827161789\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  14470 Loss  0.09057287871837616\n",
      "Training accuracy is  0.9799429086538461\n",
      "Epoch  14480 Loss  0.09049297869205475\n",
      "Training accuracy is  0.9795673076923077\n",
      "Epoch  14490 Loss  0.0906267911195755\n",
      "Training accuracy is  0.9806189903846154\n",
      "Epoch  14500 Loss  0.09111947566270828\n",
      "Training accuracy is  0.9812950721153846\n",
      "Epoch  14510 Loss  0.09033858776092529\n",
      "Training accuracy is  0.9776141826923077\n",
      "Epoch  14520 Loss  0.09055142104625702\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  14530 Loss  0.09032604098320007\n",
      "Training accuracy is  0.9775390625\n",
      "Epoch  14540 Loss  0.09025350958108902\n",
      "Training accuracy is  0.9776893028846154\n",
      "Epoch  14550 Loss  0.09035544842481613\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  14560 Loss  0.09180664271116257\n",
      "Training accuracy is  0.9710787259615384\n",
      "Epoch  14570 Loss  0.09054835140705109\n",
      "Training accuracy is  0.9813701923076923\n",
      "Epoch  14580 Loss  0.09014899283647537\n",
      "Training accuracy is  0.9772385817307693\n",
      "Epoch  14590 Loss  0.09012239426374435\n",
      "Training accuracy is  0.9777644230769231\n",
      "Epoch  14600 Loss  0.09012378007173538\n",
      "Training accuracy is  0.9799429086538461\n",
      "Epoch  14610 Loss  0.09021195769309998\n",
      "Training accuracy is  0.9803936298076923\n",
      "Epoch  14620 Loss  0.09021912515163422\n",
      "Training accuracy is  0.9806941105769231\n",
      "Epoch  14630 Loss  0.09006109833717346\n",
      "Training accuracy is  0.9801682692307693\n",
      "Epoch  14640 Loss  0.09003961086273193\n",
      "Training accuracy is  0.98046875\n",
      "Epoch  14650 Loss  0.09045287221670151\n",
      "Training accuracy is  0.9814453125\n",
      "Epoch  14660 Loss  0.09023512899875641\n",
      "Training accuracy is  0.9809194711538461\n",
      "Epoch  14670 Loss  0.09004373848438263\n",
      "Training accuracy is  0.9761868990384616\n",
      "Epoch  14680 Loss  0.08989442884922028\n",
      "Training accuracy is  0.9776141826923077\n",
      "Epoch  14690 Loss  0.08979267627000809\n",
      "Training accuracy is  0.9796424278846154\n",
      "Epoch  14700 Loss  0.0901312455534935\n",
      "Training accuracy is  0.9813701923076923\n",
      "Epoch  14710 Loss  0.09045231342315674\n",
      "Training accuracy is  0.9813701923076923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  14720 Loss  0.08989235758781433\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  14730 Loss  0.08968368917703629\n",
      "Training accuracy is  0.9782151442307693\n",
      "Epoch  14740 Loss  0.08970840275287628\n",
      "Training accuracy is  0.9805438701923077\n",
      "Epoch  14750 Loss  0.08993847668170929\n",
      "Training accuracy is  0.9809945913461539\n",
      "Epoch  14760 Loss  0.08983039110898972\n",
      "Training accuracy is  0.9808443509615384\n",
      "Epoch  14770 Loss  0.08953411132097244\n",
      "Training accuracy is  0.9785907451923077\n",
      "Epoch  14780 Loss  0.08971136063337326\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  14790 Loss  0.09055217355489731\n",
      "Training accuracy is  0.9728816105769231\n",
      "Epoch  14800 Loss  0.08955739438533783\n",
      "Training accuracy is  0.9808443509615384\n",
      "Epoch  14810 Loss  0.08950796723365784\n",
      "Training accuracy is  0.9800931490384616\n",
      "Epoch  14820 Loss  0.08946161717176437\n",
      "Training accuracy is  0.9775390625\n",
      "Epoch  14830 Loss  0.08960187435150146\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  14840 Loss  0.08964286744594574\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  14850 Loss  0.08932176977396011\n",
      "Training accuracy is  0.9788161057692307\n",
      "Epoch  14860 Loss  0.08933249115943909\n",
      "Training accuracy is  0.98046875\n",
      "Epoch  14870 Loss  0.09010953456163406\n",
      "Training accuracy is  0.9825721153846154\n",
      "Epoch  14880 Loss  0.08931028097867966\n",
      "Training accuracy is  0.9794170673076923\n",
      "Epoch  14890 Loss  0.08947420865297318\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  14900 Loss  0.0891960933804512\n",
      "Training accuracy is  0.9800180288461539\n",
      "Epoch  14910 Loss  0.08922756463289261\n",
      "Training accuracy is  0.98046875\n",
      "Epoch  14920 Loss  0.08913930505514145\n",
      "Training accuracy is  0.9797926682692307\n",
      "Epoch  14930 Loss  0.08923745900392532\n",
      "Training accuracy is  0.9809194711538461\n",
      "Epoch  14940 Loss  0.09024100750684738\n",
      "Training accuracy is  0.9825721153846154\n",
      "Epoch  14950 Loss  0.08910072594881058\n",
      "Training accuracy is  0.9767878605769231\n",
      "Epoch  14960 Loss  0.0890885666012764\n",
      "Training accuracy is  0.9778395432692307\n",
      "Epoch  14970 Loss  0.08903229236602783\n",
      "Training accuracy is  0.9808443509615384\n",
      "Epoch  14980 Loss  0.08909904956817627\n",
      "Training accuracy is  0.9810697115384616\n",
      "Epoch  14990 Loss  0.08913281559944153\n",
      "Training accuracy is  0.9808443509615384\n"
     ]
    }
   ],
   "source": [
    "for i in parameters:\n",
    "    par.append(i)\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(2, i[0])\n",
    "            self.fc2 = nn.Linear(i[0], i[1])\n",
    "            self.fc7 = nn.Linear(i[1], 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc7(x)\n",
    "            return F.log_softmax(x)\n",
    "            #return F.softmax(x)\n",
    "        #%% plot function\n",
    "\n",
    "    def plot_data(X, y, filename):\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "    def plot_decision_boundary(clf, X, y, filename):\n",
    "        # Set min and max values and give it some padding\n",
    "        #x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "        #y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "        x_min, x_max = -1, 1\n",
    "        y_min, y_max = -1, 1\n",
    "        h = 0.01\n",
    "        # Generate a grid of points with distance h between them\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "        # Predict the function value for the whole gid\n",
    "        #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        X_out = net(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype = torch.float))\n",
    "        Z = X_out.data.max(1)[1]\n",
    "        # Z.shape\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        # Plot the contour and training examples\n",
    "        plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "    #%% train\n",
    "    net = Net()\n",
    "\n",
    "    # create a stochastic gradient descent optimizer\n",
    "    learning_rate = .01\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # create a loss function\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # nepochs = 10000\n",
    "    #nepochs = 3000 #10000\n",
    "    nepochs = 15000\n",
    "    data, target = X, y\n",
    "    # run the main training loop\n",
    "    best=0\n",
    "    best_l=0\n",
    "    for epoch in range(nepochs):\n",
    "    #    adjust learning rate if desired\n",
    "        if epoch % 3000 == 0 and epoch <= 24000:\n",
    "            for g in optimizer.param_groups:\n",
    "                   g['lr'] = g['lr']/2\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagate\n",
    "        net_out = net(data)\n",
    "        # compute loss\n",
    "        loss = criterion(net_out, target)\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # print out report\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "            net_out = net(data)\n",
    "            pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "            correctidx = pred.eq(target.data) \n",
    "            ncorrect = correctidx.sum()\n",
    "            accuracy = ncorrect.item()/len(data)\n",
    "            print('Training accuracy is ', accuracy)\n",
    "            if epoch>13000 and accuracy-0.001>best:\n",
    "                best=accuracy\n",
    "                best_l=loss.item()\n",
    "                torch.save(net, './question2a.01LR1610Epochs')\n",
    "\n",
    "            \n",
    "    accuracy_l.append(accuracy)\n",
    "    loss_l.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fd85915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9825721153846154\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d72777a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09010953456163406\n"
     ]
    }
   ],
   "source": [
    "# loss\n",
    "print(best_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a933a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "net1 = torch.load('./question2a.01LR1610Epochs')\n",
    "plot_decision_boundary(net1, X, y, 'Results0.0001.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c5d1449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is  0.9825721153846154\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net_out = net1(data)\n",
    "pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "correctidx = pred.eq(target.data) \n",
    "ncorrect = correctidx.sum()\n",
    "accuracy = ncorrect.item()/len(data)\n",
    "print('Training accuracy is ', accuracy)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=pred, cmap=plt.cm.Spectral, s = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60446613",
   "metadata": {},
   "source": [
    "#### (b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a912e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"Feedforward_Data_hexa.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "343f40b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.values[:, 0:2]  # Take only the first two features.     \n",
    "X = torch.tensor(X, dtype = torch.float)   \n",
    "y = data.values[:, 2]\n",
    "y = torch.tensor(y, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a376ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=[[80,100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "584716e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss  0.6575654745101929\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  10 Loss  0.257453978061676\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  20 Loss  0.19614076614379883\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  30 Loss  0.1807277947664261\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  40 Loss  0.16243694722652435\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  50 Loss  0.1422826647758484\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  60 Loss  0.12556080520153046\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  70 Loss  0.11271944642066956\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  80 Loss  0.1009385734796524\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  90 Loss  0.0918601006269455\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  100 Loss  0.08529786765575409\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  110 Loss  0.080609530210495\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  120 Loss  0.0773005411028862\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  130 Loss  0.07491924613714218\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  140 Loss  0.07287966459989548\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  150 Loss  0.07133077830076218\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  160 Loss  0.07019831240177155\n",
      "Training accuracy is  0.9405799278846154\n",
      "Epoch  170 Loss  0.06861402094364166\n",
      "Training accuracy is  0.9704777644230769\n",
      "Epoch  180 Loss  0.06737803667783737\n",
      "Training accuracy is  0.9706280048076923\n",
      "Epoch  190 Loss  0.06628039479255676\n",
      "Training accuracy is  0.9691256009615384\n",
      "Epoch  200 Loss  0.06528010219335556\n",
      "Training accuracy is  0.9740835336538461\n",
      "Epoch  210 Loss  0.06447552144527435\n",
      "Training accuracy is  0.9751352163461539\n",
      "Epoch  220 Loss  0.06381324678659439\n",
      "Training accuracy is  0.9758864182692307\n",
      "Epoch  230 Loss  0.06296824663877487\n",
      "Training accuracy is  0.9757361778846154\n",
      "Epoch  240 Loss  0.06199677661061287\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  250 Loss  0.06142451986670494\n",
      "Training accuracy is  0.9709284855769231\n",
      "Epoch  260 Loss  0.060921426862478256\n",
      "Training accuracy is  0.9748347355769231\n",
      "Epoch  270 Loss  0.05992268770933151\n",
      "Training accuracy is  0.9763371394230769\n",
      "Epoch  280 Loss  0.05920146033167839\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  290 Loss  0.05915220454335213\n",
      "Training accuracy is  0.9747596153846154\n",
      "Epoch  300 Loss  0.058229029178619385\n",
      "Training accuracy is  0.9764873798076923\n",
      "Epoch  310 Loss  0.057657960802316666\n",
      "Training accuracy is  0.9783653846153846\n",
      "Epoch  320 Loss  0.05719887465238571\n",
      "Training accuracy is  0.9753605769230769\n",
      "Epoch  330 Loss  0.056528910994529724\n",
      "Training accuracy is  0.9760366586538461\n",
      "Epoch  340 Loss  0.056244853883981705\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  350 Loss  0.0555555634200573\n",
      "Training accuracy is  0.9751352163461539\n",
      "Epoch  360 Loss  0.05507439747452736\n",
      "Training accuracy is  0.9765625\n",
      "Epoch  370 Loss  0.05457887426018715\n",
      "Training accuracy is  0.9773888221153846\n",
      "Epoch  380 Loss  0.05454982817173004\n",
      "Training accuracy is  0.9745342548076923\n",
      "Epoch  390 Loss  0.05396735295653343\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  400 Loss  0.05394258722662926\n",
      "Training accuracy is  0.9743840144230769\n",
      "Epoch  410 Loss  0.05270069092512131\n",
      "Training accuracy is  0.9749098557692307\n",
      "Epoch  420 Loss  0.052431102842092514\n",
      "Training accuracy is  0.9750600961538461\n",
      "Epoch  430 Loss  0.052464358508586884\n",
      "Training accuracy is  0.9767127403846154\n",
      "Epoch  440 Loss  0.051686618477106094\n",
      "Training accuracy is  0.9752854567307693\n",
      "Epoch  450 Loss  0.05119777470827103\n",
      "Training accuracy is  0.9752854567307693\n",
      "Epoch  460 Loss  0.05090201646089554\n",
      "Training accuracy is  0.9749098557692307\n",
      "Epoch  470 Loss  0.05070263519883156\n",
      "Training accuracy is  0.9743840144230769\n",
      "Epoch  480 Loss  0.05065715312957764\n",
      "Training accuracy is  0.978515625\n",
      "Epoch  490 Loss  0.05022629350423813\n",
      "Training accuracy is  0.974609375\n",
      "Epoch  500 Loss  0.04962911084294319\n",
      "Training accuracy is  0.9754356971153846\n",
      "Epoch  510 Loss  0.049606118351221085\n",
      "Training accuracy is  0.9755108173076923\n",
      "Epoch  520 Loss  0.049386318773031235\n",
      "Training accuracy is  0.9758864182692307\n",
      "Epoch  530 Loss  0.049010634422302246\n",
      "Training accuracy is  0.9755859375\n",
      "Epoch  540 Loss  0.048637211322784424\n",
      "Training accuracy is  0.9757361778846154\n",
      "Epoch  550 Loss  0.048366788774728775\n",
      "Training accuracy is  0.9766376201923077\n",
      "Epoch  560 Loss  0.04822077602148056\n",
      "Training accuracy is  0.9784405048076923\n",
      "Epoch  570 Loss  0.04815222695469856\n",
      "Training accuracy is  0.9794921875\n",
      "Epoch  580 Loss  0.04799553379416466\n",
      "Training accuracy is  0.9799429086538461\n",
      "Epoch  590 Loss  0.047838859260082245\n",
      "Training accuracy is  0.9800180288461539\n",
      "Epoch  600 Loss  0.047547873109579086\n",
      "Training accuracy is  0.9806189903846154\n",
      "Epoch  610 Loss  0.04740816727280617\n",
      "Training accuracy is  0.9800931490384616\n",
      "Epoch  620 Loss  0.04710527881979942\n",
      "Training accuracy is  0.9808443509615384\n",
      "Epoch  630 Loss  0.04698524996638298\n",
      "Training accuracy is  0.98046875\n",
      "Epoch  640 Loss  0.04692288115620613\n",
      "Training accuracy is  0.9761117788461539\n",
      "Epoch  650 Loss  0.04637908190488815\n",
      "Training accuracy is  0.9812199519230769\n",
      "Epoch  660 Loss  0.04587968438863754\n",
      "Training accuracy is  0.9759615384615384\n",
      "Epoch  670 Loss  0.04543150216341019\n",
      "Training accuracy is  0.9763371394230769\n",
      "Epoch  680 Loss  0.04515897482633591\n",
      "Training accuracy is  0.9765625\n",
      "Epoch  690 Loss  0.04496220499277115\n",
      "Training accuracy is  0.9768629807692307\n",
      "Epoch  700 Loss  0.045065440237522125\n",
      "Training accuracy is  0.9768629807692307\n",
      "Epoch  710 Loss  0.044898033142089844\n",
      "Training accuracy is  0.9791165865384616\n",
      "Epoch  720 Loss  0.04438406601548195\n",
      "Training accuracy is  0.978515625\n",
      "Epoch  730 Loss  0.04418804123997688\n",
      "Training accuracy is  0.9767878605769231\n",
      "Epoch  740 Loss  0.04419540613889694\n",
      "Training accuracy is  0.9815955528846154\n",
      "Epoch  750 Loss  0.04436741769313812\n",
      "Training accuracy is  0.9762620192307693\n",
      "Epoch  760 Loss  0.04454763978719711\n",
      "Training accuracy is  0.9832481971153846\n",
      "Epoch  770 Loss  0.044572874903678894\n",
      "Training accuracy is  0.9766376201923077\n",
      "Epoch  780 Loss  0.044133465737104416\n",
      "Training accuracy is  0.9814453125\n",
      "Epoch  790 Loss  0.043799396604299545\n",
      "Training accuracy is  0.9771634615384616\n",
      "Epoch  800 Loss  0.04381663352251053\n",
      "Training accuracy is  0.9820462740384616\n",
      "Epoch  810 Loss  0.042706314474344254\n",
      "Training accuracy is  0.9776893028846154\n",
      "Epoch  820 Loss  0.042486391961574554\n",
      "Training accuracy is  0.9788912259615384\n",
      "Epoch  830 Loss  0.04355489835143089\n",
      "Training accuracy is  0.9773888221153846\n",
      "Epoch  840 Loss  0.04310686141252518\n",
      "Training accuracy is  0.9836237980769231\n",
      "Epoch  850 Loss  0.04213565215468407\n",
      "Training accuracy is  0.9776893028846154\n",
      "Epoch  860 Loss  0.04177861660718918\n",
      "Training accuracy is  0.9806941105769231\n",
      "Epoch  870 Loss  0.04178061708807945\n",
      "Training accuracy is  0.9809194711538461\n",
      "Epoch  880 Loss  0.04242590814828873\n",
      "Training accuracy is  0.9779146634615384\n",
      "Epoch  890 Loss  0.04281190410256386\n",
      "Training accuracy is  0.9836989182692307\n",
      "Epoch  900 Loss  0.04176763817667961\n",
      "Training accuracy is  0.9774639423076923\n",
      "Epoch  910 Loss  0.041127461940050125\n",
      "Training accuracy is  0.982421875\n",
      "Epoch  920 Loss  0.04087548702955246\n",
      "Training accuracy is  0.9791165865384616\n",
      "Epoch  930 Loss  0.04083126038312912\n",
      "Training accuracy is  0.9801682692307693\n",
      "Epoch  940 Loss  0.04136529192328453\n",
      "Training accuracy is  0.9824969951923077\n",
      "Epoch  950 Loss  0.04202497750520706\n",
      "Training accuracy is  0.9776141826923077\n",
      "Epoch  960 Loss  0.04169915243983269\n",
      "Training accuracy is  0.9839993990384616\n",
      "Epoch  970 Loss  0.04063563048839569\n",
      "Training accuracy is  0.9778395432692307\n",
      "Epoch  980 Loss  0.04007059335708618\n",
      "Training accuracy is  0.9823467548076923\n",
      "Epoch  990 Loss  0.039953187108039856\n",
      "Training accuracy is  0.9816706730769231\n",
      "Epoch  1000 Loss  0.040688399225473404\n",
      "Training accuracy is  0.9791165865384616\n",
      "Epoch  1010 Loss  0.04126542806625366\n",
      "Training accuracy is  0.9836237980769231\n",
      "Epoch  1020 Loss  0.04082891717553139\n",
      "Training accuracy is  0.9775390625\n",
      "Epoch  1030 Loss  0.039557501673698425\n",
      "Training accuracy is  0.9826472355769231\n",
      "Epoch  1040 Loss  0.03925400972366333\n",
      "Training accuracy is  0.9816706730769231\n",
      "Epoch  1050 Loss  0.04036829248070717\n",
      "Training accuracy is  0.9788912259615384\n",
      "Epoch  1060 Loss  0.04063425213098526\n",
      "Training accuracy is  0.9846003605769231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1070 Loss  0.03931599482893944\n",
      "Training accuracy is  0.9785907451923077\n",
      "Epoch  1080 Loss  0.038736604154109955\n",
      "Training accuracy is  0.982421875\n",
      "Epoch  1090 Loss  0.03948104754090309\n",
      "Training accuracy is  0.9828725961538461\n",
      "Epoch  1100 Loss  0.04035932198166847\n",
      "Training accuracy is  0.9776893028846154\n",
      "Epoch  1110 Loss  0.03886813670396805\n",
      "Training accuracy is  0.9837740384615384\n",
      "Epoch  1120 Loss  0.03826557844877243\n",
      "Training accuracy is  0.9812199519230769\n",
      "Epoch  1130 Loss  0.038712028414011\n",
      "Training accuracy is  0.9808443509615384\n",
      "Epoch  1140 Loss  0.0398649238049984\n",
      "Training accuracy is  0.9847506009615384\n",
      "Epoch  1150 Loss  0.03872125968337059\n",
      "Training accuracy is  0.9792668269230769\n",
      "Epoch  1160 Loss  0.03781728446483612\n",
      "Training accuracy is  0.9824969951923077\n",
      "Epoch  1170 Loss  0.03890686482191086\n",
      "Training accuracy is  0.9833233173076923\n",
      "Epoch  1180 Loss  0.039596181362867355\n",
      "Training accuracy is  0.9785907451923077\n",
      "Epoch  1190 Loss  0.037906404584646225\n",
      "Training accuracy is  0.9839993990384616\n",
      "Epoch  1200 Loss  0.03745443746447563\n",
      "Training accuracy is  0.9821213942307693\n",
      "Epoch  1210 Loss  0.0388374850153923\n",
      "Training accuracy is  0.9797175480769231\n",
      "Epoch  1220 Loss  0.038227714598178864\n",
      "Training accuracy is  0.9846003605769231\n",
      "Epoch  1230 Loss  0.03711092472076416\n",
      "Training accuracy is  0.9821213942307693\n",
      "Epoch  1240 Loss  0.03890085965394974\n",
      "Training accuracy is  0.9795673076923077\n",
      "Epoch  1250 Loss  0.03719150274991989\n",
      "Training accuracy is  0.9834735576923077\n",
      "Epoch  1260 Loss  0.03745462745428085\n",
      "Training accuracy is  0.9829477163461539\n",
      "Epoch  1270 Loss  0.03745906054973602\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  1280 Loss  0.03686737269163132\n",
      "Training accuracy is  0.9819711538461539\n",
      "Epoch  1290 Loss  0.038590703159570694\n",
      "Training accuracy is  0.9852764423076923\n",
      "Epoch  1300 Loss  0.03648804873228073\n",
      "Training accuracy is  0.982421875\n",
      "Epoch  1310 Loss  0.03885424882173538\n",
      "Training accuracy is  0.9791165865384616\n",
      "Epoch  1320 Loss  0.03655804693698883\n",
      "Training accuracy is  0.9835486778846154\n",
      "Epoch  1330 Loss  0.03692839667201042\n",
      "Training accuracy is  0.9828725961538461\n",
      "Epoch  1340 Loss  0.037073973566293716\n",
      "Training accuracy is  0.9799429086538461\n",
      "Epoch  1350 Loss  0.03618406876921654\n",
      "Training accuracy is  0.9827223557692307\n",
      "Epoch  1360 Loss  0.038447726517915726\n",
      "Training accuracy is  0.9854266826923077\n",
      "Epoch  1370 Loss  0.03601052984595299\n",
      "Training accuracy is  0.9817457932692307\n",
      "Epoch  1380 Loss  0.03735295683145523\n",
      "Training accuracy is  0.9809945913461539\n",
      "Epoch  1390 Loss  0.03620477765798569\n",
      "Training accuracy is  0.9839242788461539\n",
      "Epoch  1400 Loss  0.03620279207825661\n",
      "Training accuracy is  0.9829477163461539\n",
      "Epoch  1410 Loss  0.03708014264702797\n",
      "Training accuracy is  0.9797175480769231\n",
      "Epoch  1420 Loss  0.03560942783951759\n",
      "Training accuracy is  0.9827974759615384\n",
      "Epoch  1430 Loss  0.03789914399385452\n",
      "Training accuracy is  0.9856520432692307\n",
      "Epoch  1440 Loss  0.035441987216472626\n",
      "Training accuracy is  0.982421875\n",
      "Epoch  1450 Loss  0.03755505010485649\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  1460 Loss  0.03550904244184494\n",
      "Training accuracy is  0.9836989182692307\n",
      "Epoch  1470 Loss  0.03628109395503998\n",
      "Training accuracy is  0.9838491586538461\n",
      "Epoch  1480 Loss  0.035889748483896255\n",
      "Training accuracy is  0.9810697115384616\n",
      "Epoch  1490 Loss  0.03535589203238487\n",
      "Training accuracy is  0.9824969951923077\n",
      "Epoch  1500 Loss  0.0369824543595314\n",
      "Training accuracy is  0.9855769230769231\n",
      "Epoch  1510 Loss  0.034983161836862564\n",
      "Training accuracy is  0.9829477163461539\n",
      "Epoch  1520 Loss  0.03725098446011543\n",
      "Training accuracy is  0.9799429086538461\n",
      "Epoch  1530 Loss  0.03492402285337448\n",
      "Training accuracy is  0.9830228365384616\n",
      "Epoch  1540 Loss  0.03665754944086075\n",
      "Training accuracy is  0.9849759615384616\n",
      "Epoch  1550 Loss  0.035241395235061646\n",
      "Training accuracy is  0.9816706730769231\n",
      "Epoch  1560 Loss  0.035201460123062134\n",
      "Training accuracy is  0.9821213942307693\n",
      "Epoch  1570 Loss  0.0353660061955452\n",
      "Training accuracy is  0.9853515625\n",
      "Epoch  1580 Loss  0.03485213965177536\n",
      "Training accuracy is  0.9830979567307693\n",
      "Epoch  1590 Loss  0.03634908050298691\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  1600 Loss  0.034414634108543396\n",
      "Training accuracy is  0.9831730769230769\n",
      "Epoch  1610 Loss  0.03734448924660683\n",
      "Training accuracy is  0.9858774038461539\n",
      "Epoch  1620 Loss  0.034325722604990005\n",
      "Training accuracy is  0.9825721153846154\n",
      "Epoch  1630 Loss  0.03608937934041023\n",
      "Training accuracy is  0.9812199519230769\n",
      "Epoch  1640 Loss  0.034387942403554916\n",
      "Training accuracy is  0.9844501201923077\n",
      "Epoch  1650 Loss  0.035494353622198105\n",
      "Training accuracy is  0.9844501201923077\n",
      "Epoch  1660 Loss  0.03460877388715744\n",
      "Training accuracy is  0.9815955528846154\n",
      "Epoch  1670 Loss  0.034515801817178726\n",
      "Training accuracy is  0.9823467548076923\n",
      "Epoch  1680 Loss  0.03534076735377312\n",
      "Training accuracy is  0.9859525240384616\n",
      "Epoch  1690 Loss  0.03389353305101395\n",
      "Training accuracy is  0.9833984375\n",
      "Epoch  1700 Loss  0.03645528480410576\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  1710 Loss  0.03370939940214157\n",
      "Training accuracy is  0.9835486778846154\n",
      "Epoch  1720 Loss  0.036768946796655655\n",
      "Training accuracy is  0.9860276442307693\n",
      "Epoch  1730 Loss  0.03361828252673149\n",
      "Training accuracy is  0.9830979567307693\n",
      "Epoch  1740 Loss  0.03627679869532585\n",
      "Training accuracy is  0.9803185096153846\n",
      "Epoch  1750 Loss  0.033689919859170914\n",
      "Training accuracy is  0.9851262019230769\n",
      "Epoch  1760 Loss  0.03492524474859238\n",
      "Training accuracy is  0.9856520432692307\n",
      "Epoch  1770 Loss  0.03399190679192543\n",
      "Training accuracy is  0.9818209134615384\n",
      "Epoch  1780 Loss  0.03384162858128548\n",
      "Training accuracy is  0.9829477163461539\n",
      "Epoch  1790 Loss  0.034398555755615234\n",
      "Training accuracy is  0.986328125\n",
      "Epoch  1800 Loss  0.033349890261888504\n",
      "Training accuracy is  0.984375\n",
      "Epoch  1810 Loss  0.03545953333377838\n",
      "Training accuracy is  0.9797926682692307\n",
      "Epoch  1820 Loss  0.03298033028841019\n",
      "Training accuracy is  0.9842998798076923\n",
      "Epoch  1830 Loss  0.03617575764656067\n",
      "Training accuracy is  0.9860276442307693\n",
      "Epoch  1840 Loss  0.03286118060350418\n",
      "Training accuracy is  0.9833984375\n",
      "Epoch  1850 Loss  0.03577912971377373\n",
      "Training accuracy is  0.9799429086538461\n",
      "Epoch  1860 Loss  0.03273617848753929\n",
      "Training accuracy is  0.9849759615384616\n",
      "Epoch  1870 Loss  0.036824826151132584\n",
      "Training accuracy is  0.9861778846153846\n",
      "Epoch  1880 Loss  0.03274456411600113\n",
      "Training accuracy is  0.9831730769230769\n",
      "Epoch  1890 Loss  0.03445914015173912\n",
      "Training accuracy is  0.9821213942307693\n",
      "Epoch  1900 Loss  0.033123575150966644\n",
      "Training accuracy is  0.9869290865384616\n",
      "Epoch  1910 Loss  0.03320378437638283\n",
      "Training accuracy is  0.9861778846153846\n",
      "Epoch  1920 Loss  0.03359554708003998\n",
      "Training accuracy is  0.9816706730769231\n",
      "Epoch  1930 Loss  0.03257548063993454\n",
      "Training accuracy is  0.9836237980769231\n",
      "Epoch  1940 Loss  0.033929575234651566\n",
      "Training accuracy is  0.9868539663461539\n",
      "Epoch  1950 Loss  0.03232881799340248\n",
      "Training accuracy is  0.9859525240384616\n",
      "Epoch  1960 Loss  0.03423326462507248\n",
      "Training accuracy is  0.9799429086538461\n",
      "Epoch  1970 Loss  0.03212183341383934\n",
      "Training accuracy is  0.9849759615384616\n",
      "Epoch  1980 Loss  0.03400787338614464\n",
      "Training accuracy is  0.9868539663461539\n",
      "Epoch  1990 Loss  0.03198971599340439\n",
      "Training accuracy is  0.9855769230769231\n",
      "Epoch  2000 Loss  0.03495561331510544\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  2010 Loss  0.03176625818014145\n",
      "Training accuracy is  0.9861027644230769\n",
      "Epoch  2020 Loss  0.03533592075109482\n",
      "Training accuracy is  0.9864783653846154\n",
      "Epoch  2030 Loss  0.03165387362241745\n",
      "Training accuracy is  0.9855018028846154\n",
      "Epoch  2040 Loss  0.03483753651380539\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  2050 Loss  0.03154231607913971\n",
      "Training accuracy is  0.9858774038461539\n",
      "Epoch  2060 Loss  0.032362379133701324\n",
      "Training accuracy is  0.9873798076923077\n",
      "Epoch  2070 Loss  0.032041460275650024\n",
      "Training accuracy is  0.9871544471153846\n",
      "Epoch  2080 Loss  0.03425471857190132\n",
      "Training accuracy is  0.9797926682692307\n",
      "Epoch  2090 Loss  0.031351931393146515\n",
      "Training accuracy is  0.9861778846153846\n",
      "Epoch  2100 Loss  0.03280935436487198\n",
      "Training accuracy is  0.9876051682692307\n",
      "Epoch  2110 Loss  0.03152943775057793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is  0.9873798076923077\n",
      "Epoch  2120 Loss  0.03359074890613556\n",
      "Training accuracy is  0.9801682692307693\n",
      "Epoch  2130 Loss  0.03130166605114937\n",
      "Training accuracy is  0.9861027644230769\n",
      "Epoch  2140 Loss  0.031691621989011765\n",
      "Training accuracy is  0.9875300480769231\n",
      "Epoch  2150 Loss  0.03255784884095192\n",
      "Training accuracy is  0.9872295673076923\n",
      "Epoch  2160 Loss  0.032420191913843155\n",
      "Training accuracy is  0.9809194711538461\n",
      "Epoch  2170 Loss  0.03143056482076645\n",
      "Training accuracy is  0.9854266826923077\n",
      "Epoch  2180 Loss  0.031247390434145927\n",
      "Training accuracy is  0.9872295673076923\n",
      "Epoch  2190 Loss  0.03355789929628372\n",
      "Training accuracy is  0.9877554086538461\n",
      "Epoch  2200 Loss  0.03148509934544563\n",
      "Training accuracy is  0.9827223557692307\n",
      "Epoch  2210 Loss  0.031945355236530304\n",
      "Training accuracy is  0.9839242788461539\n",
      "Epoch  2220 Loss  0.03103627823293209\n",
      "Training accuracy is  0.9874549278846154\n",
      "Epoch  2230 Loss  0.03362283483147621\n",
      "Training accuracy is  0.9879807692307693\n",
      "Epoch  2240 Loss  0.030861446633934975\n",
      "Training accuracy is  0.9852013221153846\n",
      "Epoch  2250 Loss  0.033222589641809464\n",
      "Training accuracy is  0.9813701923076923\n",
      "Epoch  2260 Loss  0.03081001155078411\n",
      "Training accuracy is  0.9876802884615384\n",
      "Epoch  2270 Loss  0.03320329636335373\n",
      "Training accuracy is  0.9879056490384616\n",
      "Epoch  2280 Loss  0.030456237494945526\n",
      "Training accuracy is  0.9861778846153846\n",
      "Epoch  2290 Loss  0.03435630351305008\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  2300 Loss  0.030478771775960922\n",
      "Training accuracy is  0.9875300480769231\n",
      "Epoch  2310 Loss  0.033458031713962555\n",
      "Training accuracy is  0.9880558894230769\n",
      "Epoch  2320 Loss  0.030262818560004234\n",
      "Training accuracy is  0.9867037259615384\n",
      "Epoch  2330 Loss  0.0340726375579834\n",
      "Training accuracy is  0.9800931490384616\n",
      "Epoch  2340 Loss  0.030162833631038666\n",
      "Training accuracy is  0.9874549278846154\n",
      "Epoch  2350 Loss  0.033922288566827774\n",
      "Training accuracy is  0.9876802884615384\n",
      "Epoch  2360 Loss  0.029991764575242996\n",
      "Training accuracy is  0.9868539663461539\n",
      "Epoch  2370 Loss  0.0337313748896122\n",
      "Training accuracy is  0.9798677884615384\n",
      "Epoch  2380 Loss  0.02991047501564026\n",
      "Training accuracy is  0.9873798076923077\n",
      "Epoch  2390 Loss  0.03376785293221474\n",
      "Training accuracy is  0.9873798076923077\n",
      "Epoch  2400 Loss  0.02980334870517254\n",
      "Training accuracy is  0.9867788461538461\n",
      "Epoch  2410 Loss  0.03328489512205124\n",
      "Training accuracy is  0.9799429086538461\n",
      "Epoch  2420 Loss  0.029718609526753426\n",
      "Training accuracy is  0.9875300480769231\n",
      "Epoch  2430 Loss  0.033593423664569855\n",
      "Training accuracy is  0.9873046875\n",
      "Epoch  2440 Loss  0.029639512300491333\n",
      "Training accuracy is  0.9869290865384616\n",
      "Epoch  2450 Loss  0.033030059188604355\n",
      "Training accuracy is  0.9802433894230769\n",
      "Epoch  2460 Loss  0.029573626816272736\n",
      "Training accuracy is  0.9877554086538461\n",
      "Epoch  2470 Loss  0.03297531232237816\n",
      "Training accuracy is  0.9874549278846154\n",
      "Epoch  2480 Loss  0.02953619509935379\n",
      "Training accuracy is  0.9876802884615384\n",
      "Epoch  2490 Loss  0.0321098268032074\n",
      "Training accuracy is  0.9808443509615384\n",
      "Epoch  2500 Loss  0.02962772361934185\n",
      "Training accuracy is  0.9867788461538461\n",
      "Epoch  2510 Loss  0.030995650216937065\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  2520 Loss  0.030142880976200104\n",
      "Training accuracy is  0.9879056490384616\n",
      "Epoch  2530 Loss  0.03065921552479267\n",
      "Training accuracy is  0.9832481971153846\n",
      "Epoch  2540 Loss  0.030193878337740898\n",
      "Training accuracy is  0.9865534855769231\n",
      "Epoch  2550 Loss  0.030001414939761162\n",
      "Training accuracy is  0.9892578125\n",
      "Epoch  2560 Loss  0.03139752522110939\n",
      "Training accuracy is  0.9892578125\n",
      "Epoch  2570 Loss  0.029538601636886597\n",
      "Training accuracy is  0.986328125\n",
      "Epoch  2580 Loss  0.03213821351528168\n",
      "Training accuracy is  0.9826472355769231\n",
      "Epoch  2590 Loss  0.029227908700704575\n",
      "Training accuracy is  0.9879056490384616\n",
      "Epoch  2600 Loss  0.03404988348484039\n",
      "Training accuracy is  0.9876051682692307\n",
      "Epoch  2610 Loss  0.029256949201226234\n",
      "Training accuracy is  0.9867037259615384\n",
      "Epoch  2620 Loss  0.032059427350759506\n",
      "Training accuracy is  0.982421875\n",
      "Epoch  2630 Loss  0.02894653007388115\n",
      "Training accuracy is  0.9876802884615384\n",
      "Epoch  2640 Loss  0.03374170511960983\n",
      "Training accuracy is  0.9873046875\n",
      "Epoch  2650 Loss  0.028839442878961563\n",
      "Training accuracy is  0.9870793269230769\n",
      "Epoch  2660 Loss  0.032522864639759064\n",
      "Training accuracy is  0.9808443509615384\n",
      "Epoch  2670 Loss  0.028780993074178696\n",
      "Training accuracy is  0.9879807692307693\n",
      "Epoch  2680 Loss  0.032381199300289154\n",
      "Training accuracy is  0.9874549278846154\n",
      "Epoch  2690 Loss  0.028804663568735123\n",
      "Training accuracy is  0.9881310096153846\n",
      "Epoch  2700 Loss  0.031218143180012703\n",
      "Training accuracy is  0.9817457932692307\n",
      "Epoch  2710 Loss  0.028934795409440994\n",
      "Training accuracy is  0.9872295673076923\n",
      "Epoch  2720 Loss  0.030459236353635788\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  2730 Loss  0.029453281313180923\n",
      "Training accuracy is  0.9880558894230769\n",
      "Epoch  2740 Loss  0.02964576706290245\n",
      "Training accuracy is  0.9847506009615384\n",
      "Epoch  2750 Loss  0.030163563787937164\n",
      "Training accuracy is  0.9858022836538461\n",
      "Epoch  2760 Loss  0.02909240499138832\n",
      "Training accuracy is  0.9889573317307693\n",
      "Epoch  2770 Loss  0.03141983970999718\n",
      "Training accuracy is  0.9889573317307693\n",
      "Epoch  2780 Loss  0.02881820872426033\n",
      "Training accuracy is  0.9866286057692307\n",
      "Epoch  2790 Loss  0.03157099336385727\n",
      "Training accuracy is  0.9836237980769231\n",
      "Epoch  2800 Loss  0.028538759797811508\n",
      "Training accuracy is  0.9882061298076923\n",
      "Epoch  2810 Loss  0.03289657458662987\n",
      "Training accuracy is  0.9877554086538461\n",
      "Epoch  2820 Loss  0.02833365462720394\n",
      "Training accuracy is  0.9872295673076923\n",
      "Epoch  2830 Loss  0.03229517862200737\n",
      "Training accuracy is  0.9813701923076923\n",
      "Epoch  2840 Loss  0.028210800141096115\n",
      "Training accuracy is  0.98828125\n",
      "Epoch  2850 Loss  0.03245505690574646\n",
      "Training accuracy is  0.9873798076923077\n",
      "Epoch  2860 Loss  0.028191085904836655\n",
      "Training accuracy is  0.9881310096153846\n",
      "Epoch  2870 Loss  0.03112916462123394\n",
      "Training accuracy is  0.9818209134615384\n",
      "Epoch  2880 Loss  0.028295956552028656\n",
      "Training accuracy is  0.9876051682692307\n",
      "Epoch  2890 Loss  0.03067108243703842\n",
      "Training accuracy is  0.9881310096153846\n",
      "Epoch  2900 Loss  0.028503619134426117\n",
      "Training accuracy is  0.9881310096153846\n",
      "Epoch  2910 Loss  0.029672522097826004\n",
      "Training accuracy is  0.984375\n",
      "Epoch  2920 Loss  0.029035955667495728\n",
      "Training accuracy is  0.9870042067307693\n",
      "Epoch  2930 Loss  0.02848399616777897\n",
      "Training accuracy is  0.9886568509615384\n",
      "Epoch  2940 Loss  0.03144760802388191\n",
      "Training accuracy is  0.9885817307692307\n",
      "Epoch  2950 Loss  0.02835915796458721\n",
      "Training accuracy is  0.9868539663461539\n",
      "Epoch  2960 Loss  0.030963974073529243\n",
      "Training accuracy is  0.9842247596153846\n",
      "Epoch  2970 Loss  0.027906222268939018\n",
      "Training accuracy is  0.9881310096153846\n",
      "Epoch  2980 Loss  0.03300416097044945\n",
      "Training accuracy is  0.9876051682692307\n",
      "Epoch  2990 Loss  0.027773793786764145\n",
      "Training accuracy is  0.9879807692307693\n",
      "Epoch  3000 Loss  0.031515736132860184\n",
      "Training accuracy is  0.9816706730769231\n",
      "Epoch  3010 Loss  0.027796875685453415\n",
      "Training accuracy is  0.9879056490384616\n",
      "Epoch  3020 Loss  0.030430300161242485\n",
      "Training accuracy is  0.9880558894230769\n",
      "Epoch  3030 Loss  0.028165344148874283\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  3040 Loss  0.02904273010790348\n",
      "Training accuracy is  0.9851262019230769\n",
      "Epoch  3050 Loss  0.028942009434103966\n",
      "Training accuracy is  0.9869290865384616\n",
      "Epoch  3060 Loss  0.028312576934695244\n",
      "Training accuracy is  0.9893329326923077\n",
      "Epoch  3070 Loss  0.030752085149288177\n",
      "Training accuracy is  0.9889573317307693\n",
      "Epoch  3080 Loss  0.02785460278391838\n",
      "Training accuracy is  0.9870793269230769\n",
      "Epoch  3090 Loss  0.03145267441868782\n",
      "Training accuracy is  0.9833233173076923\n",
      "Epoch  3100 Loss  0.027558280155062675\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  3110 Loss  0.03262895718216896\n",
      "Training accuracy is  0.9877554086538461\n",
      "Epoch  3120 Loss  0.027425719425082207\n",
      "Training accuracy is  0.9880558894230769\n",
      "Epoch  3130 Loss  0.03107183240354061\n",
      "Training accuracy is  0.9818209134615384\n",
      "Epoch  3140 Loss  0.02750091627240181\n",
      "Training accuracy is  0.9880558894230769\n",
      "Epoch  3150 Loss  0.029948363080620766\n",
      "Training accuracy is  0.9879056490384616\n",
      "Epoch  3160 Loss  0.027863968163728714\n",
      "Training accuracy is  0.9885066105769231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3170 Loss  0.028931226581335068\n",
      "Training accuracy is  0.9849008413461539\n",
      "Epoch  3180 Loss  0.028505023568868637\n",
      "Training accuracy is  0.9869290865384616\n",
      "Epoch  3190 Loss  0.02794463187456131\n",
      "Training accuracy is  0.9892578125\n",
      "Epoch  3200 Loss  0.03057672642171383\n",
      "Training accuracy is  0.9888070913461539\n",
      "Epoch  3210 Loss  0.027421623468399048\n",
      "Training accuracy is  0.9876051682692307\n",
      "Epoch  3220 Loss  0.031718719750642776\n",
      "Training accuracy is  0.9821965144230769\n",
      "Epoch  3230 Loss  0.02716788649559021\n",
      "Training accuracy is  0.9886568509615384\n",
      "Epoch  3240 Loss  0.031473901122808456\n",
      "Training accuracy is  0.9877554086538461\n",
      "Epoch  3250 Loss  0.02725285477936268\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  3260 Loss  0.028885383158922195\n",
      "Training accuracy is  0.9847506009615384\n",
      "Epoch  3270 Loss  0.028179693967103958\n",
      "Training accuracy is  0.9870793269230769\n",
      "Epoch  3280 Loss  0.028090890496969223\n",
      "Training accuracy is  0.9895582932692307\n",
      "Epoch  3290 Loss  0.02960989810526371\n",
      "Training accuracy is  0.9895582932692307\n",
      "Epoch  3300 Loss  0.02742697112262249\n",
      "Training accuracy is  0.9871544471153846\n",
      "Epoch  3310 Loss  0.03090381622314453\n",
      "Training accuracy is  0.9839242788461539\n",
      "Epoch  3320 Loss  0.02698792889714241\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  3330 Loss  0.03212864696979523\n",
      "Training accuracy is  0.9877554086538461\n",
      "Epoch  3340 Loss  0.026911068707704544\n",
      "Training accuracy is  0.9881310096153846\n",
      "Epoch  3350 Loss  0.029819369316101074\n",
      "Training accuracy is  0.9834735576923077\n",
      "Epoch  3360 Loss  0.027296455577015877\n",
      "Training accuracy is  0.9880558894230769\n",
      "Epoch  3370 Loss  0.027905229479074478\n",
      "Training accuracy is  0.9896334134615384\n",
      "Epoch  3380 Loss  0.029421044513583183\n",
      "Training accuracy is  0.9896334134615384\n",
      "Epoch  3390 Loss  0.027245797216892242\n",
      "Training accuracy is  0.9872295673076923\n",
      "Epoch  3400 Loss  0.030764328315854073\n",
      "Training accuracy is  0.9838491586538461\n",
      "Epoch  3410 Loss  0.026774557307362556\n",
      "Training accuracy is  0.9886568509615384\n",
      "Epoch  3420 Loss  0.03165340796113014\n",
      "Training accuracy is  0.9877554086538461\n",
      "Epoch  3430 Loss  0.02676783688366413\n",
      "Training accuracy is  0.98828125\n",
      "Epoch  3440 Loss  0.029328707605600357\n",
      "Training accuracy is  0.9839993990384616\n",
      "Epoch  3450 Loss  0.02723219059407711\n",
      "Training accuracy is  0.9878305288461539\n",
      "Epoch  3460 Loss  0.02805187553167343\n",
      "Training accuracy is  0.9890324519230769\n",
      "Epoch  3470 Loss  0.028603829443454742\n",
      "Training accuracy is  0.9894831730769231\n",
      "Epoch  3480 Loss  0.026986418291926384\n",
      "Training accuracy is  0.9875300480769231\n",
      "Epoch  3490 Loss  0.030944405123591423\n",
      "Training accuracy is  0.9838491586538461\n",
      "Epoch  3500 Loss  0.026583116501569748\n",
      "Training accuracy is  0.9886568509615384\n",
      "Epoch  3510 Loss  0.03178463131189346\n",
      "Training accuracy is  0.9878305288461539\n",
      "Epoch  3520 Loss  0.026546301320195198\n",
      "Training accuracy is  0.9883563701923077\n",
      "Epoch  3530 Loss  0.0291947852820158\n",
      "Training accuracy is  0.9836989182692307\n",
      "Epoch  3540 Loss  0.02701234631240368\n",
      "Training accuracy is  0.9880558894230769\n",
      "Epoch  3550 Loss  0.02774771861732006\n",
      "Training accuracy is  0.9892578125\n",
      "Epoch  3560 Loss  0.028518449515104294\n",
      "Training accuracy is  0.9896334134615384\n",
      "Epoch  3570 Loss  0.026764998212456703\n",
      "Training accuracy is  0.9879056490384616\n",
      "Epoch  3580 Loss  0.030838940292596817\n",
      "Training accuracy is  0.9839993990384616\n",
      "Epoch  3590 Loss  0.02653326466679573\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  3600 Loss  0.03155435621738434\n",
      "Training accuracy is  0.9879807692307693\n",
      "Epoch  3610 Loss  0.026325099170207977\n",
      "Training accuracy is  0.98828125\n",
      "Epoch  3620 Loss  0.02942950837314129\n",
      "Training accuracy is  0.9833233173076923\n",
      "Epoch  3630 Loss  0.02670404314994812\n",
      "Training accuracy is  0.9882061298076923\n",
      "Epoch  3640 Loss  0.027963774278759956\n",
      "Training accuracy is  0.9889573317307693\n",
      "Epoch  3650 Loss  0.027848972007632256\n",
      "Training accuracy is  0.9891826923076923\n",
      "Epoch  3660 Loss  0.02691034786403179\n",
      "Training accuracy is  0.9873046875\n",
      "Epoch  3670 Loss  0.02959458716213703\n",
      "Training accuracy is  0.9853515625\n",
      "Epoch  3680 Loss  0.02629813551902771\n",
      "Training accuracy is  0.9886568509615384\n",
      "Epoch  3690 Loss  0.03196525573730469\n",
      "Training accuracy is  0.9876802884615384\n",
      "Epoch  3700 Loss  0.026166243478655815\n",
      "Training accuracy is  0.9883563701923077\n",
      "Epoch  3710 Loss  0.028889885172247887\n",
      "Training accuracy is  0.9840745192307693\n",
      "Epoch  3720 Loss  0.026730289682745934\n",
      "Training accuracy is  0.9880558894230769\n",
      "Epoch  3730 Loss  0.027241311967372894\n",
      "Training accuracy is  0.9895582932692307\n",
      "Epoch  3740 Loss  0.028688909485936165\n",
      "Training accuracy is  0.9896334134615384\n",
      "Epoch  3750 Loss  0.026353849098086357\n",
      "Training accuracy is  0.9881310096153846\n",
      "Epoch  3760 Loss  0.030716827139258385\n",
      "Training accuracy is  0.9836989182692307\n",
      "Epoch  3770 Loss  0.0260499007999897\n",
      "Training accuracy is  0.9888070913461539\n",
      "Epoch  3780 Loss  0.03127771615982056\n",
      "Training accuracy is  0.9876802884615384\n",
      "Epoch  3790 Loss  0.026067089289426804\n",
      "Training accuracy is  0.9886568509615384\n",
      "Epoch  3800 Loss  0.028309818357229233\n",
      "Training accuracy is  0.9849759615384616\n",
      "Epoch  3810 Loss  0.026806680485606194\n",
      "Training accuracy is  0.9880558894230769\n",
      "Epoch  3820 Loss  0.026802856475114822\n",
      "Training accuracy is  0.9897085336538461\n",
      "Epoch  3830 Loss  0.029361294582486153\n",
      "Training accuracy is  0.9889573317307693\n",
      "Epoch  3840 Loss  0.025924891233444214\n",
      "Training accuracy is  0.9886568509615384\n",
      "Epoch  3850 Loss  0.030487461015582085\n",
      "Training accuracy is  0.9826472355769231\n",
      "Epoch  3860 Loss  0.026008278131484985\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  3870 Loss  0.027889378368854523\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  3880 Loss  0.02717897668480873\n",
      "Training accuracy is  0.9889573317307693\n",
      "Epoch  3890 Loss  0.026725895702838898\n",
      "Training accuracy is  0.9873798076923077\n",
      "Epoch  3900 Loss  0.02859495021402836\n",
      "Training accuracy is  0.9868539663461539\n",
      "Epoch  3910 Loss  0.02589249797165394\n",
      "Training accuracy is  0.9886568509615384\n",
      "Epoch  3920 Loss  0.03192348778247833\n",
      "Training accuracy is  0.9876051682692307\n",
      "Epoch  3930 Loss  0.025724660605192184\n",
      "Training accuracy is  0.9885817307692307\n",
      "Epoch  3940 Loss  0.029510842636227608\n",
      "Training accuracy is  0.9836237980769231\n",
      "Epoch  3950 Loss  0.02611836977303028\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  3960 Loss  0.026186389848589897\n",
      "Training accuracy is  0.9891075721153846\n",
      "Epoch  3970 Loss  0.03059852123260498\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  3980 Loss  0.025946898385882378\n",
      "Training accuracy is  0.9881310096153846\n",
      "Epoch  3990 Loss  0.030377600342035294\n",
      "Training accuracy is  0.9840745192307693\n",
      "Epoch  4000 Loss  0.02561923675239086\n",
      "Training accuracy is  0.9885817307692307\n",
      "Epoch  4010 Loss  0.02559479884803295\n",
      "Training accuracy is  0.9885817307692307\n",
      "Epoch  4020 Loss  0.025577325373888016\n",
      "Training accuracy is  0.9886568509615384\n",
      "Epoch  4030 Loss  0.025561900809407234\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  4040 Loss  0.025547701865434647\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  4050 Loss  0.025532236322760582\n",
      "Training accuracy is  0.9885817307692307\n",
      "Epoch  4060 Loss  0.0255177840590477\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  4070 Loss  0.02550412528216839\n",
      "Training accuracy is  0.9886568509615384\n",
      "Epoch  4080 Loss  0.02549057826399803\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  4090 Loss  0.025474978610873222\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  4100 Loss  0.02546057477593422\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  4110 Loss  0.025447290390729904\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  4120 Loss  0.025432970374822617\n",
      "Training accuracy is  0.9885817307692307\n",
      "Epoch  4130 Loss  0.025418298318982124\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  4140 Loss  0.0254058800637722\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  4150 Loss  0.025390930473804474\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  4160 Loss  0.02537485957145691\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  4170 Loss  0.025357505306601524\n",
      "Training accuracy is  0.9885817307692307\n",
      "Epoch  4180 Loss  0.025328529998660088\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  4190 Loss  0.025264035910367966\n",
      "Training accuracy is  0.9885066105769231\n",
      "Epoch  4200 Loss  0.02516912668943405\n",
      "Training accuracy is  0.9888070913461539\n",
      "Epoch  4210 Loss  0.02506655640900135\n",
      "Training accuracy is  0.9889573317307693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4220 Loss  0.02496853470802307\n",
      "Training accuracy is  0.9890324519230769\n",
      "Epoch  4230 Loss  0.024873269721865654\n",
      "Training accuracy is  0.9891826923076923\n",
      "Epoch  4240 Loss  0.024782009422779083\n",
      "Training accuracy is  0.9891826923076923\n",
      "Epoch  4250 Loss  0.02467930130660534\n",
      "Training accuracy is  0.9894831730769231\n",
      "Epoch  4260 Loss  0.02456524968147278\n",
      "Training accuracy is  0.9894831730769231\n",
      "Epoch  4270 Loss  0.024455798789858818\n",
      "Training accuracy is  0.9895582932692307\n",
      "Epoch  4280 Loss  0.02435341663658619\n",
      "Training accuracy is  0.9896334134615384\n",
      "Epoch  4290 Loss  0.024269182235002518\n",
      "Training accuracy is  0.9897836538461539\n",
      "Epoch  4300 Loss  0.024194834753870964\n",
      "Training accuracy is  0.9897836538461539\n",
      "Epoch  4310 Loss  0.02411927841603756\n",
      "Training accuracy is  0.9898587740384616\n",
      "Epoch  4320 Loss  0.024046264588832855\n",
      "Training accuracy is  0.9901592548076923\n",
      "Epoch  4330 Loss  0.02397819608449936\n",
      "Training accuracy is  0.9903094951923077\n",
      "Epoch  4340 Loss  0.02391592413187027\n",
      "Training accuracy is  0.9906099759615384\n",
      "Epoch  4350 Loss  0.02386072278022766\n",
      "Training accuracy is  0.9906850961538461\n",
      "Epoch  4360 Loss  0.023804502561688423\n",
      "Training accuracy is  0.9906850961538461\n",
      "Epoch  4370 Loss  0.02375449799001217\n",
      "Training accuracy is  0.9906099759615384\n",
      "Epoch  4380 Loss  0.023706000298261642\n",
      "Training accuracy is  0.9906099759615384\n",
      "Epoch  4390 Loss  0.023657608777284622\n",
      "Training accuracy is  0.9907602163461539\n",
      "Epoch  4400 Loss  0.02362068183720112\n",
      "Training accuracy is  0.9906850961538461\n",
      "Epoch  4410 Loss  0.023582378402352333\n",
      "Training accuracy is  0.9907602163461539\n",
      "Epoch  4420 Loss  0.023543762043118477\n",
      "Training accuracy is  0.9907602163461539\n",
      "Epoch  4430 Loss  0.023500759154558182\n",
      "Training accuracy is  0.9908353365384616\n",
      "Epoch  4440 Loss  0.02345906011760235\n",
      "Training accuracy is  0.9909104567307693\n",
      "Epoch  4450 Loss  0.023420823737978935\n",
      "Training accuracy is  0.9907602163461539\n",
      "Epoch  4460 Loss  0.023384341970086098\n",
      "Training accuracy is  0.9909104567307693\n",
      "Epoch  4470 Loss  0.023347165435552597\n",
      "Training accuracy is  0.9909104567307693\n",
      "Epoch  4480 Loss  0.023310324177145958\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4490 Loss  0.023276720196008682\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4500 Loss  0.023245129734277725\n",
      "Training accuracy is  0.9909104567307693\n",
      "Epoch  4510 Loss  0.023214684799313545\n",
      "Training accuracy is  0.9908353365384616\n",
      "Epoch  4520 Loss  0.023186543956398964\n",
      "Training accuracy is  0.9909104567307693\n",
      "Epoch  4530 Loss  0.023157406598329544\n",
      "Training accuracy is  0.9908353365384616\n",
      "Epoch  4540 Loss  0.023129073902964592\n",
      "Training accuracy is  0.9909104567307693\n",
      "Epoch  4550 Loss  0.02310291863977909\n",
      "Training accuracy is  0.9909104567307693\n",
      "Epoch  4560 Loss  0.023076798766851425\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4570 Loss  0.023048270493745804\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4580 Loss  0.023019718006253242\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4590 Loss  0.02299552783370018\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4600 Loss  0.022966178134083748\n",
      "Training accuracy is  0.9909104567307693\n",
      "Epoch  4610 Loss  0.022940319031476974\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4620 Loss  0.022914428263902664\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4630 Loss  0.02288690209388733\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4640 Loss  0.02286127395927906\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4650 Loss  0.0228341706097126\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4660 Loss  0.022807521745562553\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4670 Loss  0.022783515974879265\n",
      "Training accuracy is  0.9911358173076923\n",
      "Epoch  4680 Loss  0.02275693044066429\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4690 Loss  0.022731781005859375\n",
      "Training accuracy is  0.9911358173076923\n",
      "Epoch  4700 Loss  0.02270662412047386\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4710 Loss  0.022678423672914505\n",
      "Training accuracy is  0.9911358173076923\n",
      "Epoch  4720 Loss  0.02265305258333683\n",
      "Training accuracy is  0.9910606971153846\n",
      "Epoch  4730 Loss  0.022627342492341995\n",
      "Training accuracy is  0.9912109375\n",
      "Epoch  4740 Loss  0.022603970021009445\n",
      "Training accuracy is  0.9912860576923077\n",
      "Epoch  4750 Loss  0.02257959358394146\n",
      "Training accuracy is  0.9912860576923077\n",
      "Epoch  4760 Loss  0.022563781589269638\n",
      "Training accuracy is  0.9911358173076923\n",
      "Epoch  4770 Loss  0.022549161687493324\n",
      "Training accuracy is  0.9911358173076923\n",
      "Epoch  4780 Loss  0.022554976865649223\n",
      "Training accuracy is  0.9910606971153846\n",
      "Epoch  4790 Loss  0.022663505747914314\n",
      "Training accuracy is  0.9910606971153846\n",
      "Epoch  4800 Loss  0.022904951125383377\n",
      "Training accuracy is  0.9906850961538461\n",
      "Epoch  4810 Loss  0.023180406540632248\n",
      "Training accuracy is  0.990234375\n",
      "Epoch  4820 Loss  0.02258121594786644\n",
      "Training accuracy is  0.9912860576923077\n",
      "Epoch  4830 Loss  0.02319832518696785\n",
      "Training accuracy is  0.9899338942307693\n",
      "Epoch  4840 Loss  0.02326463721692562\n",
      "Training accuracy is  0.9906850961538461\n",
      "Epoch  4850 Loss  0.023422976955771446\n",
      "Training accuracy is  0.9912109375\n",
      "Epoch  4860 Loss  0.02245735377073288\n",
      "Training accuracy is  0.9914362980769231\n",
      "Epoch  4870 Loss  0.022729845717549324\n",
      "Training accuracy is  0.9905348557692307\n",
      "Epoch  4880 Loss  0.02359863929450512\n",
      "Training accuracy is  0.9900841346153846\n",
      "Epoch  4890 Loss  0.022429578006267548\n",
      "Training accuracy is  0.9915865384615384\n",
      "Epoch  4900 Loss  0.023808274418115616\n",
      "Training accuracy is  0.9916616586538461\n",
      "Epoch  4910 Loss  0.022242220118641853\n",
      "Training accuracy is  0.9909855769230769\n",
      "Epoch  4920 Loss  0.023579664528369904\n",
      "Training accuracy is  0.9899338942307693\n",
      "Epoch  4930 Loss  0.022256525233387947\n",
      "Training accuracy is  0.9912860576923077\n",
      "Epoch  4940 Loss  0.022949380800127983\n",
      "Training accuracy is  0.9912860576923077\n",
      "Epoch  4950 Loss  0.022968750447034836\n",
      "Training accuracy is  0.9912860576923077\n",
      "Epoch  4960 Loss  0.022325832396745682\n",
      "Training accuracy is  0.9910606971153846\n",
      "Epoch  4970 Loss  0.023584473878145218\n",
      "Training accuracy is  0.9898587740384616\n",
      "Epoch  4980 Loss  0.022074677050113678\n",
      "Training accuracy is  0.9915114182692307\n",
      "Epoch  4990 Loss  0.02280593104660511\n",
      "Training accuracy is  0.9914362980769231\n",
      "Epoch  5000 Loss  0.023140551522374153\n",
      "Training accuracy is  0.9914362980769231\n",
      "Epoch  5010 Loss  0.02223225124180317\n",
      "Training accuracy is  0.9911358173076923\n",
      "Epoch  5020 Loss  0.023343583568930626\n",
      "Training accuracy is  0.990234375\n",
      "Epoch  5030 Loss  0.02191876620054245\n",
      "Training accuracy is  0.9917367788461539\n",
      "Epoch  5040 Loss  0.022620299831032753\n",
      "Training accuracy is  0.9915114182692307\n",
      "Epoch  5050 Loss  0.023254279047250748\n",
      "Training accuracy is  0.9913611778846154\n",
      "Epoch  5060 Loss  0.02263053134083748\n",
      "Training accuracy is  0.9906099759615384\n",
      "Epoch  5070 Loss  0.02224067598581314\n",
      "Training accuracy is  0.9912860576923077\n",
      "Epoch  5080 Loss  0.022121788933873177\n",
      "Training accuracy is  0.9912860576923077\n",
      "Epoch  5090 Loss  0.023558203130960464\n",
      "Training accuracy is  0.9919621394230769\n",
      "Epoch  5100 Loss  0.021730273962020874\n",
      "Training accuracy is  0.9913611778846154\n",
      "Epoch  5110 Loss  0.022966135293245316\n",
      "Training accuracy is  0.9901592548076923\n",
      "Epoch  5120 Loss  0.021894153207540512\n",
      "Training accuracy is  0.9914362980769231\n",
      "Epoch  5130 Loss  0.02160760574042797\n",
      "Training accuracy is  0.9920372596153846\n",
      "Epoch  5140 Loss  0.02374902553856373\n",
      "Training accuracy is  0.9912860576923077\n",
      "Epoch  5150 Loss  0.021552007645368576\n",
      "Training accuracy is  0.9917367788461539\n",
      "Epoch  5160 Loss  0.022539354860782623\n",
      "Training accuracy is  0.9909104567307693\n",
      "Epoch  5170 Loss  0.021491695195436478\n",
      "Training accuracy is  0.9920372596153846\n",
      "Epoch  5180 Loss  0.022588282823562622\n",
      "Training accuracy is  0.9920372596153846\n",
      "Epoch  5190 Loss  0.021747775375843048\n",
      "Training accuracy is  0.9917367788461539\n",
      "Epoch  5200 Loss  0.02129106968641281\n",
      "Training accuracy is  0.9919621394230769\n",
      "Epoch  5210 Loss  0.02145833894610405\n",
      "Training accuracy is  0.9919621394230769\n",
      "Epoch  5220 Loss  0.026689477264881134\n",
      "Training accuracy is  0.9906099759615384\n",
      "Epoch  5230 Loss  0.02291596308350563\n",
      "Training accuracy is  0.9895582932692307\n",
      "Epoch  5240 Loss  0.02143595553934574\n",
      "Training accuracy is  0.9919621394230769\n",
      "Epoch  5250 Loss  0.021229101344943047\n",
      "Training accuracy is  0.9922626201923077\n",
      "Epoch  5260 Loss  0.021339697763323784\n",
      "Training accuracy is  0.9918118990384616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5270 Loss  0.02228507213294506\n",
      "Training accuracy is  0.9903846153846154\n",
      "Epoch  5280 Loss  0.021042047068476677\n",
      "Training accuracy is  0.9918118990384616\n",
      "Epoch  5290 Loss  0.02087532728910446\n",
      "Training accuracy is  0.9921123798076923\n",
      "Epoch  5300 Loss  0.02115073800086975\n",
      "Training accuracy is  0.9917367788461539\n",
      "Epoch  5310 Loss  0.025216758251190186\n",
      "Training accuracy is  0.9883563701923077\n",
      "Epoch  5320 Loss  0.023131299763917923\n",
      "Training accuracy is  0.9919621394230769\n",
      "Epoch  5330 Loss  0.021729182451963425\n",
      "Training accuracy is  0.9907602163461539\n",
      "Epoch  5340 Loss  0.020827259868383408\n",
      "Training accuracy is  0.9922626201923077\n",
      "Epoch  5350 Loss  0.02107088454067707\n",
      "Training accuracy is  0.9922626201923077\n",
      "Epoch  5360 Loss  0.020613977685570717\n",
      "Training accuracy is  0.9928635817307693\n",
      "Epoch  5370 Loss  0.021520046517252922\n",
      "Training accuracy is  0.9920372596153846\n",
      "Epoch  5380 Loss  0.021890612319111824\n",
      "Training accuracy is  0.9921123798076923\n",
      "Epoch  5390 Loss  0.021635551005601883\n",
      "Training accuracy is  0.9903846153846154\n",
      "Epoch  5400 Loss  0.02043263055384159\n",
      "Training accuracy is  0.9924879807692307\n",
      "Epoch  5410 Loss  0.02075997367501259\n",
      "Training accuracy is  0.9923377403846154\n",
      "Epoch  5420 Loss  0.02266409620642662\n",
      "Training accuracy is  0.9921875\n",
      "Epoch  5430 Loss  0.020326005294919014\n",
      "Training accuracy is  0.9924128605769231\n",
      "Epoch  5440 Loss  0.021791808307170868\n",
      "Training accuracy is  0.9903094951923077\n",
      "Epoch  5450 Loss  0.020218083634972572\n",
      "Training accuracy is  0.9926382211538461\n",
      "Epoch  5460 Loss  0.02028679847717285\n",
      "Training accuracy is  0.9924879807692307\n",
      "Epoch  5470 Loss  0.02364845760166645\n",
      "Training accuracy is  0.9920372596153846\n",
      "Epoch  5480 Loss  0.020165132358670235\n",
      "Training accuracy is  0.9921123798076923\n",
      "Epoch  5490 Loss  0.020669979974627495\n",
      "Training accuracy is  0.9920372596153846\n",
      "Epoch  5500 Loss  0.01990206353366375\n",
      "Training accuracy is  0.9933143028846154\n",
      "Epoch  5510 Loss  0.022163208574056625\n",
      "Training accuracy is  0.9922626201923077\n",
      "Epoch  5520 Loss  0.01986910216510296\n",
      "Training accuracy is  0.9930138221153846\n",
      "Epoch  5530 Loss  0.020953355357050896\n",
      "Training accuracy is  0.9907602163461539\n",
      "Epoch  5540 Loss  0.01986824721097946\n",
      "Training accuracy is  0.9926382211538461\n",
      "Epoch  5550 Loss  0.019637515768408775\n",
      "Training accuracy is  0.9927884615384616\n",
      "Epoch  5560 Loss  0.021700721234083176\n",
      "Training accuracy is  0.9888822115384616\n",
      "Epoch  5570 Loss  0.01963404193520546\n",
      "Training accuracy is  0.9931640625\n",
      "Epoch  5580 Loss  0.02050197869539261\n",
      "Training accuracy is  0.9927133413461539\n",
      "Epoch  5590 Loss  0.020035583525896072\n",
      "Training accuracy is  0.9917367788461539\n",
      "Epoch  5600 Loss  0.01983371190726757\n",
      "Training accuracy is  0.9925631009615384\n",
      "Epoch  5610 Loss  0.01929955556988716\n",
      "Training accuracy is  0.9930138221153846\n",
      "Epoch  5620 Loss  0.020782293751835823\n",
      "Training accuracy is  0.9897836538461539\n",
      "Epoch  5630 Loss  0.019919611513614655\n",
      "Training accuracy is  0.9927884615384616\n",
      "Epoch  5640 Loss  0.020472368225455284\n",
      "Training accuracy is  0.9929387019230769\n",
      "Epoch  5650 Loss  0.01945979706943035\n",
      "Training accuracy is  0.9924879807692307\n",
      "Epoch  5660 Loss  0.01955997943878174\n",
      "Training accuracy is  0.9924879807692307\n",
      "Epoch  5670 Loss  0.018837820738554\n",
      "Training accuracy is  0.9931640625\n",
      "Epoch  5680 Loss  0.02013659104704857\n",
      "Training accuracy is  0.9903846153846154\n",
      "Epoch  5690 Loss  0.019549839198589325\n",
      "Training accuracy is  0.9928635817307693\n",
      "Epoch  5700 Loss  0.019657697528600693\n",
      "Training accuracy is  0.9933143028846154\n",
      "Epoch  5710 Loss  0.019396254792809486\n",
      "Training accuracy is  0.9918118990384616\n",
      "Epoch  5720 Loss  0.018357250839471817\n",
      "Training accuracy is  0.9936147836538461\n",
      "Epoch  5730 Loss  0.0182021576911211\n",
      "Training accuracy is  0.9944411057692307\n",
      "Epoch  5740 Loss  0.022495487704873085\n",
      "Training accuracy is  0.9918118990384616\n",
      "Epoch  5750 Loss  0.018274884670972824\n",
      "Training accuracy is  0.9927133413461539\n",
      "Epoch  5760 Loss  0.017942946404218674\n",
      "Training accuracy is  0.9944411057692307\n",
      "Epoch  5770 Loss  0.018702957779169083\n",
      "Training accuracy is  0.9939152644230769\n",
      "Epoch  5780 Loss  0.01773080602288246\n",
      "Training accuracy is  0.9948167067307693\n",
      "Epoch  5790 Loss  0.017967436462640762\n",
      "Training accuracy is  0.9930889423076923\n",
      "Epoch  5800 Loss  0.02307382971048355\n",
      "Training accuracy is  0.9884314903846154\n",
      "Epoch  5810 Loss  0.019454073160886765\n",
      "Training accuracy is  0.9933894230769231\n",
      "Epoch  5820 Loss  0.017536114901304245\n",
      "Training accuracy is  0.9942908653846154\n",
      "Epoch  5830 Loss  0.018443666398525238\n",
      "Training accuracy is  0.9924879807692307\n",
      "Epoch  5840 Loss  0.01744088903069496\n",
      "Training accuracy is  0.9945913461538461\n",
      "Epoch  5850 Loss  0.017669038847088814\n",
      "Training accuracy is  0.9932391826923077\n",
      "Epoch  5860 Loss  0.02271736040711403\n",
      "Training accuracy is  0.9888070913461539\n",
      "Epoch  5870 Loss  0.019414545968174934\n",
      "Training accuracy is  0.9938401442307693\n",
      "Epoch  5880 Loss  0.01742740347981453\n",
      "Training accuracy is  0.9937650240384616\n",
      "Epoch  5890 Loss  0.017632294446229935\n",
      "Training accuracy is  0.994140625\n",
      "Epoch  5900 Loss  0.01702500320971012\n",
      "Training accuracy is  0.9955679086538461\n",
      "Epoch  5910 Loss  0.018372246995568275\n",
      "Training accuracy is  0.9939903846153846\n",
      "Epoch  5920 Loss  0.01860160008072853\n",
      "Training accuracy is  0.9947415865384616\n",
      "Epoch  5930 Loss  0.018565405160188675\n",
      "Training accuracy is  0.9923377403846154\n",
      "Epoch  5940 Loss  0.017069583758711815\n",
      "Training accuracy is  0.9954176682692307\n",
      "Epoch  5950 Loss  0.017717991024255753\n",
      "Training accuracy is  0.9945913461538461\n",
      "Epoch  5960 Loss  0.017059672623872757\n",
      "Training accuracy is  0.9956430288461539\n",
      "Epoch  5970 Loss  0.017391864210367203\n",
      "Training accuracy is  0.9945913461538461\n",
      "Epoch  5980 Loss  0.021328529343008995\n",
      "Training accuracy is  0.9936147836538461\n",
      "Epoch  5990 Loss  0.017672967165708542\n",
      "Training accuracy is  0.9924879807692307\n",
      "Epoch  6000 Loss  0.01667436584830284\n",
      "Training accuracy is  0.9957932692307693\n",
      "Epoch  6010 Loss  0.017284391447901726\n",
      "Training accuracy is  0.9945162259615384\n",
      "Epoch  6020 Loss  0.018889673054218292\n",
      "Training accuracy is  0.9945162259615384\n",
      "Epoch  6030 Loss  0.01645304635167122\n",
      "Training accuracy is  0.9958683894230769\n",
      "Epoch  6040 Loss  0.017775990068912506\n",
      "Training accuracy is  0.9922626201923077\n",
      "Epoch  6050 Loss  0.01834597997367382\n",
      "Training accuracy is  0.9927133413461539\n",
      "Epoch  6060 Loss  0.017125995829701424\n",
      "Training accuracy is  0.9948167067307693\n",
      "Epoch  6070 Loss  0.017143504694104195\n",
      "Training accuracy is  0.9951923076923077\n",
      "Epoch  6080 Loss  0.016284380108118057\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  6090 Loss  0.016907555982470512\n",
      "Training accuracy is  0.9948167067307693\n",
      "Epoch  6100 Loss  0.021329831331968307\n",
      "Training accuracy is  0.9938401442307693\n",
      "Epoch  6110 Loss  0.01836700364947319\n",
      "Training accuracy is  0.9919621394230769\n",
      "Epoch  6120 Loss  0.01675879769027233\n",
      "Training accuracy is  0.9949669471153846\n",
      "Epoch  6130 Loss  0.016138607636094093\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  6140 Loss  0.0163304153829813\n",
      "Training accuracy is  0.9949669471153846\n",
      "Epoch  6150 Loss  0.01911815255880356\n",
      "Training accuracy is  0.990234375\n",
      "Epoch  6160 Loss  0.01595202274620533\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  6170 Loss  0.017304211854934692\n",
      "Training accuracy is  0.9949669471153846\n",
      "Epoch  6180 Loss  0.016120513901114464\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  6190 Loss  0.015837667509913445\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  6200 Loss  0.01591806299984455\n",
      "Training accuracy is  0.9959435096153846\n",
      "Epoch  6210 Loss  0.026524586603045464\n",
      "Training accuracy is  0.9876802884615384\n",
      "Epoch  6220 Loss  0.019623788073658943\n",
      "Training accuracy is  0.9900841346153846\n",
      "Epoch  6230 Loss  0.017552537843585014\n",
      "Training accuracy is  0.9951923076923077\n",
      "Epoch  6240 Loss  0.01644228771328926\n",
      "Training accuracy is  0.9945162259615384\n",
      "Epoch  6250 Loss  0.0158204585313797\n",
      "Training accuracy is  0.9959435096153846\n",
      "Epoch  6260 Loss  0.015958931297063828\n",
      "Training accuracy is  0.9957932692307693\n",
      "Epoch  6270 Loss  0.015748800709843636\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  6280 Loss  0.01757102459669113\n",
      "Training accuracy is  0.9942157451923077\n",
      "Epoch  6290 Loss  0.01685687154531479\n",
      "Training accuracy is  0.9954176682692307\n",
      "Epoch  6300 Loss  0.016978023573756218\n",
      "Training accuracy is  0.9933894230769231\n",
      "Epoch  6310 Loss  0.01548607088625431\n",
      "Training accuracy is  0.9962439903846154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6320 Loss  0.016456034034490585\n",
      "Training accuracy is  0.9954927884615384\n",
      "Epoch  6330 Loss  0.017727337777614594\n",
      "Training accuracy is  0.9948167067307693\n",
      "Epoch  6340 Loss  0.015382400713860989\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  6350 Loss  0.016891032457351685\n",
      "Training accuracy is  0.9930138221153846\n",
      "Epoch  6360 Loss  0.016672037541866302\n",
      "Training accuracy is  0.9943659855769231\n",
      "Epoch  6370 Loss  0.015690838918089867\n",
      "Training accuracy is  0.9954927884615384\n",
      "Epoch  6380 Loss  0.018033983185887337\n",
      "Training accuracy is  0.994140625\n",
      "Epoch  6390 Loss  0.015309308655560017\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  6400 Loss  0.016278162598609924\n",
      "Training accuracy is  0.9936147836538461\n",
      "Epoch  6410 Loss  0.017518682405352592\n",
      "Training accuracy is  0.9929387019230769\n",
      "Epoch  6420 Loss  0.015295205637812614\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  6430 Loss  0.01702653244137764\n",
      "Training accuracy is  0.9948918269230769\n",
      "Epoch  6440 Loss  0.015869922935962677\n",
      "Training accuracy is  0.9957181490384616\n",
      "Epoch  6450 Loss  0.015188025310635567\n",
      "Training accuracy is  0.9957932692307693\n",
      "Epoch  6460 Loss  0.018105031922459602\n",
      "Training accuracy is  0.9906850961538461\n",
      "Epoch  6470 Loss  0.015080200508236885\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  6480 Loss  0.015968043357133865\n",
      "Training accuracy is  0.9956430288461539\n",
      "Epoch  6490 Loss  0.015057291835546494\n",
      "Training accuracy is  0.9959435096153846\n",
      "Epoch  6500 Loss  0.01679033413529396\n",
      "Training accuracy is  0.9923377403846154\n",
      "Epoch  6510 Loss  0.01586310751736164\n",
      "Training accuracy is  0.9947415865384616\n",
      "Epoch  6520 Loss  0.01562176737934351\n",
      "Training accuracy is  0.9953425480769231\n",
      "Epoch  6530 Loss  0.015864558517932892\n",
      "Training accuracy is  0.9952674278846154\n",
      "Epoch  6540 Loss  0.01502153743058443\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  6550 Loss  0.015937741845846176\n",
      "Training accuracy is  0.9952674278846154\n",
      "Epoch  6560 Loss  0.019375251606106758\n",
      "Training accuracy is  0.9947415865384616\n",
      "Epoch  6570 Loss  0.01655842550098896\n",
      "Training accuracy is  0.9930889423076923\n",
      "Epoch  6580 Loss  0.015003910288214684\n",
      "Training accuracy is  0.9958683894230769\n",
      "Epoch  6590 Loss  0.015013509429991245\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  6600 Loss  0.014530988410115242\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  6610 Loss  0.015374843031167984\n",
      "Training accuracy is  0.9940655048076923\n",
      "Epoch  6620 Loss  0.02001437172293663\n",
      "Training accuracy is  0.9906099759615384\n",
      "Epoch  6630 Loss  0.016849948093295097\n",
      "Training accuracy is  0.9952674278846154\n",
      "Epoch  6640 Loss  0.015402991324663162\n",
      "Training accuracy is  0.9944411057692307\n",
      "Epoch  6650 Loss  0.014424233697354794\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  6660 Loss  0.01506893802434206\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  6670 Loss  0.015249430201947689\n",
      "Training accuracy is  0.9959435096153846\n",
      "Epoch  6680 Loss  0.016172828152775764\n",
      "Training accuracy is  0.9953425480769231\n",
      "Epoch  6690 Loss  0.015740742906928062\n",
      "Training accuracy is  0.9956430288461539\n",
      "Epoch  6700 Loss  0.01434524729847908\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  6710 Loss  0.016225282102823257\n",
      "Training accuracy is  0.9923377403846154\n",
      "Epoch  6720 Loss  0.01615348644554615\n",
      "Training accuracy is  0.9945162259615384\n",
      "Epoch  6730 Loss  0.015587283298373222\n",
      "Training accuracy is  0.9956430288461539\n",
      "Epoch  6740 Loss  0.01414121687412262\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  6750 Loss  0.014936794526875019\n",
      "Training accuracy is  0.9946664663461539\n",
      "Epoch  6760 Loss  0.017827732488512993\n",
      "Training accuracy is  0.9908353365384616\n",
      "Epoch  6770 Loss  0.014180418103933334\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  6780 Loss  0.014922257512807846\n",
      "Training accuracy is  0.9962439903846154\n",
      "Epoch  6790 Loss  0.01401768159121275\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  6800 Loss  0.014784198254346848\n",
      "Training accuracy is  0.9946664663461539\n",
      "Epoch  6810 Loss  0.02044697292149067\n",
      "Training accuracy is  0.9893329326923077\n",
      "Epoch  6820 Loss  0.01595323160290718\n",
      "Training accuracy is  0.9951171875\n",
      "Epoch  6830 Loss  0.014464386738836765\n",
      "Training accuracy is  0.9947415865384616\n",
      "Epoch  6840 Loss  0.013911668211221695\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  6850 Loss  0.014288951642811298\n",
      "Training accuracy is  0.9964693509615384\n",
      "Epoch  6860 Loss  0.014401823282241821\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  6870 Loss  0.016496015712618828\n",
      "Training accuracy is  0.9945162259615384\n",
      "Epoch  6880 Loss  0.015632472932338715\n",
      "Training accuracy is  0.9962439903846154\n",
      "Epoch  6890 Loss  0.015102732926607132\n",
      "Training accuracy is  0.9947415865384616\n",
      "Epoch  6900 Loss  0.014044886454939842\n",
      "Training accuracy is  0.9964693509615384\n",
      "Epoch  6910 Loss  0.014445032924413681\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  6920 Loss  0.013899344950914383\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  6930 Loss  0.014141843654215336\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  6940 Loss  0.023491499945521355\n",
      "Training accuracy is  0.9894831730769231\n",
      "Epoch  6950 Loss  0.0163368359208107\n",
      "Training accuracy is  0.9915865384615384\n",
      "Epoch  6960 Loss  0.015103906393051147\n",
      "Training accuracy is  0.9957932692307693\n",
      "Epoch  6970 Loss  0.014165556989610195\n",
      "Training accuracy is  0.9957181490384616\n",
      "Epoch  6980 Loss  0.01366179808974266\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  6990 Loss  0.013637393712997437\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  7000 Loss  0.013508985750377178\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  7010 Loss  0.013797030784189701\n",
      "Training accuracy is  0.9959435096153846\n",
      "Epoch  7020 Loss  0.02261294610798359\n",
      "Training accuracy is  0.9864783653846154\n",
      "Epoch  7030 Loss  0.01738010160624981\n",
      "Training accuracy is  0.9940655048076923\n",
      "Epoch  7040 Loss  0.015160763636231422\n",
      "Training accuracy is  0.9947415865384616\n",
      "Epoch  7050 Loss  0.014073053374886513\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  7060 Loss  0.013741244561970234\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  7070 Loss  0.013477612286806107\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  7080 Loss  0.013386567123234272\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  7090 Loss  0.013316144235432148\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  7100 Loss  0.01329860556870699\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  7110 Loss  0.01505556795746088\n",
      "Training accuracy is  0.9923377403846154\n",
      "Epoch  7120 Loss  0.01433587446808815\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  7130 Loss  0.01608412154018879\n",
      "Training accuracy is  0.9917367788461539\n",
      "Epoch  7140 Loss  0.013977345079183578\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  7150 Loss  0.013235984370112419\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  7160 Loss  0.013231654651463032\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  7170 Loss  0.013174621388316154\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  7180 Loss  0.01319548487663269\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  7190 Loss  0.013122452422976494\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  7200 Loss  0.01313611026853323\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  7210 Loss  0.014844611287117004\n",
      "Training accuracy is  0.9931640625\n",
      "Epoch  7220 Loss  0.018219653517007828\n",
      "Training accuracy is  0.9926382211538461\n",
      "Epoch  7230 Loss  0.013838180340826511\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  7240 Loss  0.013175081461668015\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  7250 Loss  0.013263361528515816\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  7260 Loss  0.0133069958537817\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  7270 Loss  0.01299465261399746\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  7280 Loss  0.012966599315404892\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  7290 Loss  0.013665908947587013\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  7300 Loss  0.027718015015125275\n",
      "Training accuracy is  0.9891826923076923\n",
      "Epoch  7310 Loss  0.015771565958857536\n",
      "Training accuracy is  0.9949669471153846\n",
      "Epoch  7320 Loss  0.012920807115733624\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  7330 Loss  0.012998353689908981\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  7340 Loss  0.012887096032500267\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  7350 Loss  0.01284737978130579\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  7360 Loss  0.012933789752423763\n",
      "Training accuracy is  0.9971454326923077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7370 Loss  0.012871822342276573\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  7380 Loss  0.013259627856314182\n",
      "Training accuracy is  0.9962439903846154\n",
      "Epoch  7390 Loss  0.020992176607251167\n",
      "Training accuracy is  0.9907602163461539\n",
      "Epoch  7400 Loss  0.01439778320491314\n",
      "Training accuracy is  0.9927884615384616\n",
      "Epoch  7410 Loss  0.014139879494905472\n",
      "Training accuracy is  0.9959435096153846\n",
      "Epoch  7420 Loss  0.013340572826564312\n",
      "Training accuracy is  0.9958683894230769\n",
      "Epoch  7430 Loss  0.012845057994127274\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  7440 Loss  0.012755929492413998\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  7450 Loss  0.012823257595300674\n",
      "Training accuracy is  0.9964693509615384\n",
      "Epoch  7460 Loss  0.013906210660934448\n",
      "Training accuracy is  0.9948167067307693\n",
      "Epoch  7470 Loss  0.0177775826305151\n",
      "Training accuracy is  0.9904597355769231\n",
      "Epoch  7480 Loss  0.013540657237172127\n",
      "Training accuracy is  0.9958683894230769\n",
      "Epoch  7490 Loss  0.012622499838471413\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  7500 Loss  0.013033934868872166\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  7510 Loss  0.012571417726576328\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  7520 Loss  0.013625453226268291\n",
      "Training accuracy is  0.9959435096153846\n",
      "Epoch  7530 Loss  0.023571418598294258\n",
      "Training accuracy is  0.9907602163461539\n",
      "Epoch  7540 Loss  0.01566261611878872\n",
      "Training accuracy is  0.9932391826923077\n",
      "Epoch  7550 Loss  0.013546222820878029\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  7560 Loss  0.012861787341535091\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  7570 Loss  0.012779397889971733\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  7580 Loss  0.012432952411472797\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  7590 Loss  0.012622775509953499\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  7600 Loss  0.013852614909410477\n",
      "Training accuracy is  0.9943659855769231\n",
      "Epoch  7610 Loss  0.018137522041797638\n",
      "Training accuracy is  0.9903846153846154\n",
      "Epoch  7620 Loss  0.014060680754482746\n",
      "Training accuracy is  0.9956430288461539\n",
      "Epoch  7630 Loss  0.0127940084785223\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  7640 Loss  0.012391366995871067\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  7650 Loss  0.012637892737984657\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  7660 Loss  0.01406951155513525\n",
      "Training accuracy is  0.9954927884615384\n",
      "Epoch  7670 Loss  0.01621810719370842\n",
      "Training accuracy is  0.9944411057692307\n",
      "Epoch  7680 Loss  0.012693170458078384\n",
      "Training accuracy is  0.9958683894230769\n",
      "Epoch  7690 Loss  0.012665359303355217\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  7700 Loss  0.01254359446465969\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  7710 Loss  0.014919817447662354\n",
      "Training accuracy is  0.9942908653846154\n",
      "Epoch  7720 Loss  0.01731889136135578\n",
      "Training accuracy is  0.9943659855769231\n",
      "Epoch  7730 Loss  0.01370775792747736\n",
      "Training accuracy is  0.9953425480769231\n",
      "Epoch  7740 Loss  0.013082440942525864\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  7750 Loss  0.01242674421519041\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  7760 Loss  0.012280344031751156\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  7770 Loss  0.012117709033191204\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  7780 Loss  0.0125289810821414\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  7790 Loss  0.03208436816930771\n",
      "Training accuracy is  0.9838491586538461\n",
      "Epoch  7800 Loss  0.013615589588880539\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  7810 Loss  0.014296735636889935\n",
      "Training accuracy is  0.9948167067307693\n",
      "Epoch  7820 Loss  0.012167836539447308\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  7830 Loss  0.012458867393434048\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  7840 Loss  0.012246333993971348\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  7850 Loss  0.012142087332904339\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  7860 Loss  0.012095669284462929\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  7870 Loss  0.012047962285578251\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  7880 Loss  0.012126926332712173\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  7890 Loss  0.012462135404348373\n",
      "Training accuracy is  0.9962439903846154\n",
      "Epoch  7900 Loss  0.014397312887012959\n",
      "Training accuracy is  0.9946664663461539\n",
      "Epoch  7910 Loss  0.024864692240953445\n",
      "Training accuracy is  0.9913611778846154\n",
      "Epoch  7920 Loss  0.013663957826793194\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  7930 Loss  0.012034167535603046\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  7940 Loss  0.012192266061902046\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  7950 Loss  0.011935239657759666\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  7960 Loss  0.01187184639275074\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  7970 Loss  0.011944900266826153\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  7980 Loss  0.012407430447638035\n",
      "Training accuracy is  0.9962439903846154\n",
      "Epoch  7990 Loss  0.014330046251416206\n",
      "Training accuracy is  0.9946664663461539\n",
      "Epoch  8000 Loss  0.017785344272851944\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  8010 Loss  0.013774897903203964\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  8020 Loss  0.012321542017161846\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  8030 Loss  0.011903856880962849\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8040 Loss  0.011793325655162334\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  8050 Loss  0.011755884625017643\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  8060 Loss  0.011737162247300148\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8070 Loss  0.011722789146006107\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  8080 Loss  0.01171102561056614\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  8090 Loss  0.011700659990310669\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8100 Loss  0.011691393330693245\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8110 Loss  0.011682323180139065\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8120 Loss  0.011673386208713055\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8130 Loss  0.011664615012705326\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8140 Loss  0.011655683629214764\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8150 Loss  0.011646964587271214\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  8160 Loss  0.011638069525361061\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8170 Loss  0.011628949083387852\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8180 Loss  0.01162014715373516\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8190 Loss  0.011611185036599636\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8200 Loss  0.011602342128753662\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8210 Loss  0.011593400500714779\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8220 Loss  0.011584543623030186\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8230 Loss  0.011575556360185146\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8240 Loss  0.011566719971597195\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8250 Loss  0.011557886376976967\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8260 Loss  0.011548944748938084\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8270 Loss  0.011540085077285767\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8280 Loss  0.011531286872923374\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8290 Loss  0.011522258631885052\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8300 Loss  0.011513338424265385\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8310 Loss  0.011504525318741798\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8320 Loss  0.011495562270283699\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8330 Loss  0.011486859060823917\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8340 Loss  0.011477893218398094\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8350 Loss  0.011468789540231228\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8360 Loss  0.011460036039352417\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8370 Loss  0.011451136320829391\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8380 Loss  0.011442254297435284\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8390 Loss  0.011433443985879421\n",
      "Training accuracy is  0.9973707932692307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8400 Loss  0.01142454519867897\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8410 Loss  0.011415507644414902\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8420 Loss  0.011406759731471539\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8430 Loss  0.01139772031456232\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8440 Loss  0.01138879545032978\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8450 Loss  0.011379742994904518\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8460 Loss  0.011370787397027016\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8470 Loss  0.011361820623278618\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8480 Loss  0.011352956295013428\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8490 Loss  0.011343785561621189\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8500 Loss  0.011334771290421486\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8510 Loss  0.011326145380735397\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8520 Loss  0.011317167431116104\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8530 Loss  0.011307979933917522\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8540 Loss  0.011299272999167442\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8550 Loss  0.011290216818451881\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8560 Loss  0.011281151324510574\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8570 Loss  0.011272205971181393\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8580 Loss  0.01126332487910986\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8590 Loss  0.011254498735070229\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8600 Loss  0.011245331726968288\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8610 Loss  0.011236646212637424\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8620 Loss  0.01122754905372858\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8630 Loss  0.011218489147722721\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8640 Loss  0.011209581978619099\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8650 Loss  0.011200602166354656\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8660 Loss  0.011191576719284058\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8670 Loss  0.011182615533471107\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8680 Loss  0.01117407251149416\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  8690 Loss  0.011164560914039612\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8700 Loss  0.0111545966938138\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8710 Loss  0.011145198717713356\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8720 Loss  0.011135300621390343\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8730 Loss  0.011125643737614155\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8740 Loss  0.011116143316030502\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8750 Loss  0.011107121594250202\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8760 Loss  0.011097293347120285\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8770 Loss  0.011088072322309017\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  8780 Loss  0.011078936979174614\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8790 Loss  0.011069257743656635\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8800 Loss  0.011060105636715889\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8810 Loss  0.011050681583583355\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  8820 Loss  0.011041149497032166\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  8830 Loss  0.011031885631382465\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  8840 Loss  0.01102260872721672\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8850 Loss  0.011013363488018513\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8860 Loss  0.011004303582012653\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8870 Loss  0.010994836688041687\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8880 Loss  0.010985638946294785\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8890 Loss  0.010976164601743221\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8900 Loss  0.01096666231751442\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8910 Loss  0.010951647534966469\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8920 Loss  0.010937796905636787\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  8930 Loss  0.010924826376140118\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  8940 Loss  0.010913396254181862\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  8950 Loss  0.01090240478515625\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  8960 Loss  0.010891441255807877\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  8970 Loss  0.01088053360581398\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  8980 Loss  0.010869404301047325\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  8990 Loss  0.01085874903947115\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9000 Loss  0.010848362930119038\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9010 Loss  0.010837381705641747\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  9020 Loss  0.01082655880600214\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  9030 Loss  0.010816712863743305\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  9040 Loss  0.010807654820382595\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9050 Loss  0.010796690359711647\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  9060 Loss  0.01078600063920021\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  9070 Loss  0.010776604525744915\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  9080 Loss  0.010765896178781986\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  9090 Loss  0.010757340118288994\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9100 Loss  0.01075075939297676\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9110 Loss  0.010742385871708393\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  9120 Loss  0.010731395334005356\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  9130 Loss  0.01071641780436039\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9140 Loss  0.010726498439908028\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  9150 Loss  0.010743813589215279\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9160 Loss  0.010687710717320442\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9170 Loss  0.01085114385932684\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  9180 Loss  0.011194119229912758\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  9190 Loss  0.010684579610824585\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9200 Loss  0.011153383180499077\n",
      "Training accuracy is  0.9964693509615384\n",
      "Epoch  9210 Loss  0.01094110682606697\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  9220 Loss  0.01075156033039093\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  9230 Loss  0.011411892250180244\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  9240 Loss  0.010668272152543068\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  9250 Loss  0.010934899561107159\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  9260 Loss  0.01113942638039589\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  9270 Loss  0.010588034056127071\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9280 Loss  0.011147873476147652\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  9290 Loss  0.011792250908911228\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  9300 Loss  0.011134671047329903\n",
      "Training accuracy is  0.9964693509615384\n",
      "Epoch  9310 Loss  0.010614330880343914\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  9320 Loss  0.010682566091418266\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  9330 Loss  0.010529960505664349\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9340 Loss  0.010662765242159367\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  9350 Loss  0.01306047011166811\n",
      "Training accuracy is  0.9934645432692307\n",
      "Epoch  9360 Loss  0.01123811211436987\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  9370 Loss  0.011102532967925072\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  9380 Loss  0.010659905150532722\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9390 Loss  0.010534418746829033\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9400 Loss  0.010531408712267876\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  9410 Loss  0.010503164492547512\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  9420 Loss  0.010457928292453289\n",
      "Training accuracy is  0.9975961538461539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9430 Loss  0.01045077946037054\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9440 Loss  0.01074611209332943\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  9450 Loss  0.012093285098671913\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  9460 Loss  0.010714833624660969\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  9470 Loss  0.010411879047751427\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  9480 Loss  0.0105577502399683\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  9490 Loss  0.010400648228824139\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9500 Loss  0.010390744544565678\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9510 Loss  0.011236296966671944\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  9520 Loss  0.012856172397732735\n",
      "Training accuracy is  0.9959435096153846\n",
      "Epoch  9530 Loss  0.010514809750020504\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  9540 Loss  0.010807350277900696\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  9550 Loss  0.010380766354501247\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9560 Loss  0.010334009304642677\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9570 Loss  0.010323593392968178\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9580 Loss  0.01031914260238409\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  9590 Loss  0.010307935997843742\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  9600 Loss  0.010338395833969116\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9610 Loss  0.010358836501836777\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9620 Loss  0.010503141209483147\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  9630 Loss  0.010842894203960896\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  9640 Loss  0.010476232506334782\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  9650 Loss  0.010255513712763786\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9660 Loss  0.010450819507241249\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  9670 Loss  0.01471798773854971\n",
      "Training accuracy is  0.9921875\n",
      "Epoch  9680 Loss  0.011906487867236137\n",
      "Training accuracy is  0.9959435096153846\n",
      "Epoch  9690 Loss  0.010270398110151291\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  9700 Loss  0.010474340990185738\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  9710 Loss  0.010266686789691448\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  9720 Loss  0.010213172063231468\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  9730 Loss  0.01020981278270483\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9740 Loss  0.010190819390118122\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9750 Loss  0.01019534096121788\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  9760 Loss  0.01017698459327221\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  9770 Loss  0.010234463959932327\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  9780 Loss  0.01084802858531475\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  9790 Loss  0.01059435959905386\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  9800 Loss  0.01055817399173975\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  9810 Loss  0.010221992619335651\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9820 Loss  0.010174354538321495\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  9830 Loss  0.011297349818050861\n",
      "Training accuracy is  0.9957932692307693\n",
      "Epoch  9840 Loss  0.01037932001054287\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9850 Loss  0.010182855650782585\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  9860 Loss  0.01020018570125103\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  9870 Loss  0.010301009751856327\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  9880 Loss  0.010089523158967495\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  9890 Loss  0.010271335951983929\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  9900 Loss  0.010398552753031254\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  9910 Loss  0.010242434218525887\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  9920 Loss  0.010272761806845665\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  9930 Loss  0.012183443643152714\n",
      "Training accuracy is  0.9947415865384616\n",
      "Epoch  9940 Loss  0.010249365121126175\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  9950 Loss  0.010192228481173515\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  9960 Loss  0.010070926509797573\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  9970 Loss  0.010012879967689514\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  9980 Loss  0.010136041790246964\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  9990 Loss  0.009996702894568443\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  10000 Loss  0.010065353475511074\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  10010 Loss  0.011093948036432266\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  10020 Loss  0.010479563847184181\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  10030 Loss  0.010454901494085789\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  10040 Loss  0.010211512446403503\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  10050 Loss  0.009975774213671684\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  10060 Loss  0.010019112378358841\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  10070 Loss  0.010583833791315556\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  10080 Loss  0.011055277660489082\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  10090 Loss  0.010435525327920914\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  10100 Loss  0.009951869025826454\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  10110 Loss  0.010163173079490662\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  10120 Loss  0.010013716295361519\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  10130 Loss  0.010007240809500217\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  10140 Loss  0.0112744877114892\n",
      "Training accuracy is  0.9951923076923077\n",
      "Epoch  10150 Loss  0.010275820270180702\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  10160 Loss  0.009950259700417519\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  10170 Loss  0.010011553764343262\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  10180 Loss  0.009938226081430912\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  10190 Loss  0.009856230579316616\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  10200 Loss  0.009896377101540565\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  10210 Loss  0.009865064173936844\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  10220 Loss  0.009931372478604317\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  10230 Loss  0.010727145709097385\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  10240 Loss  0.010097810998558998\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  10250 Loss  0.010347409173846245\n",
      "Training accuracy is  0.9964693509615384\n",
      "Epoch  10260 Loss  0.00982630904763937\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  10270 Loss  0.01006329245865345\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  10280 Loss  0.010959248058497906\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  10290 Loss  0.00978893879801035\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  10300 Loss  0.010252703912556171\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  10310 Loss  0.009799158200621605\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  10320 Loss  0.01043679378926754\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  10330 Loss  0.010255887173116207\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  10340 Loss  0.009840646758675575\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  10350 Loss  0.010644196532666683\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  10360 Loss  0.010013812221586704\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  10370 Loss  0.01031450554728508\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  10380 Loss  0.009728585369884968\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  10390 Loss  0.009953896515071392\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  10400 Loss  0.010506181046366692\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  10410 Loss  0.009812445379793644\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  10420 Loss  0.010016058571636677\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  10430 Loss  0.010810855776071548\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  10440 Loss  0.009693091735243797\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  10450 Loss  0.0102117620408535\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  10460 Loss  0.00967314187437296\n",
      "Training accuracy is  0.9975210336538461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10470 Loss  0.00988665409386158\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  10480 Loss  0.011974758468568325\n",
      "Training accuracy is  0.9955679086538461\n",
      "Epoch  10490 Loss  0.00984184630215168\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  10500 Loss  0.0097733773291111\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  10510 Loss  0.009653772227466106\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  10520 Loss  0.009675429202616215\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  10530 Loss  0.009698504582047462\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  10540 Loss  0.009923135861754417\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  10550 Loss  0.009926054626703262\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  10560 Loss  0.009891977533698082\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  10570 Loss  0.009810633026063442\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  10580 Loss  0.010552952066063881\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  10590 Loss  0.010301182977855206\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  10600 Loss  0.01014433242380619\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  10610 Loss  0.009586656466126442\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  10620 Loss  0.010044872760772705\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  10630 Loss  0.009716310538351536\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  10640 Loss  0.009613298811018467\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  10650 Loss  0.010847732424736023\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  10660 Loss  0.010524975135922432\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  10670 Loss  0.009575392119586468\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  10680 Loss  0.009538482874631882\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  10690 Loss  0.009536524303257465\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  10700 Loss  0.009632876142859459\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  10710 Loss  0.009512561373412609\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  10720 Loss  0.009545990265905857\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  10730 Loss  0.010084264911711216\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  10740 Loss  0.01045146118849516\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  10750 Loss  0.009928256273269653\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  10760 Loss  0.009518066421151161\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  10770 Loss  0.009976237080991268\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  10780 Loss  0.009683678857982159\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  10790 Loss  0.009612509980797768\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  10800 Loss  0.010353378020226955\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  10810 Loss  0.009769905358552933\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  10820 Loss  0.009619032964110374\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  10830 Loss  0.010085388086736202\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  10840 Loss  0.00966606568545103\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  10850 Loss  0.0094292676076293\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  10860 Loss  0.00942451972514391\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  10870 Loss  0.010192696005105972\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  10880 Loss  0.013187658041715622\n",
      "Training accuracy is  0.9964693509615384\n",
      "Epoch  10890 Loss  0.011290748603641987\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  10900 Loss  0.009813309647142887\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  10910 Loss  0.00942293182015419\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  10920 Loss  0.009526840411126614\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  10930 Loss  0.009400706738233566\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  10940 Loss  0.009378490969538689\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  10950 Loss  0.00937134213745594\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  10960 Loss  0.009366346523165703\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  10970 Loss  0.009358057752251625\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  10980 Loss  0.00935591571033001\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  10990 Loss  0.009385180659592152\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11000 Loss  0.009382282383739948\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  11010 Loss  0.009393253363668919\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  11020 Loss  0.009772057645022869\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  11030 Loss  0.00984360370784998\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  11040 Loss  0.009397135116159916\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  11050 Loss  0.010190282016992569\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  11060 Loss  0.009516734629869461\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11070 Loss  0.009609313681721687\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  11080 Loss  0.0101822130382061\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  11090 Loss  0.009305828250944614\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11100 Loss  0.009844345971941948\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  11110 Loss  0.009419988840818405\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  11120 Loss  0.009305493906140327\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11130 Loss  0.010135417804121971\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  11140 Loss  0.012098209001123905\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  11150 Loss  0.009277314879000187\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  11160 Loss  0.009563342668116093\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  11170 Loss  0.00946835707873106\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  11180 Loss  0.009325303137302399\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  11190 Loss  0.009247713722288609\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11200 Loss  0.009255599230527878\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11210 Loss  0.009237419813871384\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11220 Loss  0.00936744175851345\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  11230 Loss  0.01014128141105175\n",
      "Training accuracy is  0.9960186298076923\n",
      "Epoch  11240 Loss  0.00926906242966652\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  11250 Loss  0.009827355854213238\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  11260 Loss  0.009352477267384529\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  11270 Loss  0.00927321333438158\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  11280 Loss  0.010348058305680752\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  11290 Loss  0.009654580615460873\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  11300 Loss  0.009819925762712955\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  11310 Loss  0.009305744431912899\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  11320 Loss  0.00952085480093956\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  11330 Loss  0.00923874881118536\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11340 Loss  0.009285401552915573\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  11350 Loss  0.010836764238774776\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  11360 Loss  0.009385442361235619\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11370 Loss  0.009174666367471218\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  11380 Loss  0.009186522103846073\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  11390 Loss  0.009355503134429455\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  11400 Loss  0.009199089370667934\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  11410 Loss  0.009243694134056568\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  11420 Loss  0.009278550744056702\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  11430 Loss  0.010077358223497868\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  11440 Loss  0.009364361874759197\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  11450 Loss  0.009703059680759907\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  11460 Loss  0.00910229329019785\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  11470 Loss  0.009529473260045052\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  11480 Loss  0.00983285903930664\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  11490 Loss  0.009097222238779068\n",
      "Training accuracy is  0.9974459134615384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  11500 Loss  0.009782628156244755\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  11510 Loss  0.010323102585971355\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  11520 Loss  0.009627705439925194\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  11530 Loss  0.009063934907317162\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  11540 Loss  0.009465975686907768\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  11550 Loss  0.009065638296306133\n",
      "Training accuracy is  0.9976712740384616\n",
      "Epoch  11560 Loss  0.00904853455722332\n",
      "Training accuracy is  0.9976712740384616\n",
      "Epoch  11570 Loss  0.009592781774699688\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  11580 Loss  0.013544013723731041\n",
      "Training accuracy is  0.9946664663461539\n",
      "Epoch  11590 Loss  0.0091001708060503\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11600 Loss  0.009576883167028427\n",
      "Training accuracy is  0.9963191105769231\n",
      "Epoch  11610 Loss  0.009263532236218452\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  11620 Loss  0.009090220555663109\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  11630 Loss  0.009058644063770771\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  11640 Loss  0.009028889238834381\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  11650 Loss  0.009012391790747643\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  11660 Loss  0.009049193933606148\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  11670 Loss  0.009244516491889954\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  11680 Loss  0.009491438046097755\n",
      "Training accuracy is  0.9964693509615384\n",
      "Epoch  11690 Loss  0.009125545620918274\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11700 Loss  0.008980939164757729\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  11710 Loss  0.009224576875567436\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  11720 Loss  0.014723219908773899\n",
      "Training accuracy is  0.9942908653846154\n",
      "Epoch  11730 Loss  0.0103253573179245\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  11740 Loss  0.008982396684587002\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  11750 Loss  0.009080423042178154\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  11760 Loss  0.009042599238455296\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  11770 Loss  0.008959565311670303\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11780 Loss  0.008979027159512043\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  11790 Loss  0.008936132304370403\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  11800 Loss  0.008935726247727871\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  11810 Loss  0.009306926280260086\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  11820 Loss  0.009826753288507462\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  11830 Loss  0.009072734974324703\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  11840 Loss  0.009874213486909866\n",
      "Training accuracy is  0.99609375\n",
      "Epoch  11850 Loss  0.009003712795674801\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  11860 Loss  0.009388039819896221\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  11870 Loss  0.008943278342485428\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  11880 Loss  0.008985531516373158\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  11890 Loss  0.01117709744721651\n",
      "Training accuracy is  0.9949669471153846\n",
      "Epoch  11900 Loss  0.009063196368515491\n",
      "Training accuracy is  0.9962439903846154\n",
      "Epoch  11910 Loss  0.00943154189735651\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  11920 Loss  0.009191913530230522\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  11930 Loss  0.00900676753371954\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  11940 Loss  0.008871050551533699\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  11950 Loss  0.008965978398919106\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  11960 Loss  0.008949817158281803\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  11970 Loss  0.009041854180395603\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  11980 Loss  0.009868783876299858\n",
      "Training accuracy is  0.9961688701923077\n",
      "Epoch  11990 Loss  0.008882707916200161\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  12000 Loss  0.00940814707428217\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12010 Loss  0.009030327200889587\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  12020 Loss  0.008900489658117294\n",
      "Training accuracy is  0.9976712740384616\n",
      "Epoch  12030 Loss  0.008850056678056717\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  12040 Loss  0.008833428844809532\n",
      "Training accuracy is  0.9976712740384616\n",
      "Epoch  12050 Loss  0.008827818557620049\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12060 Loss  0.008824856020510197\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12070 Loss  0.008822151459753513\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12080 Loss  0.008819576352834702\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12090 Loss  0.00881680753082037\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12100 Loss  0.008814329281449318\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12110 Loss  0.008811812847852707\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12120 Loss  0.008809379301965237\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12130 Loss  0.008806843310594559\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12140 Loss  0.00880387146025896\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12150 Loss  0.00880171824246645\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12160 Loss  0.008799307979643345\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12170 Loss  0.008796780370175838\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12180 Loss  0.008794508874416351\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12190 Loss  0.008791711181402206\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12200 Loss  0.008789307437837124\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12210 Loss  0.0087865786626935\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12220 Loss  0.00878450833261013\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12230 Loss  0.008781755343079567\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12240 Loss  0.008779010735452175\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12250 Loss  0.008776525966823101\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12260 Loss  0.008773858658969402\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12270 Loss  0.008771495893597603\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12280 Loss  0.008768513798713684\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12290 Loss  0.008765100501477718\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12300 Loss  0.008762265555560589\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12310 Loss  0.008759861811995506\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12320 Loss  0.0087570296600461\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12330 Loss  0.008754351176321507\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12340 Loss  0.008751830086112022\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12350 Loss  0.00874894205480814\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12360 Loss  0.008746488951146603\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12370 Loss  0.008744051679968834\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12380 Loss  0.0087415911257267\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12390 Loss  0.00873853825032711\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12400 Loss  0.008736354298889637\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12410 Loss  0.008733389899134636\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12420 Loss  0.008731067180633545\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12430 Loss  0.00872845109552145\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12440 Loss  0.00872556772083044\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12450 Loss  0.008723126724362373\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12460 Loss  0.008720717392861843\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12470 Loss  0.00871750246733427\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12480 Loss  0.008715308271348476\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12490 Loss  0.00871253665536642\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12500 Loss  0.008710240945219994\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12510 Loss  0.008707411587238312\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12520 Loss  0.008704652078449726\n",
      "Training accuracy is  0.9975210336538461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  12530 Loss  0.008701862767338753\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12540 Loss  0.008699072524905205\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12550 Loss  0.008696472272276878\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12560 Loss  0.008693820796906948\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12570 Loss  0.008691338822245598\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12580 Loss  0.008688739500939846\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12590 Loss  0.00868607684969902\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12600 Loss  0.00868288055062294\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12610 Loss  0.00868046935647726\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12620 Loss  0.008677867241203785\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12630 Loss  0.00867509189993143\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12640 Loss  0.008672291412949562\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12650 Loss  0.008669628761708736\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12660 Loss  0.008667057380080223\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12670 Loss  0.008664248511195183\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12680 Loss  0.008661672472953796\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12690 Loss  0.008658800274133682\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12700 Loss  0.00865629967302084\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12710 Loss  0.008653341792523861\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12720 Loss  0.008650676347315311\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12730 Loss  0.008647858165204525\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  12740 Loss  0.00864492729306221\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12750 Loss  0.00864187628030777\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12760 Loss  0.008638924919068813\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12770 Loss  0.008636013604700565\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12780 Loss  0.00863335095345974\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12790 Loss  0.008630354888737202\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12800 Loss  0.008627982810139656\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12810 Loss  0.008625087328255177\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12820 Loss  0.008621793240308762\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12830 Loss  0.008619905449450016\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12840 Loss  0.008617122657597065\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12850 Loss  0.008613714948296547\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12860 Loss  0.008610827848315239\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12870 Loss  0.008608088828623295\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12880 Loss  0.008605174720287323\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12890 Loss  0.008602200075984001\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12900 Loss  0.008600025437772274\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12910 Loss  0.00859772227704525\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12920 Loss  0.008594276383519173\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12930 Loss  0.00859156809747219\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12940 Loss  0.00858891848474741\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12950 Loss  0.008586162701249123\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12960 Loss  0.00858286488801241\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12970 Loss  0.008580377325415611\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12980 Loss  0.008577353321015835\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  12990 Loss  0.008574901148676872\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13000 Loss  0.008571648970246315\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13010 Loss  0.008569211699068546\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13020 Loss  0.008566923439502716\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13030 Loss  0.00856358278542757\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13040 Loss  0.00856067519634962\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13050 Loss  0.008558522909879684\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13060 Loss  0.008555076085031033\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13070 Loss  0.008551427163183689\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13080 Loss  0.008549155667424202\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13090 Loss  0.008546633645892143\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13100 Loss  0.008543484844267368\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13110 Loss  0.008540951646864414\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13120 Loss  0.00853769388049841\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13130 Loss  0.008537402376532555\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13140 Loss  0.008533199317753315\n",
      "Training accuracy is  0.9976712740384616\n",
      "Epoch  13150 Loss  0.008532277308404446\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13160 Loss  0.008526078425347805\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13170 Loss  0.008525433018803596\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13180 Loss  0.008529621176421642\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13190 Loss  0.008519919589161873\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13200 Loss  0.00852265302091837\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  13210 Loss  0.00854574330151081\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13220 Loss  0.008523931726813316\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  13230 Loss  0.008538177236914635\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13240 Loss  0.008655453100800514\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  13250 Loss  0.00857598427683115\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13260 Loss  0.008514678105711937\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13270 Loss  0.008792898617684841\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  13280 Loss  0.008566966280341148\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13290 Loss  0.008779981173574924\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  13300 Loss  0.008500460535287857\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13310 Loss  0.008570431731641293\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13320 Loss  0.008482005447149277\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  13330 Loss  0.0084913931787014\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13340 Loss  0.008874666877090931\n",
      "Training accuracy is  0.9964693509615384\n",
      "Epoch  13350 Loss  0.008480758406221867\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13360 Loss  0.008628902025520802\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13370 Loss  0.008572901599109173\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  13380 Loss  0.008514491841197014\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13390 Loss  0.008470862172544003\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  13400 Loss  0.008633746765553951\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13410 Loss  0.008652087301015854\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  13420 Loss  0.008526582270860672\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13430 Loss  0.008556615561246872\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13440 Loss  0.008435401134192944\n",
      "Training accuracy is  0.9976712740384616\n",
      "Epoch  13450 Loss  0.008538419380784035\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13460 Loss  0.00882695522159338\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  13470 Loss  0.008497367613017559\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  13480 Loss  0.008516255766153336\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  13490 Loss  0.008417266421020031\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13500 Loss  0.008474212139844894\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13510 Loss  0.008881260640919209\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  13520 Loss  0.008466685190796852\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13530 Loss  0.00859927199780941\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  13540 Loss  0.008477944880723953\n",
      "Training accuracy is  0.9971454326923077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  13550 Loss  0.00849360041320324\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  13560 Loss  0.008394249714910984\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13570 Loss  0.008396027609705925\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  13580 Loss  0.008501900359988213\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  13590 Loss  0.009034451097249985\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  13600 Loss  0.008728345856070518\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  13610 Loss  0.008527548052370548\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13620 Loss  0.008398983627557755\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13630 Loss  0.008432332426309586\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  13640 Loss  0.008395486511290073\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13650 Loss  0.008486330509185791\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13660 Loss  0.00857243500649929\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  13670 Loss  0.008367463946342468\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  13680 Loss  0.0083609689027071\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  13690 Loss  0.00872576329857111\n",
      "Training accuracy is  0.9965444711538461\n",
      "Epoch  13700 Loss  0.008416514843702316\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13710 Loss  0.008376003243029118\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13720 Loss  0.008421453647315502\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13730 Loss  0.00842321291565895\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13740 Loss  0.0083535797894001\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13750 Loss  0.008344032801687717\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  13760 Loss  0.008464976213872433\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  13770 Loss  0.008545124903321266\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13780 Loss  0.008355283178389072\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13790 Loss  0.008412002585828304\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13800 Loss  0.008707224391400814\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  13810 Loss  0.008320888504385948\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  13820 Loss  0.008447819389402866\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13830 Loss  0.008336443454027176\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13840 Loss  0.008431226946413517\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  13850 Loss  0.00857365969568491\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  13860 Loss  0.008310609497129917\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13870 Loss  0.008321825414896011\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  13880 Loss  0.008822279050946236\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  13890 Loss  0.008300913497805595\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  13900 Loss  0.008326508104801178\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13910 Loss  0.008434888906776905\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13920 Loss  0.008348489180207253\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  13930 Loss  0.008329152129590511\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  13940 Loss  0.008293566294014454\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  13950 Loss  0.008470308966934681\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  13960 Loss  0.008378762751817703\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  13970 Loss  0.008437548764050007\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  13980 Loss  0.008396766148507595\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  13990 Loss  0.008277658373117447\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  14000 Loss  0.008439335972070694\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14010 Loss  0.008488869294524193\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  14020 Loss  0.008288426324725151\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  14030 Loss  0.008451336063444614\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  14040 Loss  0.008345156908035278\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  14050 Loss  0.00825176015496254\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  14060 Loss  0.008256361819803715\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  14070 Loss  0.008849425241351128\n",
      "Training accuracy is  0.9963942307692307\n",
      "Epoch  14080 Loss  0.00828741118311882\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14090 Loss  0.008316900581121445\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  14100 Loss  0.008300017565488815\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14110 Loss  0.00824415311217308\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  14120 Loss  0.00824717991054058\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  14130 Loss  0.008252988569438457\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  14140 Loss  0.008306563831865788\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  14150 Loss  0.008336398750543594\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14160 Loss  0.008249969221651554\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  14170 Loss  0.008424399420619011\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14180 Loss  0.008332572877407074\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  14190 Loss  0.0082563990727067\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14200 Loss  0.00844960194081068\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  14210 Loss  0.008240246213972569\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  14220 Loss  0.008218662813305855\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  14230 Loss  0.008486500941216946\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  14240 Loss  0.008294297382235527\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  14250 Loss  0.008473256602883339\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  14260 Loss  0.00832410529255867\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14270 Loss  0.00821508839726448\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  14280 Loss  0.008384497836232185\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  14290 Loss  0.008188263513147831\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  14300 Loss  0.00826368760317564\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14310 Loss  0.008420119993388653\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14320 Loss  0.008191393688321114\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  14330 Loss  0.008180173113942146\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  14340 Loss  0.008348066359758377\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14350 Loss  0.008803622797131538\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  14360 Loss  0.008520341478288174\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  14370 Loss  0.008325827307999134\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  14380 Loss  0.008236372843384743\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  14390 Loss  0.008165648207068443\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  14400 Loss  0.008191335946321487\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  14410 Loss  0.008312881924211979\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14420 Loss  0.008205315098166466\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  14430 Loss  0.008185077458620071\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  14440 Loss  0.008573639206588268\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  14450 Loss  0.008148257620632648\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14460 Loss  0.008366046473383904\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  14470 Loss  0.008226899430155754\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  14480 Loss  0.008177625015377998\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  14490 Loss  0.00813763216137886\n",
      "Training accuracy is  0.9976712740384616\n",
      "Epoch  14500 Loss  0.00822917278856039\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  14510 Loss  0.008837036788463593\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  14520 Loss  0.00846526212990284\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  14530 Loss  0.008197162300348282\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  14540 Loss  0.008120760321617126\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  14550 Loss  0.008251087740063667\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  14560 Loss  0.008115587756037712\n",
      "Training accuracy is  0.9976712740384616\n",
      "Epoch  14570 Loss  0.00821550190448761\n",
      "Training accuracy is  0.9972956730769231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  14580 Loss  0.008317144587635994\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14590 Loss  0.008109248243272305\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  14600 Loss  0.008153877221047878\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14610 Loss  0.008510317653417587\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  14620 Loss  0.008097055368125439\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  14630 Loss  0.008329958654940128\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14640 Loss  0.0081033231690526\n",
      "Training accuracy is  0.9976712740384616\n",
      "Epoch  14650 Loss  0.008087942376732826\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  14660 Loss  0.008084517903625965\n",
      "Training accuracy is  0.9975961538461539\n",
      "Epoch  14670 Loss  0.008300702087581158\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  14680 Loss  0.008503494784235954\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  14690 Loss  0.008125045336782932\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14700 Loss  0.008200706914067268\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  14710 Loss  0.00816922727972269\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14720 Loss  0.008081551641225815\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  14730 Loss  0.00807610061019659\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  14740 Loss  0.008065013214945793\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  14750 Loss  0.008117573335766792\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  14760 Loss  0.008132639341056347\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  14770 Loss  0.008104519918560982\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  14780 Loss  0.008305538445711136\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  14790 Loss  0.008148068562150002\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  14800 Loss  0.008229423314332962\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  14810 Loss  0.008062214590609074\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  14820 Loss  0.008097059093415737\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  14830 Loss  0.00849278923124075\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  14840 Loss  0.00816674530506134\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  14850 Loss  0.00805819220840931\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  14860 Loss  0.008196409791707993\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  14870 Loss  0.008064896799623966\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  14880 Loss  0.008035961538553238\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  14890 Loss  0.008409450761973858\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  14900 Loss  0.008028858341276646\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  14910 Loss  0.008188419975340366\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14920 Loss  0.008177237585186958\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  14930 Loss  0.008044612593948841\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  14940 Loss  0.00815150048583746\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14950 Loss  0.008090974763035774\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  14960 Loss  0.008015796542167664\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  14970 Loss  0.008143266662955284\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  14980 Loss  0.008464392274618149\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  14990 Loss  0.008303193375468254\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  15000 Loss  0.008043495938181877\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15010 Loss  0.008087432011961937\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15020 Loss  0.008008838631212711\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15030 Loss  0.008288789540529251\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  15040 Loss  0.00799440685659647\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15050 Loss  0.008115725591778755\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15060 Loss  0.008254422806203365\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15070 Loss  0.007991226390004158\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15080 Loss  0.008250758983194828\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  15090 Loss  0.008001526817679405\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15100 Loss  0.00798220094293356\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15110 Loss  0.008295550011098385\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  15120 Loss  0.00805369671434164\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15130 Loss  0.008191586472094059\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  15140 Loss  0.008124127984046936\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  15150 Loss  0.007981822825968266\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15160 Loss  0.008117306977510452\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15170 Loss  0.00800309982150793\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15180 Loss  0.007984899915754795\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15190 Loss  0.008292597718536854\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  15200 Loss  0.007982822135090828\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15210 Loss  0.008279831148684025\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  15220 Loss  0.008011759258806705\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15230 Loss  0.008020413108170033\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15240 Loss  0.007943814620375633\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15250 Loss  0.00802246667444706\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  15260 Loss  0.008587559685111046\n",
      "Training accuracy is  0.9966195913461539\n",
      "Epoch  15270 Loss  0.008269772864878178\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  15280 Loss  0.007992378436028957\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15290 Loss  0.00798243097960949\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15300 Loss  0.008006524294614792\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15310 Loss  0.008012103848159313\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15320 Loss  0.007948198355734348\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15330 Loss  0.008139219135046005\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  15340 Loss  0.008075580932199955\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15350 Loss  0.008145847357809544\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  15360 Loss  0.00794040597975254\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15370 Loss  0.007914829067885876\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  15380 Loss  0.008036566898226738\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15390 Loss  0.00837001297622919\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  15400 Loss  0.008142312057316303\n",
      "Training accuracy is  0.9968449519230769\n",
      "Epoch  15410 Loss  0.007907258346676826\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15420 Loss  0.008079564198851585\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  15430 Loss  0.007904387079179287\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15440 Loss  0.008000651374459267\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  15450 Loss  0.008188256993889809\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  15460 Loss  0.007901445031166077\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15470 Loss  0.008190685883164406\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  15480 Loss  0.007898006588220596\n",
      "Training accuracy is  0.9975210336538461\n",
      "Epoch  15490 Loss  0.008095725439488888\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  15500 Loss  0.008057150058448315\n",
      "Training accuracy is  0.9971454326923077\n",
      "Epoch  15510 Loss  0.008175807073712349\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  15520 Loss  0.00790182314813137\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15530 Loss  0.008067135699093342\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  15540 Loss  0.007898164913058281\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15550 Loss  0.0080708097666502\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15560 Loss  0.007916426286101341\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15570 Loss  0.007936429232358932\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15580 Loss  0.00833143014460802\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  15590 Loss  0.007870884612202644\n",
      "Training accuracy is  0.9972205528846154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  15600 Loss  0.008094560354948044\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  15610 Loss  0.008007247932255268\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15620 Loss  0.007878277450799942\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15630 Loss  0.007965698838233948\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  15640 Loss  0.008031588047742844\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  15650 Loss  0.00786561332643032\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15660 Loss  0.007890312932431698\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15670 Loss  0.008558783680200577\n",
      "Training accuracy is  0.9966947115384616\n",
      "Epoch  15680 Loss  0.007966699078679085\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15690 Loss  0.00784436147660017\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15700 Loss  0.007913148030638695\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15710 Loss  0.007905700244009495\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15720 Loss  0.00788408238440752\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15730 Loss  0.007864980958402157\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15740 Loss  0.008079535327851772\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  15750 Loss  0.007931714877486229\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15760 Loss  0.008161968551576138\n",
      "Training accuracy is  0.9967698317307693\n",
      "Epoch  15770 Loss  0.007830135524272919\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15780 Loss  0.007986648008227348\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15790 Loss  0.007817783392965794\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15800 Loss  0.007931094616651535\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  15810 Loss  0.008174407295882702\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  15820 Loss  0.007873959839344025\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15830 Loss  0.007993088103830814\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15840 Loss  0.007914500311017036\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  15850 Loss  0.007897411473095417\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15860 Loss  0.007808319292962551\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15870 Loss  0.007984776981174946\n",
      "Training accuracy is  0.9969200721153846\n",
      "Epoch  15880 Loss  0.008105998858809471\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  15890 Loss  0.008122649975121021\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15900 Loss  0.008020647801458836\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  15910 Loss  0.007805301807820797\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15920 Loss  0.007903561927378178\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15930 Loss  0.007817411795258522\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  15940 Loss  0.007885507307946682\n",
      "Training accuracy is  0.9972956730769231\n",
      "Epoch  15950 Loss  0.008113471791148186\n",
      "Training accuracy is  0.9970703125\n",
      "Epoch  15960 Loss  0.007786420173943043\n",
      "Training accuracy is  0.9972205528846154\n",
      "Epoch  15970 Loss  0.008076963946223259\n",
      "Training accuracy is  0.9969951923076923\n",
      "Epoch  15980 Loss  0.007781940512359142\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  15990 Loss  0.007827620021998882\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16000 Loss  0.00805612001568079\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16010 Loss  0.007875573821365833\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16020 Loss  0.007805020082741976\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16030 Loss  0.007778473664075136\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16040 Loss  0.007768921088427305\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16050 Loss  0.0077654654160141945\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16060 Loss  0.007764377165585756\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16070 Loss  0.007762592751532793\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16080 Loss  0.007761984132230282\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16090 Loss  0.007760554552078247\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16100 Loss  0.007759752683341503\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16110 Loss  0.00775881065055728\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16120 Loss  0.007757737301290035\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16130 Loss  0.007756357081234455\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16140 Loss  0.0077552711591124535\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16150 Loss  0.0077539654448628426\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16160 Loss  0.007753146346658468\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16170 Loss  0.0077520934864878654\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16180 Loss  0.007751378696411848\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16190 Loss  0.007750239688903093\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16200 Loss  0.007748921401798725\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16210 Loss  0.00774808693677187\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16220 Loss  0.007746717892587185\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16230 Loss  0.007745497394353151\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16240 Loss  0.00774433184415102\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16250 Loss  0.007743281312286854\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16260 Loss  0.007742696441709995\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16270 Loss  0.0077417646534740925\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16280 Loss  0.0077399639412760735\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16290 Loss  0.007738309446722269\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16300 Loss  0.007737357635051012\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16310 Loss  0.007736216764897108\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16320 Loss  0.007734827231615782\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16330 Loss  0.00773386238142848\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16340 Loss  0.007732562720775604\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16350 Loss  0.0077306851744651794\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16360 Loss  0.007730183191597462\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16370 Loss  0.007728768512606621\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16380 Loss  0.007727379444986582\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16390 Loss  0.007726690731942654\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16400 Loss  0.0077253300696611404\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16410 Loss  0.0077235815115273\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16420 Loss  0.007722687441855669\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16430 Loss  0.0077219572849571705\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16440 Loss  0.007720636203885078\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16450 Loss  0.007718958426266909\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16460 Loss  0.007717907428741455\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16470 Loss  0.007716312073171139\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16480 Loss  0.007715173531323671\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16490 Loss  0.007713119499385357\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16500 Loss  0.007712202146649361\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16510 Loss  0.007710454519838095\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16520 Loss  0.007709086872637272\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16530 Loss  0.007707555312663317\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16540 Loss  0.007706339471042156\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16550 Loss  0.007704250048846006\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16560 Loss  0.007703025825321674\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16570 Loss  0.00770157016813755\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16580 Loss  0.0077001675963401794\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16590 Loss  0.00769930612295866\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16600 Loss  0.007697721011936665\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16610 Loss  0.007695951499044895\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16620 Loss  0.0076946113258600235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16630 Loss  0.007693128660321236\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16640 Loss  0.007691919803619385\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16650 Loss  0.007690404541790485\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16660 Loss  0.007688913028687239\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16670 Loss  0.007687430363148451\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16680 Loss  0.007686656899750233\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16690 Loss  0.007685227319598198\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16700 Loss  0.007683872245252132\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16710 Loss  0.007682394701987505\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16720 Loss  0.007680932525545359\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16730 Loss  0.007679725997149944\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16740 Loss  0.007678363937884569\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16750 Loss  0.007676840294152498\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16760 Loss  0.007675659377127886\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16770 Loss  0.007674402557313442\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16780 Loss  0.007672714535146952\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16790 Loss  0.007671247702091932\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16800 Loss  0.007670267950743437\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16810 Loss  0.00766946654766798\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16820 Loss  0.007667975500226021\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16830 Loss  0.007666054647415876\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16840 Loss  0.007665495853871107\n",
      "Training accuracy is  0.9974459134615384\n",
      "Epoch  16850 Loss  0.00766475684940815\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16860 Loss  0.007663126569241285\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16870 Loss  0.007661129347980022\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16880 Loss  0.007659534923732281\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16890 Loss  0.007658649701625109\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16900 Loss  0.007657391019165516\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16910 Loss  0.007656017784029245\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16920 Loss  0.007653931621462107\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16930 Loss  0.0076522668823599815\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16940 Loss  0.007650517392903566\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16950 Loss  0.007649681530892849\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16960 Loss  0.007647363469004631\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16970 Loss  0.007645346224308014\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16980 Loss  0.007644386030733585\n",
      "Training accuracy is  0.9973707932692307\n",
      "Epoch  16990 Loss  0.007643016520887613\n",
      "Training accuracy is  0.9973707932692307\n"
     ]
    }
   ],
   "source": [
    "for i in parameters:\n",
    "    par.append(i)\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(2, i[0])\n",
    "            self.fc2 = nn.Linear(i[0], i[1])\n",
    "\n",
    "            self.fc7 = nn.Linear(i[1], 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc7(x)\n",
    "            return F.log_softmax(x)\n",
    "            #return F.softmax(x)\n",
    "        #%% plot function\n",
    "\n",
    "    def plot_data(X, y, filename):\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "    def plot_decision_boundary(clf, X, y, filename):\n",
    "        # Set min and max values and give it some padding\n",
    "        #x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "        #y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "        x_min, x_max = -1, 1\n",
    "        y_min, y_max = -1, 1\n",
    "        h = 0.01\n",
    "        # Generate a grid of points with distance h between them\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "        # Predict the function value for the whole gid\n",
    "        #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        X_out = net(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype = torch.float))\n",
    "        Z = X_out.data.max(1)[1]\n",
    "        # Z.shape\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        # Plot the contour and training examples\n",
    "        plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s = 1)\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "    #%% train\n",
    "    net = Net()\n",
    "\n",
    "    # create a stochastic gradient descent optimizer\n",
    "    learning_rate = .01\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # create a loss function\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # nepochs = 10000\n",
    "    #nepochs = 3000 #10000\n",
    "    nepochs = 17000\n",
    "    data, target = X, y\n",
    "    # run the main training loop\n",
    "    best=0\n",
    "    best_l=0\n",
    "    for epoch in range(nepochs):\n",
    "    #    adjust learning rate if desired\n",
    "        if epoch % 4000 == 0 and epoch <= 24000:\n",
    "            for g in optimizer.param_groups:\n",
    "                   g['lr'] = g['lr']/2\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagate\n",
    "        net_out = net(data)\n",
    "        # compute loss\n",
    "        loss = criterion(net_out, target)\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # print out report\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch ', epoch, 'Loss ', loss.item())\n",
    "            net_out = net(data)\n",
    "            pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "            correctidx = pred.eq(target.data) \n",
    "            ncorrect = correctidx.sum()\n",
    "            accuracy = ncorrect.item()/len(data)\n",
    "            print('Training accuracy is ', accuracy)\n",
    "            if epoch>13000 and accuracy-0.0005>best:\n",
    "                best=accuracy\n",
    "                best_l=loss.item()\n",
    "                torch.save(net, './question2b.01LR1610Epochs')\n",
    "\n",
    "    accuracy_l.append(accuracy)\n",
    "    loss_l.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81b93db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9975961538461539\n",
      "0.008569211699068546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\example_env\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "print(best)\n",
    "\n",
    "print(best_l)\n",
    "\n",
    "net1 = torch.load('./question2b.01LR1610Epochs')\n",
    "plot_decision_boundary(net1, X, y, 'Results0.0001.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
